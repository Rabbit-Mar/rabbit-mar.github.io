{"meta":{"title":"Marveal Rabbit","subtitle":"MR","description":"Marveal Rabbit 的个人博客网站","author":"Marveal Rabbit","url":"https://rabbit-mar.github.io","root":"/"},"pages":[{"title":"关于","date":"2021-02-19T11:23:35.980Z","updated":"2021-02-19T11:23:35.980Z","comments":false,"path":"about/index.html","permalink":"https://rabbit-mar.github.io/about/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-02-18T07:12:43.192Z","updated":"2021-02-18T07:12:43.192Z","comments":false,"path":"tags/index.html","permalink":"https://rabbit-mar.github.io/tags/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2021-02-18T07:12:43.125Z","updated":"2021-02-18T07:12:43.124Z","comments":false,"path":"/404.html","permalink":"https://rabbit-mar.github.io/404.html","excerpt":"","text":""}],"posts":[{"title":"Kafka官网翻译——设计(上)","slug":"Kafka官网翻译——设计(上)","date":"2021-02-25T09:23:26.000Z","updated":"2021-02-25T09:24:10.780Z","comments":true,"path":"2021/02/25/Kafka官网翻译——设计(上)/","link":"","permalink":"https://rabbit-mar.github.io/2021/02/25/Kafka%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E8%AE%BE%E8%AE%A1(%E4%B8%8A)/","excerpt":"描述","text":"设计4.1 动机我们设计Kafka使其能够作为一个统一的平台，来处理大型公司可能拥有的所有实时数据来源。为此，我们必须考虑一组相当广泛的用例。 它必须具有高吞吐量才能支持大量事件流，例如实时日志聚合。 它将需要优雅处理大量数据积压，以支持从脱机系统定期加载数据。 这也意味着系统将不得不处理低延迟的传递，以处理更多传统的消息传递用例。 我们希望支持对这些提要进行分区，分布式，实时处理，以创建新的派生提要。这激发了我们的分区和消费者模型。 最终，在将流发送到其他数据系统中进行服务的情况下，我们需要保证该系统必须能够在存在机器故障情况下的容错能力。 支持这些用途使我们进行了包含许多独特元素的设计，与传统的消息系统相比，该元素更类似于数据库日志。在以下各节中，我们将概述设计的某些元素。 4.2 持久化不要害怕文件系统！Kafka在很大程度上依赖于文件系统来存储和缓存消息。人们普遍认为“磁盘速度很慢”，这使人们怀疑持久性架构能否提供有竞争力的性能。实际上，磁盘速度和人们期望的速度相比，更快或者更慢都取决于他们的使用。正确设计的磁盘架构通常可以和网络一样快。 有关磁盘性能的关键事实是，过去十年来，硬盘驱动器的吞吐量与磁盘寻道的等待时间有所不同。 结果，在具有六个7200rpm SATA RAID-5阵列的JBOD配置上，线性写入的性能约为600MB / sec，但是随机写入的性能仅为约100k / sec，相差超过6000倍。 这些线性读取和写入是所有使用模式中最可预测的，并且已由操作系统进行了大幅优化。 现代操作系统提供了预读和后写技术，这些技术可以以大块倍数预取数据，并将较小的逻辑写入分组为大型物理写入。 有关此问题的进一步讨论，请参见ACM队列文章。 他们实际上发现，在某些情况下，顺序磁盘访问比随机存储器访问要快！ 为了弥补这种性能差异，现代操作系统在使用主内存进行磁盘缓存方面变得越来越积极。 当回收内存时，现代的操作系统会很乐意将所有可用内存转移到磁盘缓存中，并且对性能的影响很小。 所有磁盘读写都将通过此统一缓存。 如果不使用direct IO，就无法轻易关闭此功能，因此，即使进程维护了数据在进程内高速的缓存，此数据也很可能在OS的pagecache中被复制，将所有数据有效的存储两次。 此外，我们是在JVM之上构建的，花了时间使用Java内存的人都知道两件事： 对象的内存开销非常高，通常使存储数据大小增加一倍（或更大）。 随着堆内数据的增加，Java垃圾收集变得越来越轻而慢。 由于这些因素，使用文件系统和依靠pagecache优于维护内存级缓存或其他架构，通过自动访问所有未使用的内存，我们至少使可用内存增加了一倍，通过存储压缩的字节结构，有可能再增加一倍而不是单个对象。这样做使得在32GB的计算机上可获取最多28-30GB的缓存，并且不会造成GC损失。此外，即使重新启动服务也将保持热缓存，而进程内高速缓存将需要在内存中重建（对于10GB的缓存可能需要10分钟），否则它将需要从冷缓存开始（意味着可能有糟糕的的初始性能）。这也大大简化了代码，因为所有用于维持缓存和文件系统之间一致性的逻辑现在都在OS中，这比一次性读入到进程更有效，更正确。如果您的磁盘支持线性读取，那么预读将在每次读取的磁盘上有效地预先填充有用的数据。 这表明设计非常简单：当空间不足时，不要在内存中维护过多的内存，并且把它全部刷新到文件系统中。而是将其反转。 所有数据都会立即写入文件系统上的持久日志中，而不必刷新到磁盘。 实际上，意味着将数据只传输到内核的pagecache中。 这种以页面缓存为中心的设计风格在此处有关Varnish设计的文章中进行了描述（以及一些自大的技巧）。 常量时间( O (1) )足够了消息系统中使用的持久性数据结构通常是每个消费者队列，具有关联的BTree或其他通用的随机访问数据结构，来维护有关消息的元数据。 BTree是最通用的数据结构，可以在消息系统中支持各种事务性和非事务性语义。但是，它们的代价确实很高：Btree操作为O(log N)。通常认为O(log N)本质上等同于恒定时间，但是对于磁盘操作而言并非如此。一次磁盘搜寻的发生时间为10毫秒，每个磁盘一次只能执行一次搜寻，因此并行性受到限制。因此，即使很少的磁盘搜寻也会导致非常高的开销。由于存储系统将非常快的缓存操作与非常慢的物理磁盘操作混合在一起，因此随着固定缓存的数据增加，观察到的树结构的性能通常是超线性的。将数据加倍会使事情变得比速度慢两倍还要更糟。 直观上讲，持久性队列可以建立在简单的读取上并附加到文件上，这与日志记录解决方案通常是一样的。 这种结构的优点是所有操作均为O(1)，读取不会阻塞写入或彼此阻塞。由于性能与数据大小完全脱钩，因此具有明显的性能优势。一台服务器现在可以充分利用许多便宜的低转速1+ TB SATA驱动器。 尽管它们的寻道性能较差，但这些驱动器有可接受的大容量读写性能，而且价格只有1/3，容量为3倍。 可以访问几乎无限的磁盘空间而不会降低性能，这意味着我们可以提供消息传递系统中通常不具备的某些功能。 例如，在Kafka中，我们可以尝试将消息保留相对较长的时间（例如一周），而不是尝试在消息被使用后立即删除。 正如我们将要描述的那样，这为消费者带来了很大的灵活性。 4.3 效率我们为提高效率付出了巨大的努力。我们的主要用例之一是处理网络活动数据，该数据量非常大：每个页面视图可能会产生数十次写入。此外，我们假设发布的每条消息都至少由一个消费者（通常是许多消费者）读取，因此我们努力使消费尽可能开销小。 我们还从建立和运行许多类似系统的经验中发现，效率是有效的多租户操作的关键。 如果下游基础设施服务由于应用程序使用量的小幅度增加而容易成为瓶颈，那么这种小的更改通常会产生问题。 我们帮助确保应用程序在有负载的情况下先于基础架构进行快速过渡。当尝试运行支持集中式群集上数十个或数百个应用程序的集中式服务时，这尤其重要，因为使用模式的变化几乎每天都会发生。 我们在上一节中讨论了磁盘效率。 一旦消除了不良的磁盘访问模式，这种系统效率低下的常见原因有两个：过多的小IO操作和过多的字节复制。 小IO问题在客户端和服务器之间以及服务器自身的持久性操作中均会发生。 为避免这种情况，我们的协议围绕“消息集”抽象构建，该抽象将消息自然地组合在一起。这允许网络请求将消息组合在一起并分摊网络往返的开销，而不是一次发送单个消息。服务器又将消息块一次性添加到其日志中，而消费者则一次性获取大型线性消息块。 这种简单的优化可以增加数量级的速度。批处理导致更大的网络数据包，更大的顺序磁盘操作，连续的内存块等，所有这些都使Kafka可以将突发的随机消息写入流转换为线性写入流，这些写入流将流向消费者。 另一个低效率是字节复制。在低消息速率下，这不是问题，但是在负载下影响很大。 为避免这种情况，我们采用了标准的二进制消息格式，该格式由生产者，borker和消费者共享（因此，数据块可以在它们之间进行传递而无需修改）。 Broker维护的消息日志本身只是文件目录，每个文件目录都由一系列消息集填充，这些消息集以生产者和消费者使用的相同格式写入磁盘。保持这种通用格式可以优化最重要的操作：持久日志块的网络传输。现代的UNIX操作系统提供了高度优化的代码路径，用于将数据从pagecache传输到socket。 在Linux中，这是通过sendfile系统调用完成的。 要了解sendfile的影响，重要的是了解将数据从文件传输到socket的通用数据路径： 操作系统将数据从磁盘读取到内核空间中的pagecache中 应用程序将数据从内核空间读取到用户空间缓冲区中 应用程序将数据写回到内核空间的socket缓冲区中 操作系统将数据从socket缓冲区复制到通过网络发送的NIC缓冲区 摘自：https://developer.ibm.com/developer/default/articles/j-zerocopy/images/figure1.gif 摘自：https://developer.ibm.com/developer/default/articles/j-zerocopy/images/figure2.gif 这显然是低效的，有四个副本和两个系统调用。使用sendfile，可以通过允许OS将数据从pagecache直接发送到网络来避免这种重新复制。 因此，在此优化路径中，仅需要最终复制到NIC缓冲区。 我们希望一个常见的用例是某个topic的多个消费者。使用上述零拷贝优化，数据将被复制到pagecache中一次，并在每次消费时重复使用，而不是存储在内存中，并在每次读取时复制到用户空间。这允许以接近网络连接限制的速率使用消息。 pagecache和sendfile的这种组合意味着，在大量消费者挂载的Kafka集群上，您将看不到磁盘上的任何读取活动，因为它们将完全从缓存中提供数据。 有关Java中sendfile和零拷贝支持的更多背景信息，请参阅本文。 端到端批量压缩在某些情况下，瓶颈实际上不是CPU或磁盘，而是网络带宽，尤其是对于需要通过广域网在数据中心之间发送消息的数据管道。当然，用户总是可以一次压缩其消息，而无需Kafka的任何支持，但这可能导致非常糟糕的压缩率，因为大量冗余是由于相同类型消息之间的重复（例如， Web日志中的JSON或用户代理或通用字符串值）。有效压缩需要将多个消息压缩在一起，而不是分别压缩每个消息。 Kafka以有效的批处理格式支持此操作。可以将一批消息压缩在一起，然后以这种形式发送到服务器。这批消息将以压缩形式写入，并保持压缩在日志中，并且仅由消费者解压缩。 Kafka支持GZIP，Snappy，LZ4和ZStandard压缩协议。有关压缩的更多详细信息，请参见此处。 4.4 生产者负载均衡生产者直接将数据发送到分区leader的broker上，不需要中间路由层。为了帮助生产者做到这一点，所有Kafka节点都可以在任何给定时间回答关于元数据的请求，这些数据关于哪些服务器处于活动状态以及topic分区的leader在哪里，帮助生产者确定它的请求发送到哪里去。 客户端控制将消息发布到哪个分区。这可以随机执行，实现一种随机的负载均衡，也可以通过某些语义分区来完成。通过用户指定的键来进行分区并使用其散列到分区，我们公开了用于语义分区的接口（如果需要有一个选项可以重写分区函数）。例如，如果选择的键是用户ID，则给定用户的所有数据将发送到同一分区。如果没有这种语义上的分区，在本地的消费者就要对他们的消费进行猜测。这种明确分区的设计，可以在本地的消费者端处理敏感数据。 异步发送批处理是提高效率的主要方式之一，而要启用批处理，Kafka生产者将尝试在内存中累积数据并在单个请求中发出更大的批处理。 批处理可以配置为累积不超过固定数量的消息，并且等待不超过某个固定等待时间限制（例如64k或10 ms）。这可以累积更多的字节来发送，并且服务器上很少进行较大的IO操作。这种增加少量额外的延迟以提高吞吐量的机制是可以权衡的。 有关配置和生产者的api的详细信息，可以在文档的其他地方找到。 4.5 消费者Kafka消费者通过向broker发出“fetch”请求来工作，leader会引导到消费者想要消费的分区上。每个请求消费者指定他在日志文件中的偏移，接收从偏移量开始的一块日志，并从该位置开始接收回日志的一部分。 消费者因此对偏移量具有重要的控制权，并且可以根据需要倒带以重新消费数据。 push vs pull我们考虑的第一个问题是，消费者应该从broker那里拉数据，还是broker应该将数据推送给消费者。在这方面，Kafka遵循了一种更为传统的设计，大多数消息系统都采用这种设计，在这种设计中，数据从生产者推送到broker，消费者从broker拉。某些以日志记录为中心的系统（例如Scribe和Apache Flume）遵循完全不同的基于推送的方式，将数据推送到下游。两种方法都各有利弊。但是，基于推送的系统很难与多样化的消费者打交道，因为broker控制着数据的传输速率。通常，目标是使消费者能够以尽可能最大的速度消费。不幸的是，在推式系统中，这意味着当消费者的消费速度低于生产速度时，消费者往往处理不过来（本质上是拒绝服务攻击）。基于拉的系统具有更好的特性，即消费者稍微落后在可能的情况下可以追赶上来。可以通过某种退避协议来缓解这种情况，消费者可以通过这种退避协议来表明它已不堪重负，但是要想完全利用（但绝不过度利用）消费者的传输速率要困难得多。根据先前以这种方式构建的系统的经验，我们选择了更传统的拉模式。 基于拉模式的另一个优点是，它有助于对发送给消费者的数据进行批处理。 基于推模式必须选择立即发送请求或累积更多数据，稍后在不知道下游消费者是否能够立即处理请求的情况下发送。 如果针对低延迟做了调整，这会导致每次仅发送一条消息，并且数据无论如何传输最终都会被缓冲，这样十分浪费性能。 基于拉模式设计就可以解决这个问题，因为消费者始终将会把所有可用消息拉取到在日志中的当前位置之后（或配置的最大size）。 这样一来，您可以在不获得最佳的批处理性能（没有引入非必要的延迟情况下）。 原生拉模式的不足之处在于，如果broker没有数据，则消费者可能最终会在不断的循环中进行轮询，忙于等待数据到达。 为了避免这种情况，我们在拉取的请求中添加了一些参数，这些参数允许消费者请求阻塞在“长时间轮询”中，直到数据到达为止（也可以选择持续等待，直到有一定量等待被消费的数据，这样是为了确保有较大的传输数据量）。 你可能到想象其他的设计针对端到端的拉取。生产者可以在本地写入本地日志，broker从本地日志中拉取，而消费者则从他们那里拉取日志。经常提出一种类似于“存储转发”的生产者。 但是我们觉得它不适合我们的目标用例，因为有成千上万的生产者。 我们在大规模运行持久性数据系统的经验让我们觉得，涉及许多应用程序的系统中，如果有成千上万个磁盘实际上会使系统变得不可靠，并且操作起来十分困难。 在实践中，我们发现我们可以大规模运行具有强大SLA的管道，不需要生产者的持久性。 消费者的定位令人惊讶的是，跟踪已消耗的内容是消息系统的关键性能点之一。大多数消息系统保留了在broker上消耗了哪些消息的元数据。即，当消息发送给消费者时，broker要么立即在本地记录，要么等待消费者的确认后记录。 这是一个相当直观的选择，实际上对于单台机器服务器，性能如何都不清楚。 由于许多消息系统中用于存储的数据结构扩展性很差，因此这也是一个务实的选择，因为broker知道被消费的内容，因此可以立即删除它，使数据量变小。 可能不注意，使broker和消费者就消费了哪些消息的事情，达成协议并不是一个小问题。如果broker每次在发出网络请求后立马记录消息被消费，那么如果消费者没有消费该消息（例如，网络崩溃或请求超时或其他原因），该消息就丢失了。为了解决这个问题，许多消息系统都添加了确认机制，这意味着消息仅被标记为已发送，发送时不被消费。broker等待消费者的特定确认后，再记录消息的消费情况。这个策略解决了丢失消息的问题，但会带来新的问题。首先，如果消费者消费了该消息但在发送确认之前失败，则该消息将被消费两次。第二个问题是性能，现在的broker必须对每个消息保持多个状态（首先将其锁定，这样就不会再次发出该消息，然后将其标记为永久使用，以便可以将其删除）。必须处理棘手的问题，例如如何处理已发送但从未确认的消息。 Kakfa对这个问题的处理方式有所不同。我们的topic分为一组完全有序的分区，每个分区在给定的时间正好由每个订阅用户组中的一个用户消费。这意味着消费者在每个分区中的位置只是一个整数，即下一个要使用的消息的偏移量。 这样使消费的状态很小，每个分区只有一个数字。可以定期检查该状态。这等同于消息确认的开销很小。 这个处理方式有一个附带好处。 消费者可以有意地倒回到旧的偏移量并重新消费数据。这违反了队列的通用约定，但事实证明这是许多消费者的基本功能。例如，如果消费者代码中有bug，并且发现某些消息被消费了，则消费者可以在错误修复后重新消费这些消息。 离线数据堆积可扩展的持久性可以让消费者定期消费例如批量数据加载，定期批量加载数据到一个离线系统中，诸如Hadoop或关系数据仓库。在Hadoop的情况下，我们通过将加载划分为独立的map任务来并行加载数据，每个节点/主题/分区进行组合，从而实现了完全并行加载。Hadoop提供了任务管理，失败的任务可以重新启动而没有重复数据的危险，它们只是从原始位置重新启动。 静态成员静态成员旨在提高流应用程序，消费者组和其他基于Group Rebalance协议构建的应用程序的可用性。Rebalance协议依赖于组Coordinator将实体ID分配给组成员。这些生成的ID是短暂的，在成员重新启动并重新加入时会更改。对于基于消费者的应用程序，这种“动态成员身份”可以导致在管理操作（例如代码部署，配置更新和定期重新启动）期间将很大一部分任务重新分配给不同的实例。对于大型状态应用程序，经过重排的任务需要很长时间才能恢复其本地状态之后才能处理，并且会导致应用程序部分或全部不可用。 经过这个结果的启发，Kafka的组管理协议允许组成员提供持久的实体ID。 根据这些ID，组成员身份保持不变，因此不会触发Rebalance。 如果你想使用静态成员： 更新broker集群和客户端app到2.3+，并且同时保证更新的broker使用inter.broker.protocol.version2.3+ 在同一个组内，为每一个消费者实例设置ConsumerConfig#GROUP_INSTANCE_ID_CONFIG为唯一的值 对于Kafka Streams应用程序，为每个Kafka Streams实例设置一个唯一的ConsumerConfig#GROUP_INSTANCE_ID_CONFIG就足够了，与实例使用的线程数无关。 如果broker的版本低于2.3，但您仍然选择在客户端上设置ConsumerConfig#GROUP_INSTANCE_ID_CONFIG，则应用程序将检测broker版本，然后引发UnsupportedException。 如果您不小心为不同实例配置重复ID，则broker端的防护机制将通过触发org.apache.kafka.common.errors.FencedInstanceIdException通知您的重复客户端立即关闭。 有关更多详细信息，请参见KIP-345","categories":[],"tags":[]},{"title":"设计模式——单例模式","slug":"设计模式——单例模式","date":"2021-02-24T08:17:16.000Z","updated":"2021-02-24T08:18:59.849Z","comments":true,"path":"2021/02/24/设计模式——单例模式/","link":"","permalink":"https://rabbit-mar.github.io/2021/02/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"介绍设计模式中最简单中的一种——单例模式，具体介绍其实现和破坏单例模式的三种场景，包括使用ThreadLocal实现线程内的单例","text":"单例模式单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意： 1、单例类只能有一个实例。 2、单例类必须自己创建自己的唯一实例。 3、单例类必须给所有其他对象提供这一实例。 单例模式的实现方式任何一种单例模式的实现都有一个特点：私有化构造函数和对象，对外暴露统一方法获取对象。 1. 饿汉模式饿汉式在类加载的时候就立即初始化，并且创建单例对象。 优点：没有加锁，所以执行效率很高，代码简单容易理解 缺点：内存浪费，不管是否使用，对象都已经被创建 123456789public class HungrySingleton &#123; private static final HungrySingleton instance = new HungrySingleton(); private HungrySingleton() &#123;&#125; private static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 或者： 12345678910111213public class HungrySingleton &#123; private static final HungrySingleton instance; static &#123; instance = new HungrySingleton(); &#125; private HungrySingleton() &#123;&#125; public static HungrySingleton getInstance() &#123; return instance; &#125;&#125; 2. 懒汉模式懒汉式在被外部调用时才回创建对象，再次调用时获取第一次创建的对象 如果使用下面这种方式，存在着线程不安全的问题，当两个线程都执行到instance == null的时候，由于还没有创建对象，都进入到了if的代码块中，但是创建多个对象： 12345678910111213public class LazySimpleSingleton &#123; private static LazySimpleSingleton instance = null; private LazySimpleSingleton() &#123; &#125; public static LazySimpleSingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySimpleSingleton(); &#125; return instance; &#125;&#125; 如果使用 synchronized 包裹 getInstance()方法时，会出现锁力度过大的问题，于是在双重检测模式中进行解决： 12345678910111213public class LazySimpleSingleton &#123; private static LazySimpleSingleton instance = null; private LazySimpleSingleton() &#123; &#125; public static synchronized LazySimpleSingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySimpleSingleton(); &#125; return instance; &#125;&#125; 3. 双重检测模式双重检测模式也称为DCL(double check locking)，即两次判断instance == null。 代码如下： 12345678910111213141516public class LazyDoubleCheckSingleton &#123; // 使用volatile禁用指令重排序，如果不使用volatile会有可能产生指令重排，导致破坏单例的情况发生 private static volatile LazyDoubleCheckSingleton instance = null; private LazyDoubleCheckSingleton()&#123;&#125; public static LazyDoubleCheckSingleton getInstance() &#123; if (instance == null) &#123; synchronized (LazyDoubleCheckSingleton.class) &#123; if (instance == null) &#123; instance = new LazyDoubleCheckSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 4. 内部类模式由于使用synchronized关键字总是在使用锁资源，对系统性能都有一定的影响，于是产生了内部类的方式。 这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟饿汉式不同的是：饿汉式只要 HungrySingleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 LazyInnerClassSingleton 类被装载了，instance 不一定被初始化。因为 LazyHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 LazyHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 LazyHolder 类加载时就实例化，因为不能确保 LazyInnerClassSingleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比饿汉式就显得很合理。 123456789101112public class LazyInnerClassSingleton &#123; private LazyInnerClassSingleton() &#123;&#125; public static LazyInnerClassSingleton getInstance() &#123; return LazyHolder.LAZY; &#125; private static class LazyHolder &#123; private static final LazyInnerClassSingleton LAZY = new LazyInnerClassSingleton(); &#125;&#125; 注册式的单例模式注册式单例模式又称为登记式单例模式，就是将每一个实例都登记到某一个地方，使用唯一的标识获取实例。注册式单例模式有两种，一种为枚举式单例模式，另一种为容器式单例模式。 1. 枚举式单例模式枚举式单例模式也是 Effective Java 书中推荐的一种单例模式实现写法。JDK 枚举的语法特殊性及反射也为枚举保驾护航，让枚举式单例模式成为一种比较优雅的实现。同时在下文中也会提到，枚举类的实现方式会避免对单例模式的破坏。 123456789public enum EnumSingleton &#123; INSTANCE; private Object data; public Object getData() &#123; return data; &#125; public void setData(Object data)&#123; this.data = data; &#125; public static EnumSingleton getInstance() &#123; return EnumSingleton.INSTANCE; &#125;&#125; 2. 容器式单例模式容器式单例模式适用于实例非常多的情况，便于管理，但它是非线程安全的。 12345678910111213141516171819public class ContainerSingleton &#123; private static final Map&lt;String, Object&gt; ioc = new ConcurrentHashMap&lt;&gt;(16); private ContainerSingleton() &#123;&#125; public static Object getBean(String className) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; synchronized (ioc) &#123; if (ioc.containsKey(className)) &#123; return ioc.get(className); &#125; final Class&lt;?&gt; clazz = Class.forName(className); final Constructor&lt;?&gt; constructor = clazz.getDeclaredConstructor(null); constructor.setAccessible(true); Object obj = constructor.newInstance(); ioc.put(className, obj); return obj; &#125; &#125;&#125; 破坏单例模式的场景1. 反射破坏单例123456789101112131415/** * 反射破坏单例模式 */class LazyInnerClassSingletonTest &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; Class&lt;?&gt; clazz = LazyInnerClassSingleton.class; final Constructor&lt;?&gt; constructor = clazz.getDeclaredConstructor(null); constructor.setAccessible(true); final Object obj1 = constructor.newInstance(); final Object obj2 = constructor.newInstance(); System.out.println(obj1); System.out.println(obj2); &#125;&#125; 在代码中可以发现使用反射的方式获取LazyInnerClassSingleton类，调用其 newInstance()方法，相当于调用了两次new，于是破坏了单例模式。 如果避免这种情况发生呢？在空构造函数中对instance进行判断，如果 instance != null，就抛出错误 12345678910111213141516public class LazyInnerClassSingleton &#123; private LazyInnerClassSingleton() &#123; // 防止反射破坏单例模式 if (LazyHolder.LAZY != null) &#123; throw new RuntimeException(&quot;不允许创建多个实例&quot;); &#125; &#125; public static LazyInnerClassSingleton getInstance() &#123; return LazyHolder.LAZY; &#125; private static class LazyHolder &#123; private static final LazyInnerClassSingleton LAZY = new LazyInnerClassSingleton(); &#125;&#125; 2. 序列化破坏单例一个单例对象创建好后，有时候需要将对象序列化然后写入磁盘，下次使用时再从磁盘中读取对象并进行反序列化，将其转化为内存对象。反序列化后的对象会重新分配内存，即重新创建。如果序列化的目标对象为单例对象，就违背了单例模式的初衷，相当于破坏了单例。 123456789101112131415161718192021class SerializableSingletonTest &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; SerializableSingleton s1 = null; SerializableSingleton s2 = SerializableSingleton.getInstance(); FileOutputStream fos = new FileOutputStream(&quot;SerializableSingleton.obj&quot;); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(s2); oos.flush(); fos.flush(); FileInputStream fis = new FileInputStream(&quot;SerializableSingleton.obj&quot;); ObjectInputStream ois = new ObjectInputStream(fis); s1 = (SerializableSingleton) ois.readObject(); ois.close(); fis.close(); System.out.println(s1); System.out.println(s2); &#125;&#125; 执行这段代码会发现两个输出对象不为同一个，那么解决办法就是在SerializableSingleton类中添加readResolve()方法 1234567891011121314151617public class SerializableSingleton implements Serializable &#123; private static final long serialVersionUID = 7060213510364627603L; private static final SerializableSingleton instance = new SerializableSingleton(); private SerializableSingleton() &#123;&#125; public static SerializableSingleton getInstance() &#123; return instance; &#125; // 解决反序列化破坏单例模式 // 实际上序列化了两次，只是新创建的对象没有被返回 private Object readResolve() &#123; return instance; &#125;&#125; 原因： java.io.ObjectInputStream#readObject() -&gt; java.io.ObjectInputStream#readObject(java.lang.Class&lt;?&gt;) -&gt; java.io.ObjectInputStream#readObject0(java.lang.Class&lt;?&gt;, boolean) 123case TC_OBJECT: ... return checkResolve(readOrdinaryObject(unshared)); -&gt; java.io.ObjectInputStream#readOrdinaryObject(boolean) -&gt; java.io.ObjectStreamClass#isInstantiable() 判断一下构造方法是否为空，构造方法不为空就返回 true。这意味着只要有无参构造方法就会实例化 还没有找到加上 readResolve()方法就避免单例模式被破坏的真正原因。再回到ObjectInputStream的readOrdinaryObject()方法 1234567if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod())&#123; Object rep = desc.invokeReadResolve(obj); ...&#125; 上述代码判断 readResolveMethod 是否为空， 不为空就返回 true。那么readResolveMethod 是在哪里赋值的呢?通过全局查找知道，在私有方法 ObjectStreamClass()中给readResolveMethod 进行了赋值 -&gt; java.io.ObjectStreamClass#ObjectStreamClass(java.lang.Class&lt;?&gt;) 12readResolveMethod = getInheritableMethod( cl, &quot;readResolve&quot;, null, Object.class); 至此，只要有readResolve()方法，就会执行这个方法，从而直接返回这个值。但是可以方法，该解决方案只是将readResolve()方法的返回值返回，本质上还是初始化了两次。如果创建对象的频率加快，内存的开销也会变大。 3. 深拷贝破坏单例12345678class HungrySingletonTest &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; final HungrySingleton s1 = HungrySingleton.getInstance(); final HungrySingleton s2 = (HungrySingleton) s1.clone(); System.out.println(s1); System.out.println(s2); &#125;&#125; 由于深拷贝会为新对象重新分配内存，从而导致破坏单例模式，那么解决方案就是：1. 禁止深拷贝；2. 不实现Cloneable接口；3. 在clone方法中返回单例对象 1234@Overrideprotected Object clone() throws CloneNotSupportedException &#123; return instance;&#125; 线程单例实现ThreadLocal使用线程内的ThreadLocal实现线程内的单例模式，ThreadLocal不能保证其创建的对象是全局唯一的，但是能保证在单个线 程中是唯一的，天生是线程安全的。 12345678910public class ThreadLocalSingleton &#123; private static final ThreadLocal&lt;ThreadLocalSingleton&gt; threadLocalInstance = ThreadLocal.withInitial(ThreadLocalSingleton::new); private ThreadLocalSingleton() &#123;&#125; public static ThreadLocalSingleton getInstance() &#123; return threadLocalInstance.get(); &#125;&#125; 单例模式为了达到线程安全的目 的，会给方法上锁，以时间换空间。ThreadLocal 将所有的对象全部放 在ThreadLocalMap中，为每个线程都提供一个对象，实际上是以空间换 时间来实现线程隔离的。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://rabbit-mar.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Kafka官网翻译——API","slug":"Kafka官网翻译——API","date":"2021-02-20T06:06:43.000Z","updated":"2021-02-20T06:37:28.977Z","comments":true,"path":"2021/02/20/Kafka官网翻译——API/","link":"","permalink":"https://rabbit-mar.github.io/2021/02/20/Kafka%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94API/","excerpt":"Kafka官网翻译，对应版本为2.7.x，网址：https://kafka.apache.org/27/documentation.html#api","text":"APIsKafka有五个核心api： Producer API允许应用程序将数据流发送到Kafka集群中的topics。 Consumer API允许应用程序从Kafka集群中的topic读取数据流。 Streams API允许将数据流从输入topic转换为输出topic。 Connect API允许实现连接器，这些连接器不断地从一些源系统或应用程序拉入到Kafka，或从Kafka推入到一些下游数据系统或应用程序。 Admin API允许管理和检查topic，broker和其他Kafka对象。 Kafka通过与语言无关的协议公开其所有功能，该协议具有可用于多种编程语言的客户端。 但是，只有Java客户端是作为Kafka主项目的一部分维护的，其他Java客户端则可以作为独立的开源项目使用。 非Java客户端列表在此处提供。 2.1 Producer APIProducer API允许应用程序将数据流发送到Kafka集群中的topics。 使用生产者的事例在javadocs中给出 使用生产者api，需要添加以下maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 2.2 Consumer APIConsumer API允许应用程序从Kafka集群中的topic读取数据流。 使用消费者的事例在javadocs中给出 使用消费者api，需要添加以下maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 2.3 Streams APIStreams API允许将数据流从输入topic转换为输出topic。 使用库的事例在javadocs中给出 使用streams api的额外文档在这里 使用streams api，需要添加以下maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 如果需要使用Scala需要添加 kafka-streams-scala 库，使用Kafka Streams DSL的Scala文档在开发者文档中 如果使用Scala2.13的Kafka Streams DSL，需要添加一下依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams-scala_2.13&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 2.4 Connect APIConnect API允许实现连接器，这些连接器不断地从一些源系统或应用程序拉入到Kafka，或从Kafka推入到一些下游数据系统或应用程序。 很多的连接用户不需要直接使用这些api，他们使用这些预编译的连接器不需要编写代码，使用连接器的额外信息在文档的连接器部分 如何实现自定义的连接器可以看javadoc 2.5 Admin APIAdmin API允许管理和检查topic，broker，acl和其他Kafka对象。 关于更多的admin apis信息，查看javadoc 使用admin api，需要添加以下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://rabbit-mar.github.io/tags/Kafka/"}]},{"title":"Kafka官网翻译——起步","slug":"Kafka官网翻译——起步","date":"2021-02-19T03:18:08.000Z","updated":"2021-02-19T09:02:57.360Z","comments":true,"path":"2021/02/19/Kafka官网翻译——起步/","link":"","permalink":"https://rabbit-mar.github.io/2021/02/19/Kafka%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E8%B5%B7%E6%AD%A5/","excerpt":"Kafka官网翻译，对应版本为2.7.x，网址：https://kafka.apache.org/27/documentation.html#gettingStarted","text":"1. 起步1.1 介绍什么是事件流事件流是人体中枢神经系统的数字等效形式。 它是“永远在线”世界的技术基础，在这个世界中，业务越来越多地由软件定义和自动化，并且软件的用户越来越多。 从技术上讲，事件流是一种以事件流的形式从事件源（例如数据库，传感器，移动设备，云服务和软件应用程序）实时捕获数据的实践。 持久存储这些事件流以供以后检索； 实时以及回顾性地处理，处理和响应事件流； 并根据需要将事件流路由到不同的目标技术。 事件流因此确保了数据的连续流和解释，以便正确的信息在正确的时间，正确的位置。 事件流能做什么事件流适用于众多行业和组织的各种用例。 它的许多示例包括： 实时处理付款和金融交易，例如在证券交易所，银行和保险中。 实时跟踪和监视汽车，卡车，车队和货运，例如在物流和汽车行业。 连续捕获和分析来自IoT设备或其他设备（例如工厂和风电场）中的传感器数据。 收集并立即响应客户的交互和订单，例如在零售，酒店和旅游行业以及移动应用程序中。 监测患者的医院护理情况并预测病情变化，以确保在紧急情况下及时得到治疗。 连接，存储和提供公司不同部门产生的数据。 用作数据平台，事件驱动的体系结构和微服务的基础。 Kafka是一个事件流平台，有什么含义Kafka结合了三个关键功能，因此您可以使用一个经过战斗验证的解决方案来端到端实施事件流的用例： 发布（写入）和订阅（读取）事件流，包括从其他系统连续导入/导出数据。 根据需要持久而可靠地存储事件流。 处理事件流的发生或追溯。 所有这些功能都以分布式，高度可扩展，弹性，容错和安全的方式提供。 Kafka可以部署在裸机硬件，虚拟机和容器，本地以及云中。 您可以在自我管理Kafka环境与使用各种供应商提供的完全托管服务之间进行选择。 概括说Kafka的工作Kafka是一个分布式系统，由通过高性能TCP网络协议进行通信的服务器和客户端组成。它可以部署在内部以及云环境中的裸机硬件，虚拟机和容器上。 服务器：Kafka作为一个或多个服务器的集群运行，可以跨越多个数据中心或云区域。其中一些服务器构成了存储层，称为代理。其他服务器运行Kafka Connect来连续导入和导出数据作为事件流，以将Kafka与现有系统集成在一起，例如关系数据库以及其他Kafka群集。为了实现关键任务用例，Kafka群集具有高度的可扩展性和容错能力：如果其任何服务器发生故障，其他服务器将接管其工作，以确保连续运行而不会丢失任何数据。 客户端：它们使您可以编写分布式应用程序和微服务，即使在网络问题或机器故障的情况下，它们也可以并行，大规模且以容错的方式读取，写入和处理事件流。 Kafka附带了一些这样的客户端，由Kafka社区提供的数十个客户端进行了扩充：客户端可用于Java和Scala，包括更高级的Kafka Streams库，Go，Python，C / C ++和许多其他编程语言以及REST API。 主要概念和术语Events记录了世界中或你的业务中“发生了什么事”的事实。在文档中也称为记录或消息。 当您向Kafka读取或写入数据时，您将以event的形式进行操作。 从概念上讲，event具有键，值，时间戳和可选的元数据标题。 这是一个示例事件： Event key: “Alice” Event value: “Made a payment of $200 to Bob” Event timestamp: “Jun. 25, 2020 at 2:06 p.m.” 生产者是那些向Kafka发布（写入）事件的客户端应用程序，而消费者是那些订阅（读取和处理）这些事件的客户端应用程序。 在Kafka中，生产者和消费者之间完全脱钩且彼此不可知，这是实现Kafka众所周知的高可伸缩性的关键设计元素。 例如，生产者永远不需要等待消费者。 Kafka提供各种保证，例如能够一次准确地处理事件。 Events被组织并持久地存储在Topics中。 非常简化，Topic类似于文件系统中的文件夹，Event是该文件夹中的文件。 例如topic名可以是“payments”。 Kafka中的topic始终是多生产者和多消费者：一个topic可以有零个，一个或多个向其写入event的生产者，以及零个，一个或多个订阅这些event的消费者。 可以根据需要随时读取topic中的event，与传统的消息中间件不同，消费过的事件不会被删除。 相反，您可以通过按topic配置的设置，来定义Kafka将event保留多长时间，之后旧的event将被丢弃。 Kafka的性能相对于数据大小实际上是恒定的，因此长时间存储数据是完全可以的。 Topics是被分区的，这意味着topic分布在不同Kafka Brokers上的多个“buckets”中。数据的这种分布式放置对于可伸缩性非常重要，因为它允许客户端应用程序可以同时从多个Borker中读取数据，或者向多个Broker写入数据。当发布一个新event到topic时，实际上它会将其追加到其中一个topic分区。具有相同event key（例如，一个顾客或车辆ID）的事件将写入到同一分区，并且Kafka保证，单个给定topic分区的任何消费者都将始终以与写入时完全相同的顺序读取该分区的事件。 图：该示例topic具有四个分区P1-P4。两个不同的生产者通过网络彼此独立地发布新事件，写入到topic分区。 具有相同key（在图中由颜色表示）的事件被写入同一分区。注意，如果需要，两个生产者可以写入同一分区。 为了使您的数据具有容错性和高可用性，可以在每个地理区域或数据中心之间备份每个topic，以便始终有多个broker具有数据副本，防止万一出错或者对brokers进行维护等等。 常见的生产设置是三个备份实例，即，您的数据将保持有三个副本。备份级别为topic分区。 该入门指南应该足够。 如果您有兴趣，文档的“设计”部分将详细介绍Kafka的各种概念。 Kafka APIs除了用于管理和管理任务的命令行工具外，Kafka还具有用于Java和Scala的五个核心API： Admin API，用于管理和检查topics，brokers和其他Kafka对象。 Producer API，用于将事件流发布（写入）到一个或多个Kafka topics。 Consumer API，订阅（读取）一个或多个topics并处理为其产生的事件流。 Kafka Streams API，用于实现流处理应用程序和微服务。它提供了更高级别的功能来处理事件流，包括转换，诸如聚合和联接之类的状态操作，窗口，基于事件时间的处理等等。从一个或多个topics读取输入，以便生成一个或多个topic的输出，从而有效地将输入流转换为输出流。 Kafka Connect API，可以构建和运行可重用的数据导入/导出连接器，这些连接器从外部系统和应用程序消费（读取）或生产（写入）事件流，以便它们可以与Kafka集成。例如，需要一个连接到关系型数据库（如PostgreSQL）的连接器，捕获数据库所有的更改到一组表中。然而，实际上，您通常不需要实现自己的连接器，因为Kafka社区已经提供了数百个随时可用的连接器。 从这到哪去 要获得有关Kafka的动手经验，请遵循快速入门。 要更详细地了解Kafka，请阅读文档。 您还可以选择Kafka的书籍和学术论文。 浏览用例，了解我们全球社区中的其他用户如何从Kafka中获得价值。 加入一个当地的Kafka聚会小组，观看Kafka峰会的演讲，Kafka社区主要会议。 1.2 使用案例这是对Apache Kafka®的一些流行用例的描述。有关这些领域的概述，请参阅此博客文章。 消息Kafka可以很好地替代传统消息中间件。消息中间件的使用有多种原因（从数据生产者中分离处理，缓冲未处理的消息等）。与大多数消息系统相比，Kafka具有更好的吞吐量，内置的分区，备份和容错能力，这使其成为大规模消息处理应用程序的理想解决方案。根据我们的经验，消息传递的使用通常吞吐量较低，但是可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的持久性保证。 在此领域中，Kafka可与传统消息系统例如如ActiveMQ或RabbitMQ相媲美。 网站活动跟踪Kafka最初的用意是能够重建一个用户活动跟踪管道，作为一组实时的发布/订阅来源。 这意味着将网站活动（页面浏览，搜索或用户可能采取的其他操作）发布到中心主题，每种活动类型只有一个主题。 这些消息来源可用于一系列用例的订阅，包括实时处理，实时监控，以及加载到Hadoop或离线数据仓库系统中，进行离线处理和报告。活动跟踪通常量很大，因为每个用户页面视图都会生成许多活动消息。 指标Kafka通常用于操作监控数据。 这涉及到聚合来自分布式应用程序的统计信息，生成集中的操作数据提要。 日志汇总许多人使用Kafka代替日志聚合解决方案。日志聚合通常从服务器上收集物理日志文件，并将它们放在数据中心（例如文件服务器或HDFS）以进行处理。 Kafka抽取文件的详细信息，并提供一个更清晰的日志抽象数据或者事件数据作为消息流。 它提供了较低延迟的处理，并更容易的支持多个数据源和分布式数据消耗。 与以日志为中心的系统（例如Scribe或Flume）相比，Kafka具有同样出色的性能，由于备份提供了更强的耐用性保证，以及更低的端到端延迟。 流处理Kafka的许多用户在由多个阶段组成的处理管道中处理数据，其中原始输入数据从Kafka的topic中消费，然后进行汇总，增强或以其他方式转换为新topic，以供进一步使用或后续处理。 例如，用于推荐新闻文章的处理管道可能会从RSS来源中检索文章内容，并将其发布到“articles”主题中。 进一步的处理可能会使该内容规范化或者删除重复数据，并将清洗后的文章内容发布到新topic中；最后的处理阶段可能会向用户推荐此内容。 这样的处理管道基于单一的topic创建实时数据流图。 从0.10.0.0开始，Apache Kafka中提供了一个轻量但功能强大的流处理库，称为Kafka Streams，可以执行上述数据处理。 除了Kafka Streams，其他开源流处理工具还包括Apache Storm和Apache Samza。 事件源事件源是应用程序设计的一种样式，其中状态的更改用时间顺序的记录序列记录下来。Kafka对大量日志数据堆积的支持使它成为以这种方式构建应用程序的绝佳后端。 提交日志Kafka可以用作分布式系统的一种外部提交日志。 该日志有助于在节点之间备份数据，并充当故障节点恢复其数据的重新同步机制。 Kafka中的日志压缩功能有助于支持此用法。 在这种用法中，Kafka类似于Apache BookKeeper项目。 1.3 快速开始步骤一：获取Kafka下载最近的kafka发行版并且解压 123$ curl -O https://downloads.apache.org/kafka/2.7.0/kafka_2.13-2.7.0.tgz$ tar -xzf kafka_2.13-2.7.0.tgz$ cd kafka_2.13-2.7.0 步骤二：开始Kafka环境备注: 你本地环境必须安装Java 8+ 按照正确的顺序启动服务，执行以下命令 123# Start the ZooKeeper service# Note: Soon, ZooKeeper will no longer be required by Apache Kafka.$ bin/zookeeper-server-start.sh config/zookeeper.properties 打开另一个终端然后执行： 12# Start the Kafka broker service$ bin/kafka-server-start.sh config/server.properties 一旦所有的服务都成功启动，kafka基本运行环境已经启动 步骤三：创建一个topic存储eventKafka是一个分布式事件流平台，可让您跨多台机器读取，写入，存储和处理事件（在文档中也称为record或message）。 示例事件包括付款交易，移动电话的地理位置更新，运输订单，物联网设备或医疗设备的传感器测量等等。 这些事件被组织并存储在topic中。 非常简单，topic类似于文件系统中的文件夹，event是该文件夹中的文件。 因此，在编写第一个event之前，必须创建一个topic。 打开另一个终端并执行： 1$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092 Kafka的所有命令行工具都有其他选项：不带任何参数的kafka-topics.sh命令以显示使用情况信息。 例如，它还可以向您显示详细信息，例如topic的分区数： 123$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092Topic:quickstart-events PartitionCount:1 ReplicationFactor:1 Configs: Topic: quickstart-events Partition: 0 Leader: 0 Replicas: 0 Isr: 0 步骤四：写入事件到topic中Kafka客户端通过网络与Kafka broker进行通信，编写（或读取）事件。 一旦收到，broker将以持久和容错的方式存储事件，如果您需要，甚至可以永久存储。 运行控制台生产者客户端，将一些event写入您的topic。 默认情况下，您输入的每一行都会产生一个单独的事件写入该topic。 123$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092This is my first eventThis is my second event 你可以随时使用 Ctrl+C 停止生产者客户端 步骤五：读取事件打开另一个终端，执行终端消费者客户端去读取你创建的事件 123$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092This is my first eventThis is my second event 你可以随时使用 Ctrl+C 停止消费者客户端 随时尝试：例如，切换回生产者终端（上一步）编写其他event，并查看event如何立即在您的消费者终端中显示。 因为事件被持久地存储在Kafka中，所以您可以根据需要任意多次地读取它们。您可以通过打开另一个终端会话并再次重新运行上一个命令来验证。 步骤六：使用Kafka连接像事件流一样导入/导出数据在诸如关系数据库或传统消息系统之类的现有系统中，您可能拥有大量数据，以及已经使用这些系统的许多应用程序。 通过Kafka Connect，您可以将来自外部系统的数据连续地吸收到Kafka中，反之亦然。因此，将现有系统与Kafka集成非常容易。为了使此过程更加容易，Kafka有数百种此类连接器可供使用。 看一下Kafka Connect部分，了解更多有关如何连续将数据导入和导出Kafka的信息。 步骤七：使用Kafka流处理事件一旦将数据作为事件存储在Kafka中，就可以使用Java / Scala的Kafka Streams客户端库处理数据。 它允许您实现关键任务实时应用程序和微服务，其中输入 和/或 输出数据存储在Kafka主题中。Kafka Streams结合了在客户端编写和部署标准Java和Scala应用程序的简便性以及Kafka服务器端集群技术的优势，使这些应用程序具有高度可伸缩性，弹性，容错性和分布式性。该库支持一次精确处理，有状态操作和聚合，窗口化，联接，基于事件时间的处理等等。 为了让您有一个初步的了解，以下是实现流行的WordCount算法的方法： 12345678KStream&lt;String, String&gt; textLines = builder.stream(&quot;quickstart-events&quot;);KTable&lt;String, Long&gt; wordCounts = textLines .flatMapValues(line -&gt; Arrays.asList(line.toLowerCase().split(&quot; &quot;))) .groupBy((keyIgnored, word) -&gt; word) .count();wordCounts.toStream().to(&quot;output-topic&quot;), Produced.with(Serdes.String(), Serdes.Long())); Kafka Streams 案例和应用程序开发教程演示了如何从头到尾编写和运行这种流式应用程序。 步骤八：终止Kafka环境既然您已开始快速入门，可以随时终止Kafka环境或继续练习。 如果尚未停止，请使用Ctrl-C停止生产者和消费者客户端。使用Ctrl-C停止Kafka Broker。最后，使用Ctrl-C停止ZooKeeper服务器。如果您还想删除本地Kafka环境的任何数据，包括您在此过程中创建的所有event，请运行以下命令： 1$ rm -rf /tmp/kafka-logs /tmp/zookeeper 恭喜！您已成功完成Apache Kafka快速入门。 要了解更多信息，我们建议执行以下后续步骤： 通读简短的简介，以了解Kafka的工作原理，主要概念以及与其他技术的比较。 要更详细地了解Kafka，请转至文档。 浏览用例，了解我们全球社区中的其他用户如何从Kafka中获得价值。 加入当地的Kafka聚会小组，观看Kafka社区主要会议，Kafka峰会的演讲。 1.4 生态在主发行版之外，有很多与Kafka集成的工具。生态页面列出了许多此类资源，包括流处理系统，Hadoop集成，监视和部署工具。","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://rabbit-mar.github.io/tags/Kafka/"}]},{"title":"分库分表之sharding-jdbc&mycat","slug":"分库分表之sharding-jdbc&mycat","date":"2020-12-22T20:00:08.000Z","updated":"2021-02-18T15:07:06.013Z","comments":true,"path":"2020/12/23/分库分表之sharding-jdbc&mycat/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/23/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B9%8Bsharding-jdbc&mycat/","excerpt":"分库分表介绍，并使用sharding-jdbc和mycat","text":"分库分表互联网大数据时代，如何解决数据库性能瓶颈 读多写少的情况，采用读写分离 海量数据的情况，采用数据切分 数据切分方式一：垂直切分 按照业务切分 每种业务一个数据库 不同业务之间，禁止跨库join联查 优点： 拆分后业务清晰，拆分规则明确； 系统之间容易扩展和整合 数据维护简单 缺点： 部分业务表无法join，只能通过接口调用，提升了系统的复杂度 跨库事务难以处理 垂直切分后，某些业务数据过于庞大，仍然存在单体性瓶颈 数据切分方式二：水平切分 将一张表的数据按照某种规则分到不同的数据库中 需确定分片的规则 使用分片字段查询时，可确定实体库，其他字段查询，查询所有表 优点： 解决了单库大数据、高并发的性能瓶颈 拆分规则封装好，对应用端几乎透明，开发人员无需关心拆分细节 提高了系统的稳定性和负载能力 缺点： 拆分规则很难抽象 分片事务一致性难以解决 二次扩展时，数据迁移大、维护难度大 先垂直切分，再水平切分 实现读写分离和数据切分的两种方式 模式一：中间层代理（MyCat） 模式二：客户端模式（Sharding-jdbc） MyCat环境搭建 mycat服务器： 192.168.1.2 mysql服务器： 192.168.1.7；192.168.1.8 MySQL安装官网：https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html#yum-repo-installing-mysql mycat安装官网：http://dl.mycat.org.cn/ 用户配置server.xml配置 配置MyCat的用户名、密码、权限、Schema等； 如同给MySQL新建用户一样 客户端连接MyCat与连接MySQL相同 123456789101112&lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; ... &lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;&#123;password&#125;&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;&#123;schema_name&#125;&lt;/property&gt; &lt;/user&gt; &lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;&#123;schema_name&#125;&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; schema.xml配置 配置dataHost(节点主机)，包括读host、写host 配置dataNode(数据节点)，指定到具体的数据库 配置schema，表名、数据节点、分片规则等 12345678910111213141516171819202122232425262728293031&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;!-- checkSQLschema：是否去掉sql中的schema sqlMaxLimit：select默认的limit值，仅对分片表有效 --&gt; &lt;schema name=&quot;&#123;schema_name&#125;&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!--table：定义表 name:定义逻辑表的表名 dataNode: 定义逻辑表的数据节点 rule:定义分片表的分片规则，必须与rule.xml中的tableRule对应 ruleRequired：是否绑定分片规则，如果是true，没有绑定分片规则，程序报错 --&gt; &lt;table name=&quot;&#123;table_name&#125;&quot; dataNode=&quot;&#123;data_node_01&#125;,&#123;data_node_02&#125;&quot; rule=&quot;auto-sharding-long&quot; /&gt; &lt;/schema&gt; &lt;dataNode name=&quot;&#123;data_node_01&#125;&quot; dataHost=&quot;&#123;data_host_01&#125;&quot; database=&quot;&#123;database_01&#125;&quot; /&gt; &lt;dataNode name=&quot;&#123;data_node_02&#125;&quot; dataHost=&quot;&#123;data_host_02&#125;&quot; database=&quot;&#123;database_02&#125;&quot; /&gt; &lt;!-- balance: 负载均衡类型：0 不开启读写分离； 1和2读写均匀分配；3 读落在readHost上 writeType： 写请求类型：0 落在第一个writeHost上；1 随机； --&gt; &lt;dataHost name=&quot;&#123;data_host_01&#125;&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;&#123;host_name&#125;&quot; url=&quot;&#123;mysql_ip:port&#125;&quot; user=&quot;&#123;mysql_username&#125;&quot; password=&quot;&#123;mysql_password&#125;&quot; /&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;&#123;data_host_02&#125;&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;&#123;host_name&#125;&quot; url=&quot;&#123;mysql_ip:port&#125;&quot; user=&quot;&#123;mysql_username&#125;&quot; password=&quot;&#123;mysql_password&#125;&quot; /&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 全局表mysql中存在着地址，省份之类的数据，不需要进行进行切分操作，就称为全局表。全局表在每一个数据库中都存在一份，每个库中的数据都相同，这样保证了在join的时候只需要join本库的数据就可以了 123456&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;&#123;schema_name&#125;&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- type: 指定为全局表--&gt; &lt;table name=&quot;&#123;table_name&#125;&quot; dataNode=&quot;&#123;data_node_01&#125;,&#123;data_node_02&#125;&quot; type=&quot;global&quot; /&gt; &lt;/schema&gt;&lt;/mycat:schema&gt; 子表举个例子，项目中存在着订单表，订单表中对应着购买的商品信息表，做一个关联，如果订单表中对应的商品信息不在同一个库中，会存在着跨库的问题，所以商品信息表称为子表。 childTable标签，定义分片子表 name属性，子表名称 joinKey属性，标志 子表中的列，用于与父表做关联 parentKey标签，标志父表中的列，与joinKey对应 primaryKey属性，子表主键，同table标签 needAddLimit属性，同table标签 1234567&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;&#123;schema_name&#125;&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;&#123;order_table_name&#125;&quot; dataNode=&quot;&#123;data_node_01&#125;,&#123;data_node_02&#125;&quot; rule=&quot;auto-sharding-long&quot;&gt; &lt;childTable name=&quot;&#123;order_item_table_name&#125;&quot; joinKey=&quot;&#123;order_join_id&#125;&quot; parentKey=&quot;&#123;order_primary_id&#125;&quot; /&gt; &lt;/table&gt; &lt;/schema&gt;&lt;/mycat:schema&gt; 重新加载配置 连接mycat:9066管理端口 在命令行中输入 show @@help; 命令，查看帮助命令 reload @@config; 重新加载配置文件 如果修改数据源配置，使用 reload @@config_all; 命令 MyCat的HA使用keepalived+haproxy进行负载均衡 配置HAproxy 下载haproxy 1yum install -y haproxy 编辑haproxy配置文件 1vim /etc/haproxy/haproxy.cfg 修改以下配置 123456defaults mode tcpbackend app balance roundrobin server app1 &lt;mycat_ip1:8066&gt; check server app2 &lt;mycat_ip2:8066&gt; check 启动haproxy 1haproxy -f /etc/haproxy/haproxy.cfg 下载keepalived 1yum install -y keepalived 安装killall，用于keepalived的脚本执行 1yum install psmisc -y 编辑配置文件 /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041global_defs &#123; router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_script chk_haproxy &#123; script &quot;killall -0 haproxy&quot; interval 2&#125;vrrp_instance VI_1 &#123; state MASTER # 备机为BACKUP interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; &lt;vip&gt; &#125; track_script &#123; chk_haproxy &#125;&#125;virtual_server &lt;vip&gt; &lt;port&gt; &#123; delay_loop 6 lb_algo rr lb_kind NAT persistence_timeout 50 protocol TCP real_server &lt;haproxy-ip&gt; &lt;port&gt; &#123; weight 1 &#125;&#125; MySQL搭建主从 主库编辑my.cnf文件，然后重启主库服务器 12log-bin=&lt;bin_log_file_name&gt;server-id=1 从库编辑my.cnf文件，然后重启从库服务器 1server-id=2 在主库中创建一个从库用户 1create user &#x27;repl&#x27;@&#x27;%&#x27; identified by &#x27;&lt;slave_password&gt;&#x27;; 给从库用户授权 1grant replication slave on *.* to &#x27;repl&#x27;@&#x27;%&#x27;; 主库刷新权限 1flush privileges; 锁定主库 1flush tables with read lock; 读取主库bin-log状态 1show master status; 使用复制会话的方式新打开窗口，备份主库数据，在MySQL命令行外执行 1mysqldump --all-databases --master-data &gt; dbdump.db -uroot -p&lt;mysql_password&gt; 拷贝主库dump文件到从库 1scp dbdump.db root@&lt;slave_ip&gt;:~/ 在从库中执行命令写入db文件 1mysql &lt; dbdump.db -uroot -p&lt;mysql_password&gt; 在主库中解锁数据库 1unlock tables; 在从库中设置配置 1change master to master_host=&#x27;&lt;master_host&gt;&#x27;, master_user=&#x27;repl&#x27;, master_password=&#x27;&lt;slave_password&gt;&#x27;, master_log_file=&#x27;&lt;bin_log_file_name.no&gt;&#x27;, master_log_pos=&lt;bin_log_file_pos&gt;; 开启从库 1start slave; Sharding-jdbc 一个开源的分布式的关系型数据库中间件 客户端代理模式 定位为轻量级的Java框架，以jar包提供服务 可以理解为增强版的jdbc驱动 完全兼容各种ORM框架 提供四种配置方式：Java API 、yaml、SpringBoot和Spring命名空间 与mycat的区别 MyCat是服务端代理，Sharding-Jdbc是客户端代理 MyCat不支持同一库内的水平切分，Sharding-jdbc支持 官网：https://shardingsphere.apache.org/index_zh.html","categories":[],"tags":[{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://rabbit-mar.github.io/tags/sharding-jdbc/"},{"name":"mycat","slug":"mycat","permalink":"https://rabbit-mar.github.io/tags/mycat/"}]},{"title":"Redis学习之路（五）—— 集群架构","slug":"Redis学习之路（五）——-集群架构","date":"2020-12-11T00:02:55.000Z","updated":"2021-02-18T15:04:21.959Z","comments":true,"path":"2020/12/11/Redis学习之路（五）——-集群架构/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/11/Redis%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94-%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84/","excerpt":"Redis学习之路的第五章，主要介绍Redis的三种集群模式","text":"Redis 线程模型同步与异步，阻塞与非阻塞 同步阻塞： 客户端发送请求给服务端，此时服务端处理任务时间很久，则客户端则被服务端堵塞了，所以客户端会一直等待服务端的响应，此时客户端不能做事，服务端也不会接受其他客户端的请求。这种通信机制比较简单粗暴，但是效率不高。 同步非阻塞： 客户端发送请求给服务端，此时服务端处理任务时间很久，这个时候虽然客户端会一直等待响应，但是服务端可以处理其他的请求，过一会回来的。这种方式很高效，一个服务端可以处理很多请求，不会在因为任务没有处理完而堵着，所以这是非阻塞的。 异步阻塞： 客户端发送请求给服务端，此时服务端处理任务时间很久，但是客户端不会等待服务器响应，它可以做其他的任务，等服务器处理完毕后再把结果端，客户端得到回调后再处理服务端的响应。这种方式可以避免客户端一直处于等待的状态，优化了用户体验，其实就是类似于网页里发起的ajax异步请求。 异步非阻塞： 客户端发送请求给服务端，此时服务端处理任务时间很久，这个时候的任务虽然处理时间会很久，但是客户端可以做其他的任务，因为他是异步回调函数里处理响应；同时服务端是非阻塞的，所以服务端可以去处理其他的任务，如此，这个模式就显得非常的高效了。 小结： 异步 的优势显而易见，大大优化用户体验， 非阻塞 使得系统资源开销远远小于 阻塞 模式，因为系统不需要创建新的进程(或线程)，大大地节省了系统多出来的系统资源可以给其他的中间件去服务了 Redis线程模型 发布与订阅发布命令publish channel message 订阅命令subscribe channel 批量订阅命令： psubscribe channel channel可以使用 * 作为通配符，例如 foo* 即订阅所有以foo为前缀的频道 持久化官方文档：https://redis.io/topics/persistence 主从架构主从原理主服务器负责写操作，从服务器负责读去操作，首先从服务器通过ping的方式告知主服务器，进行一次全量备份，后续操作通过数据复制的方式进行同步。使用主从方式，主服务器必须开始持久化！ 主从模式一主多从主服务器： 192.168.1.5 从服务器：192.168.1.100；192.168.1.101 命令info replication # 查看主从复制模式信息 搭建主从复制 修改从服务器配置文件 1234# 主节点 IP 端口replicaof 192.168.1.5 6379# 主节点密码masterauth password 重启从服务器，进入redis-cli 1234567891011121314151617181920&gt; info replication # 查看从服务器信息# Replicationrole:slavemaster_host:192.168.1.5master_port:6379master_link_status:upmaster_last_io_seconds_ago:8master_sync_in_progress:0slave_repl_offset:739slave_priority:100slave_read_only:1connected_slaves:0master_replid:e3517de5f26dbbadc5c1ef311aa9be665ee4f818master_replid2:0000000000000000000000000000000000000000master_repl_offset:739second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:739 树状从多主多从无磁盘化复制redis中还有一种方式就是采用无磁盘化方式，即使用socket进行网络传输，忽略磁盘的性能损耗 开启无磁盘化方式1repl-diskless-sync yes 缓存过期机制主动（定期）删除在一定时间内随机抽查一部分key，如果过期就将其删除 12# 设置为1秒检查10次hz 10 被动（惰性）删除客户端请求redis时，很有可能请求到过期的key，一旦过期的key被请求到，就会被redis检测到，并将key从内存中删除掉 内存淘汰管理机制1234567891011121314151617# volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key having an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don&#x27;t evict anything, just return an error on write operations.# LRU means Least Recently Used(最近最少使用)# LFU means Least Frequently Used(最少使用)volatile 表示有过期时间的keyallkeys 表示所有的key 哨兵机制由于主从复制的方式存在一个致命的缺点，即主结点宕机后从节点无法代替主结点工作。从节点无法提供写服务，那么就产生了哨兵模式，监控所有的redis服务器，一旦主服务器出现问题后，将一个从服务器变为主服务器。 开启哨兵模式官方文档：https://redis.io/topics/sentinel 拷贝主服务器中的解压文件中的sentinel.conf文件到redis配置文件目录 修改sentinel.conf 123456789101112131415161718# 关闭保护模式protected-mode no# 开启后台运行模式daemonize yes# 日志文件所在位置logfile /data/redis/log/sentinel.log# 哨兵的工作目录dir /data/redis/working/sentinel# 配置sentinel主结点 名称:redis-master ip:192.168.1.5 quorum:2(表明达成共识的哨兵数，例如都认同主结点发生故障的数量)sentinel monitor redis-master 192.168.1.5 6379 2# sentinel 主结点密码sentinel auth-pass redis-master password# 主结点被检测为宕机后10秒后被设为宕机sentinel down-after-milliseconds redis-master 10000# 从节点并行同步新主结点数据的并行数量sentinel parallel-syncs redis-master 1# 哨兵在3min内没有完成主从切换，由新哨兵负责sentinel failover-timeout redis-master 180000 拷贝该配置文件到从服务器中 启动主从服务器上的sentinel 1redis-sentinel &lt;sentinel文件&gt; 查看主服务器上的sentinel日志文件 123456789102983:X 18 Nov 2020 23:21:50.074 # Configuration loaded2983:X 18 Nov 2020 23:21:50.074 * Increased maximum number of open files to 10032 (it was originally set to 1024).2983:X 18 Nov 2020 23:21:50.075 * Running mode=sentinel, port=26379.2983:X 18 Nov 2020 23:21:50.075 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.2983:X 18 Nov 2020 23:21:50.107 # Sentinel ID is fcca783724a1984be1f5bd664f837c44a7b6c0fe2983:X 18 Nov 2020 23:21:50.107 # +monitor master redis-master 192.168.1.5 6379 quorum 22983:X 18 Nov 2020 23:21:50.108 * +slave slave 192.168.1.100:6379 192.168.1.100 6379 @ redis-master 192.168.1.5 63792983:X 18 Nov 2020 23:21:50.110 * +slave slave 192.168.1.101:6379 192.168.1.101 6379 @ redis-master 192.168.1.5 63792983:X 18 Nov 2020 23:23:36.624 * +sentinel sentinel 6be0268f7ffa1f7d2d1a018d2d9a5e5ae94cf24e 192.168.1.100 26379 @ redis-master 192.168.1.5 63792983:X 18 Nov 2020 23:23:49.769 * +sentinel sentinel 29ebcf39187ba801b47589c0e268f6ca7f061f16 192.168.1.101 26379 @ redis-master 192.168.1.5 6379 Redis 集群 三从三从的方式实现Redis集群，主服务器通过分片的方式实现集群，从服务器通过主从复制同步数据 搭建redis的三主三从集群模式 编辑主从服务器上的redis.conf文件 12345678# 开启集群模式cluster-enabled yes# 集群配置文件cluster-config-file nodes-6379.conf# 集群节点超时时间，主备切换cluster-node-timeout 5000# 开启aofappendonly yes 重启主从服务器上的redis服务 在主服务器中使用redis-cli构建集群 1redis-cli -a password --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]},{"title":"Kafka 学习之路（二）","slug":"Kafka-学习之路（二）","date":"2020-12-10T23:56:18.000Z","updated":"2021-02-18T15:04:21.783Z","comments":true,"path":"2020/12/11/Kafka-学习之路（二）/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/11/Kafka-%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"Kafka 学习笔记的第二节：海量日志收集架构设计","text":"海量日志收集架构设计beats: 主要是用于收集日志，例如Filebeat底层使用Golang编写，性能好。业务代码中使用log打印出来的日志都会使用Filebeat抓取出来，输入到其他地方。 在这个架构中Beats中抓取到的数据全部输出到Kafka中，通过Kafka输入到logstash中进行过滤，将过滤后的数据输入到es中，使用kibana进行数据展示 项目中使用的架构设计 Kafka高吞吐核心实战 - 日志输出log4j2的使用 日志输出 日志分级 日志过滤 MDC线程变量 ​ slf4j框架的功能，可以认为它是在日志中的ThreadLocal，跟着每一个线程来的。他的作用是跟着每一次请求都会执行某些方法，这些日志都可以进入到一次线程的局部变量里面，打日志的时候如果有一些特殊的变量需要put到MDC中，可以理解为一个不可写不可变的Map。当EventLog4f2这个对象创建好之后，这里面的内容就不可变了，在日志收集之前可以往里面put很多内容，当执行收集的过程的时候就不可变了。 依赖环境1234567891011121314151617181920212223242526272829303132333435363738394041&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-json&lt;/artifactId&gt; &lt;version&gt;5.5.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; log4j2文件具体配置信息详见官方：https://logging.apache.org/log4j/2.x/manual/configuration.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--https://logging.apache.org/log4j/2.x/manual/configuration.html--&gt;&lt;Configuration status=&quot;error&quot; schema=&quot;Log4J-V2.0.xsd&quot; monitorInterval=&quot;600&quot;&gt; &lt;Properties&gt; &lt;Property name=&quot;LOG_HOME&quot; value=&quot;logs&quot;/&gt; &lt;Property name=&quot;FILE_HOME&quot; value=&quot;logger-parent&quot;/&gt; &lt;Property name=&quot;patternLayout&quot; value=&quot;[%d&#123;yyyy-MM-dd&#x27;T&#x27;HH:mm:ss.SSSZZ&#125;] [%level&#123;length=5&#125;] [%thread-%tid] [%logger] [%X&#123;hostName&#125;] [%X&#123;ip&#125;] [%X&#123;applicationName&#125;] [%F:%L, %C.%M] [%m] ## &#x27;%ex&#x27;%n&quot;/&gt; &lt;/Properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;patternLayout&#125;&quot;/&gt; &lt;/Console&gt; &lt;RollingRandomAccessFile name=&quot;appAppender&quot; fileName=&quot;$&#123;LOG_HOME&#125;/app-$&#123;FILE_HOME&#125;.log&quot; filePattern=&quot;$&#123;LOG_HOME&#125;/app-$&#123;FILE_HOME&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;patternLayout&#125;&quot;/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy interval=&quot;1&quot; modulate=&quot;true&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;500M&quot;/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max=&quot;20&quot;/&gt; &lt;/RollingRandomAccessFile&gt; &lt;RollingRandomAccessFile name=&quot;errorAppender&quot; fileName=&quot;$&#123;LOG_HOME&#125;/error-$&#123;FILE_HOME&#125;.log&quot; filePattern=&quot;$&#123;LOG_HOME&#125;/error-$&#123;FILE_HOME&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;patternLayout&#125;&quot;/&gt; &lt;Filters&gt; &lt;ThresholdFilter level=&quot;warn&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy interval=&quot;1&quot; modulate=&quot;true&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;500M&quot;/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max=&quot;20&quot;/&gt; &lt;/RollingRandomAccessFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;AsyncLogger name=&quot;com.marveal.*&quot; level=&quot;info&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;appAppender&quot;/&gt; &lt;/AsyncLogger&gt; &lt;AsyncLogger name=&quot;com.marveal.*&quot; level=&quot;info&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;errorAppender&quot;/&gt; &lt;/AsyncLogger&gt; &lt;Root level=&quot;info&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;AppenderRef ref=&quot;appAppender&quot;/&gt; &lt;AppenderRef ref=&quot;errorAppender&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 使用MDC赋值由于log4j2使用了%X表达式，那么对应的值需要使用MDC进行赋值，在日志打印前进行方法的一次调用 12345678910111213141516171819202122@Componentpublic class InputMDC implements EnvironmentAware &#123; private static Environment env; @Override public void setEnvironment(Environment environment) &#123; env = environment; &#125; public static void putMDC() &#123; InetAddress ia = null; try &#123; ia = InetAddress.getLocalHost(); MDC.put(&quot;hostName&quot;, ia.getHostName()); MDC.put(&quot;ip&quot;, ia.getHostAddress()); &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; MDC.put(&quot;applicationName&quot;, env.getProperty(&quot;spring.application.name&quot;)); &#125;&#125; FileBeat的使用 安装入门 配置文件 对接Kafka 实战应用 启动Zookeeper启动Kafka创建两个topic 12kafka-topics.sh --create --topic app-logger-parent --bootstrap-server &lt;kafka-server-ip:port&gt; --partitions 1 --replication-factor 1kafka-topics.sh --create --topic error-logger-parent --bootstrap-server &lt;kafka-server-ip:port&gt; --partitions 1 --replication-factor 1 FileBeat的安装 docker安装 1docker pull elastic/filebeat:7.9.3 创建文件 /mydata/filebeat/filebeat.yml 详细配置详见官网：https://www.elastic.co/guide/en/beats/filebeat/7.x/configuration-filebeat-options.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344filebeat.inputs:- type: log paths: - /root/logs/app-logger-parent.log # 日志所在位置 document_type: &quot;app-log&quot; # 文档名 multiline: type: pattern pattern: &#x27;^\\[&#x27; negate: true match: after max_lines: 2000 timeout: 2s fields: log_biz: logger-parent log_topic: app-logger-parent env: dev- type: log paths: - /root/logs/error-logger-parent.log document_type: &quot;error-log&quot; multiline: type: pattern pattern: &#x27;^\\[&#x27; negate: true match: after max_lines: 2000 timeout: 2s fields: log_biz: logger-parent log_topic: error-logger-parent env: devoutput.kafka: enabled: true hosts: [&quot;192.168.1.2:9092&quot;] # kafka服务器 topic: &#x27;%&#123;[fields.log_topic]&#125;&#x27; partition.hash: reachable_only: false required_acks: 1 compression: gzip max_message_bytes: 1000000logging.to_files: true 启动filebeat 12345docker run -d \\ --name&#x3D;log-filebeat \\ --restart&#x3D;always \\ -v &#x2F;mydata&#x2F;filebeat&#x2F;filebeat.yml:&#x2F;usr&#x2F;share&#x2F;filebeat&#x2F;filebeat.yml \\ elastic&#x2F;filebeat:&lt;version&gt; 启动logstash 下载logstash，启动logstash 12docker pull logstash:7.9.3docker run -d --name logstash logstash:&lt;version&gt; 拷贝文件夹到本地 12docker cp logstash:/usr/share/logstash/config /mydata/logstash/configdocker cp logstash:/usr/share/logstash/pipline /mydata/logstash/pipline 创建文件 /mydata/logstash/config/logstash.yml 12http.host: &quot;0.0.0.0&quot;xpack.monitoring.elasticsearch.hosts: [ &quot;http://&lt;es-ip&gt;:9200&quot; ] 编辑文件 /mydata/logstash/config/pipelines.yml 123- pipeline.id: logger-parent path.config: &quot;/usr/share/logstash/pipeline/logger-parent.conf&quot; pipeline.workers: 2 编辑文件 /mydata/logstash/config/jvm.options 12-Xms256m-Xmx256m 创建文件 /mydata/logstash/pipeline/logger-parent.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061input &#123; kafka &#123; topics_pattern =&gt; &quot;app-logger-parent.*&quot; bootstrap_servers =&gt; &quot;192.168.1.2:9092&quot; codec =&gt; json consumer_threads =&gt; 4 decorate_events =&gt; true group_id =&gt; &quot;app-logger-parent-group&quot; &#125; kafka &#123; topics_pattern =&gt; &quot;error-logger-parent.*&quot; bootstrap_servers =&gt; &quot;192.168.1.2:9092&quot; codec =&gt; json consumer_threads =&gt; 4 decorate_events =&gt; true group_id =&gt; &quot;error-logger-parent-group&quot; &#125;&#125;filter &#123; ruby &#123; code =&gt; &quot;event.set(&#x27;index_time&#x27;, event.timestamp.time.localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125; if &quot;app-logger-parent&quot; in [fields][log_topic] &#123; grok &#123; match =&gt; [&quot;message&quot;, &quot;\\[%&#123;NOTSPACE:currentDateTime&#125;\\] \\[%&#123;NOTSPACE:level&#125;\\] \\[%&#123;NOTSPACE:thraed_id&#125;\\] \\[%&#123;NOTSPACE:class&#125;\\] \\[%&#123;DATA:hostName&#125;\\] \\[%&#123;DATA:ip&#125;\\] \\[%&#123;DATA:applicationName&#125;\\] \\[%&#123;DATA:location&#125;\\] \\[%&#123;DATA:messageInfo&#125;\\] ## (\\&#x27;\\&#x27;|%&#123;QUOTEDSTRING:throwable&#125;)&quot;] &#125; &#125; if &quot;error-logger-parent&quot; in [fields][log_topic] &#123; grok &#123; match =&gt; [&quot;message&quot;, &quot;\\[%&#123;NOTSPACE:currentDateTime&#125;\\] \\[%&#123;NOTSPACE:level&#125;\\] \\[%&#123;NOTSPACE:thraed_id&#125;\\] \\[%&#123;NOTSPACE:class&#125;\\] \\[%&#123;DATA:hostName&#125;\\] \\[%&#123;DATA:ip&#125;\\] \\[%&#123;DATA:applicationName&#125;\\] \\[%&#123;DATA:location&#125;\\] \\[%&#123;DATA:messageInfo&#125;\\] ## (\\&#x27;\\&#x27;|%&#123;QUOTEDSTRING:throwable&#125;)&quot;] &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;output &#123; if &quot;app-logger-parent&quot; in [fields][log_topic] &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.1.2:9200&quot;] index =&gt; &quot;app-%&#123;[fields][log_biz]&#125;-%&#123;index_time&#125;&quot; sniffing =&gt; true template_overwrite =&gt; true &#125; &#125; if &quot;error-logger-parent&quot; in [fields][log_topic] &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.1.2:9200&quot;] index =&gt; &quot;error-%&#123;[fields][log_biz]&#125;-%&#123;index_time&#125;&quot; sniffing =&gt; true template_overwrite =&gt; true &#125; &#125;&#125; 启动logstash 12345678docker run -d \\ --name=logstash \\ --restart=always \\ -p 5044:5044 \\ -v /mydata/logstash/config:/usr/share/logstash/config \\ -v /mydata/logstash/pipeline:/usr/share/logstash/pipeline \\ --add-host docker001:192.168.1.2 \\ logstash:&lt;version&gt; 启动es 下载es 1docker pull elasticsearch:&lt;version&gt; 创建文件 /mydata/es-log/config/elasticsearch.yml 123456789http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;cluster.name: elasticsearch-lognode.name: es-nodenetwork.host: 0.0.0.0discovery.seed_hosts: [&quot;192.168.1.2:9300&quot;]discovery.type: single-node 启动es 12345678docker run -d \\-e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\-p 9200:9200 \\-p 9300:9300 \\-v /mydata/es-log/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\-v /mydata/es-log/data:/usr/share/elasticsearch/data \\--name elasticsearch-log \\elasticsearch:&lt;version&gt; 启动kibana 下载kibana 1docker pull kibana:&lt;version&gt; 创建文件 /mydata/kibana/config/kibana.yml 1234server.name: kibanaserver.host: &quot;0&quot;elasticsearch.hosts: [ &quot;http://192.168.1.2:9200&quot; ]monitoring.ui.container.elasticsearch.enabled: true 启动kibana 1docker run -d -v /mydata/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml -p 5601:5601 --name kibana kibana:&lt;version&gt; Kafka高吞吐核心实战 - watcher监控告警※ 使用告警功能需要至少黄金版服务 elasticsearch的破解：https://www.azurew.com/elk/3750.html 打开kibana &gt; dev tool 输入以下内容，插入模板 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374PUT _template/error-logger-parent-&#123; &quot;template&quot;: &quot;error-logger-parent-*&quot;, &quot;order&quot;: 0, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;refresh_interval&quot;: &quot;5s&quot; &#125; &#125;, &quot;mappings&quot;: &#123; &quot;_default_&quot;: &#123; &quot;dynamic_templates&quot;: [ &#123; &quot;message_field&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;path_match&quot;: &quot;message&quot;, &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125; &#125;, &#123; &quot;throwable_field&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;path_match&quot;: &quot;throwable&quot;, &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125; &#125;, &#123; &quot;string_fields&quot;: &#123; &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot;, &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; &#125; &#125; ], &quot;_all&quot;: &#123; &quot;enabled&quot;: false &#125;, &quot;properties&quot;: &#123; &quot;hostName&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;ip&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125;, &quot;level&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;currentDateTime&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125;&#125; 创建一个watch 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283PUT _watcher/watch/error_logger_parent_watcher&#123; &quot;trigger&quot;: &#123; &quot;schedule&quot;: &#123; &quot;interval&quot;: &quot;5s&quot; &#125; &#125;, &quot;input&quot;: &#123; &quot;search&quot;: &#123; &quot;request&quot;: &#123; &quot;indices&quot;: [&quot;&lt;error-logger-parent-&#123;now+8h/d&#125;&gt;&quot;], &quot;body&quot;: &#123; &quot;size&quot;: 0, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123; &quot;term&quot;: &#123; &quot;level.keyword&quot;: &quot;ERROR&quot; &#125; &#125;], &quot;filter&quot;: [ &#123;&quot;range&quot;: &#123; &quot;currentDateTime&quot;: &#123; &quot;gt&quot;: &quot;now-30s&quot;, &quot;lt&quot;: &quot;now&quot; &#125; &#125;&#125; ] &#125; &#125; &#125; &#125; &#125; &#125;, &quot;condition&quot;: &#123; &quot;compare&quot;: &#123; &quot;ctx.payload.hits.total&quot;: &#123; &quot;gt&quot;: 0 &#125; &#125; &#125;, &quot;transform&quot;: &#123; &quot;search&quot;: &#123; &quot;request&quot;: &#123; &quot;indices&quot;: [&quot;&lt;error-logger-parent-&#123;now+8h/d&#125;&gt;&quot;], &quot;body&quot;: &#123; &quot;size&quot;: 1, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [&#123; &quot;term&quot;: &#123; &quot;level.keyword&quot;: &quot;ERROR&quot; &#125; &#125;], &quot;filter&quot;: [ &#123;&quot;range&quot;: &#123; &quot;currentDateTime&quot;: &#123; &quot;gt&quot;: &quot;now-30s&quot;, &quot;lt&quot;: &quot;now&quot; &#125; &#125;&#125; ] &#125; &#125;, &quot;sort&quot;: [&#123; &quot;currentDateTime&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;] &#125; &#125; &#125; &#125;, &quot;actions&quot;: &#123; &quot;test_error&quot;: &#123; &quot;webhook&quot;: &#123; &quot;method&quot;: &quot;POST&quot;, &quot;url&quot;: &quot;http://192.168.1.4:8001/accurateWatch&quot;, // IP为监控平台的IP地址 &quot;body&quot;: &quot;&#123;\\&quot;title\\&quot;: \\&quot;异常信息告警\\&quot;, \\&quot;applicationName\\&quot;: \\&quot;&#123;&#123;#ctx.payload.hits.hits&#125;&#125;&#123;&#123;_source.applicationName&#125;&#125;&#123;&#123;/ctx.payload.hits.hits&#125;&#125;\\&quot;, \\&quot;level\\&quot;: \\&quot;告警级别P1\\&quot;, \\&quot;body\\&quot;: \\&quot;&#123;&#123;#ctx.payload.hits.hits&#125;&#125;&#123;&#123;_source.messageInfo&#125;&#125;&#123;&#123;/ctx.payload.hits.hits&#125;&#125;\\&quot;, \\&quot;executionTime\\&quot;: \\&quot;&#123;&#123;#ctx.payload.hits.hits&#125;&#125;&#123;&#123;_source.currentDateTime&#125;&#125;&#123;&#123;/ctx.payload.hits.hits&#125;&#125;\\&quot;&#125;&quot; &#125; &#125; &#125;&#125; 编写接口处理请求 1234567891011121314151617@RestControllerpublic class WatcherController &#123; @RequestMapping(&quot;/accurateWatch&quot;) public void accurateWatch(@RequestBody AccurateWatchMessage message) &#123; System.out.println(HutoolJsonUtil.convertObjectToJSON(message)); &#125;&#125;@Datapublic class AccurateWatchMessage &#123; private String title; private String applicationName; private String level; private String body; private String executionTime;&#125;","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://rabbit-mar.github.io/tags/Kafka/"}]},{"title":"Kafka 学习之路（一）","slug":"Kafka-学习之路（一）","date":"2020-12-10T23:54:03.000Z","updated":"2021-02-18T15:04:21.891Z","comments":true,"path":"2020/12/11/Kafka-学习之路（一）/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/11/Kafka-%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"Kafka 学习笔记的第一节：Kafka特性原理与集群架构解析以及常用命令","text":"Kafka特性原理与集群架构解析Kafka介绍 Kafka是LinkedIn开源的分布式消息系统，目前归属于Apache顶级项目 Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用来日志收集和传输 0.8版本开始支持复制，不支持事务，对消息的重复，丢失，错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务 Kafka有哪些特点 分布式 跨平台 实时性 伸缩性 Kafka高性能的原因 顺序写，Page Cache，空中接力，高效读写 高性能高吞吐 后台异步，主动Flush 预读策略，IO调度 Page CachePage Cache是操作系统主要实现的一种磁盘缓存，以此来减少磁盘IO的操作，就是把磁盘的数据缓存到内存中，把对磁盘的访问变成对内存的访问。 用户操作磁盘文件的时候会在PageCache中查找是否存在这该磁盘文件，如果存在就直接返回，如果不存在就真正请求一次磁盘IO，返回将文件缓存在PageCache中，再进行返回。 zero copy磁盘文件只在内核空间的上下文上进行一次copy，即由磁盘文件到内核读取缓冲区的拷贝，由页面缓存直接发送到网卡接口 Kafka集群模式使用Zookeeper进行协调 Kafka 常用命令官方文档：https://kafka.apache.org/documentation/ 查看topic列表123kafka-topics.sh --zookeeper &lt;zookeeper-server-ip:port&gt; --list# 或者kafka-topics.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --list 创建一个topic执行在指定的kafka服务器上创建一个topic，设置分区为2个，备份为1个 1$ bin/kafka-topics.sh --create --topic &lt;topic-name&gt; --bootstrap-server &lt;kafka-server-ip:port&gt; --partitions 2 --replication-factor 1 修改topic修改topic的分区为40 1$ bin/kafka-topics.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --alter --topic &lt;topic-name&gt; --partitions 40 删除一个topic1$ bin/kafka-topics.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --delete --topic &lt;topic-name&gt; 查看topic的描述 不带任何参数的kafka-topics.sh命令以显示使用情况信息。 例如，它还可以向您显示详细信息，例如新主题的分区数： 1$ bin/kafka-topics.sh --describe --topic &lt;topic-name&gt; --bootstrap-server &lt;kafka-server-ip:port&gt; 终端生产者写入数据运行控制台生产者客户端，将一些事件写入您的主题。 默认情况下，您输入的每一行都会导致一个单独的事件写入该主题， 您可以随时使用 Ctrl-C 停止生产者客户端。 1$ bin/kafka-console-producer.sh --topic &lt;topic-name&gt; --bootstrap-server &lt;kafka-server-ip:port&gt; 消费者获取数据 打开另一个终端会话并运行控制台使用者客户端以读取您刚刚创建的事件 1$ bin/kafka-console-consumer.sh --topic &lt;topic-name&gt; --from-beginning --bootstrap-server &lt;kafka-server-ip:port&gt; 查看订阅组对应消费者位置1&gt; bin/kafka-consumer-groups.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --describe --group &lt;group-name&gt; 查看订阅组1&gt; bin/kafka-consumer-groups.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --list 要查看偏移量，我们像这样“describe”订阅组 1&gt; bin/kafka-consumer-groups.sh --bootstrap-server &lt;kafka-server-ip:port&gt; --describe --group &lt;group-name&gt;","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://rabbit-mar.github.io/tags/Kafka/"}]},{"title":"RabbitMQ 学习之路（二）","slug":"RabbitMQ-学习之路（二）","date":"2020-12-05T05:20:31.000Z","updated":"2021-02-18T15:02:15.861Z","comments":true,"path":"2020/12/05/RabbitMQ-学习之路（二）/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/05/RabbitMQ-%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"RabbitMQ 学习之路第二节，RabbitMQ实战、RabbitMQ基础组件封装以及RabbitMQ 安装延迟插件","text":"RabbitMQ实战RabbitMQ是一个开源的消息代理和队列服务器，用来通过普通协议再完全不同的应用之间共享数据，RabbitMQ是使用Erlang语言来编写的，并且RabbitMQ是基于AMQP协议的。 哪些大厂在用RabbitMQ滴滴、美团、头条、去哪儿、艺龙…… 开源、性能优秀，稳定性保障 提供可靠性消息投递模式(confirm)，返回模式(return) 与SpringAMQP完美的整合，API丰富 集群模式丰富，表达式配置，HA模式，镜像队列模型 保证数据不丢失的前提做到高可靠性、可用性 RabbitMQ高性能的原因 Erlang语言最初在于交换机领域的架构模式，这样使得RabbitMQ在Broker之间进行数据交互的性能是非常优秀的 Erlang的优点：Erlang有着和原生Socket一样的延迟 AMQP高级消息队列协议AMQP全称：Advanced Message Queuing Protocal AMQP翻译：高级消息队列协议 AMQP定义：是具有现代特征的二进制协议。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。 AMQP协议模型 AMQP核心概念 Server：又称Broker，接受客户端的连接，实现AMQP实体服务 Connection：连接，应用程序与Broker的网络连接 Channel：网络信道，几乎所有的操作都在Channel中进行，Channel时进行消息读写的通道，客户端可建立多个Channel，每个Channel代表一个会话任务。 Message：消息，服务器和应用程序之间传送的数据，由Properties和Body组成，Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body则就是消息体内容。 Virtual host：虚拟地址，用于进行逻辑隔离，最上层的消息路由。一个Vtrtual host里面可以有若干个Exchange和Queue，同一个Virtual host里面不能有相同名称的Exchange或Queue Exchange：交换机，接收消息，根据路由键转发消息到绑定的队列 Binding：Exchange和Queue之间的虚拟连接，Binding中可以包含Routing key Routing key：一个路由规则，虚拟机可用他来确定路由一个特定消息 Queue：也称为Message queue，消息队列，保存消息并将它们转发给消费者 RabbitMQ的整体架构 消息由publisher发送给broker中的一个vhost 由vhost交给指定的Exchange 再根据消息头中的 路由键 决定发送到哪个Queue中 消息到达Queue中后，就可以由消费者建立连接（多路复用），从Queue中取出消息 消息如何保证100%的投递成功生产端的可靠性投递 保障消息的成功发出 保障MQ节点的成功接收 发送端收到MQ节点(Broker)确认应答 完善的消息进行补偿机制 生产端可靠性投递解决方案 消息落库，对消息状态进行打标 消息的延迟投递，做二次确认，回调检查 幂等性 对于同一个系统，在同样条件下，一次请求和重复多次请求对资源的影响是一致的，就称该操作为幂等的。 MVCC 借鉴数据库的多版本控制方式来实现数据库的幂等，即在执行SQL的时候，通过Version来控制 1update t_table set value = value + 1, version = version + 1 where version = 1 token 发起异步请求创建一个唯一的ticketId，就是门票，这张门票只能使用一次就作废，具体步骤如下： 异步请求获取门票 调用支付，传入门票 根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，执行请求，保存结果 返回结果到客户端 如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的 消费端-幂等性保障如何避免消息的重复消费消费端实现幂等性，就意味着，我们的消息永远不会消费多次，即使我们收到了多条一样的消息 唯一ID + 指纹码 机制，利用数据库主键去重 SELECT COUNT(1) FROM t_table WHERE ID = 唯一ID + 指纹码 好处：实现简单 坏处：高并发下有数据库写入的性能瓶颈 解决方案：根据ID进行分库分表进行算法路由 利用Redis的原子性去实现 需要考虑以下问题 数据是否需要落库，如果落库的话，关键解决的问题是数据库和缓存如何做到原子性 如果不进行落库，那么都存储到缓存中，如何设置定时同步的策略 RabbitMQ的安装官网：https://www.rabbitmq.com/install-rpm.html RabbitMQ基础组件封装基础组件实现关键点 MQ组件实现思路和架构设计方案 基础组件封装设计 - 迅速消息发送 基础组件封装设计 - 确认消息发送 基础组件封装设计 - 延迟消息发送 基础组件实现的功能点 迅速、延迟、可靠 消息异步化、序列化 连接池化、高性能 完备的补偿机制 基础组件模块划分— rabbit-parent​ | — rabbit-api​ | — rabbit-common​ | — rabbit-core-producer​ | — rabbit-task 代码实现见Gitee：https://gitee.com/marveal_admin/rabbit-parent RabbitMQ 安装延迟插件安装包方式安装 插件的下载地址：https://www.rabbitmq.com/community-plugins.html，下载 rabbitmq_delayed_message_exchange 插件 放置到rabbitmq安装目录下得plugins目录下 docker方式安装 同上，先下载插件 拷贝插件到rabbitmq容器的 /plugins 目录下 1docker cp rabbitmq_delayed_message_exchange-&lt;version&gt;.ez rabbitmq:/plugins 重新授权rabbitmq用户 123# 进入容器启用插件docker exec -it rabbitmq /bin/bashchown -R rabbitmq:rabbitmq rabbitmq_delayed_message_exchange-&lt;version&gt;.ez 启动延迟插件 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 重启rabbitmq服务完成安装 添加一个延迟消息Exchange设置type为x-delay-message，必须添加参数 x-delayed-type 为 topic","categories":[],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://rabbit-mar.github.io/tags/RabbitMQ/"}]},{"title":"RabbitMQ 学习之路（一）","slug":"RabbitMQ-学习之路（一）","date":"2020-12-05T05:16:23.000Z","updated":"2021-02-18T15:02:15.902Z","comments":true,"path":"2020/12/05/RabbitMQ-学习之路（一）/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/05/RabbitMQ-%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"RabbitMQ 学习之路第一节，业界主流的分布式消息队列（MQ）与技术选型以及RabbitMQ特性原理与集群架构解析","text":"业界主流的分布式消息队列（MQ）与技术选型分布式消息队列（MQ）应用场景 服务解耦/拆分 削峰填谷 异步化缓冲 分布式消息队列（MQ）应用思考点 生产端可靠性投递 消费端幂等 高可用 低延迟 可靠性 堆积能力 扩展性 业界主流的分布式消息队列（MQ） ActiveMQ RabbitMQ RocketMQ Kafka 如何进行技术选型 各个MQ的性能、优缺点、相应的业务场景 ActiveMQ适合传统行业/中小型公司。它的消息并发及承载能力不是特别优秀，在高流量的情况下，表现得并不是很好。 RabbitMQ在高流量下是可以的。RabbitMQ是有瓶颈的，RabbitMQ的集群有镜像队列，满足于消息不丢失，满足可靠性，但是横向扩展能力不强。 集群架构模式，分布式、可扩展、高可用、可维护性 RabbitMQ可扩展性不强，需要自己加一层路由组件，但是可用性和可维护性是首屈一指的 Kafka或者RocketMQ扩展性很强，高可用也是很强的，但是可用性会差一点 综合成本问题，集群规模，人员成本 未来的方向、规划、思考 如果消息不是特别要求可靠性，可以选择Kafka，因为Kafka可以在很廉价的服务器上有很高的性能和吞吐量表现 RabbitMQ特性原理与集群架构解析RabbitMQ四种集群架构 主备模式：热备份的模式，主服务在正常情况下提供服务，从服务器负责备份。当主服务器宕机后，从服务器能够代替主服务器对外提供服务 远程模式：多活，异地容灾。当单个服务器集群无法处理的时候，可以将消息转发给下流服务器集群 镜像模式 多活模型：异地容灾。数据的转储 主备模式warren(兔子窝)，一个主/备方案（主节点如果宕机，从节点提供服务，和ActiveMQ利用Zookeeper做主/备一样），采用HAProxy实现 消费者通过HaProxy路由默认到主结点，当主节点发生故障的时候，HAProxy会路由到备份节点。当主节点恢复后重新加入到集群，会重新变为一个备份节点。 HAProxy 配置123456listen rabbitmq_clusterbind 0.0.0.0:5672mode tcp # 配置TCP模式balance roundrobin # 简单的轮询server hostname1 192.168.1.1:5672 check inter 5000 rise 2 fall 2 # 主节点server hostname2 192.168.1.2:5672 backup check inter 5000 rise 2 fall 2 # 备份节点 备注：rabbitmq集群节点配置#inter每隔五秒对mq集群做健康检查，2次正确证明服务器可用，2次失败证明服务器不可用，并且配置主备机制 远程模式 远距离通信和复制，可以实现双活的一种模式，简称Shovel模式 所谓Shovel就是我们可以把消息进行不同数据中心的复制工作，可以跨地域的让两个mq集群互联 在使用shovel插件后，模型变成了近端同步确认，远端异步确认的方式，大大提高了订单确认速度，并且还能保证可靠性； 现在使用的并不多，由于其效率并不高而且配置复杂 Shovel 集群配置步骤 启动RabbitMQ插件 12rabbitmq-plugins enable amqp_clientrabbitmq-plugins enable rabbitmq_shovel 创建rabbitmq.config文件 1touch &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.config 添加配置 源与目的地服务器使用相同的配置文件(rabbitmq.config) 镜像模式集群模式非常经典的就是Mirror镜像模式，保证100%数据不丢失 在实际工作中用的最多，并且实现集群非常的简单，一般互联网大厂都会构建这种镜像集群模式 高可靠 数据同步 三节点 集群架构图 这种模式下，无法做到水平扩容，在高流量的情况下，如果消费端消费速率不够快，那么就会形成消息的堆积 多活模式这种模式也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂，所以一般来说实现异地集群都是使用这种双活或者多活模型来实现的 这种模型需要依赖RabbitMQ的federation插件，可以实现持续的可靠的AMQP数据通信，多活模式实际配置与应用非常简单 RabbitMQ部署架构采用双中心模式（多中心），那么在两套（或多套）数据中心中各部署一套RabbitMQ集群，各中心的RabbitMQ服务除了需要为业务提供正常的消息服务外，中心还需要实现部分队列消息共享 Federation插件Federation插件是一个不需要构建Cluster，而在Brokers之间传输消息的高性能插件，Federation插件可以在Brokers或者Cluster之间传输消息，连接的双方可以使用不同的users和virtual hosts，双方也可以使用版本不同的RabbitMQ和Erlang。Federation插件使用AMQP协议通讯，可以接收不连续的传输 Federation Exchange，可以看成Downstream从Upstream主动拉取消息，但并不是拉取所有消息，必须是在Downstream上已经明确定义Bindings关系的Exchange，也就是有实际的物理Queue来接收消息，才会从Upstream拉取消息到Downstream。使用AMQP协议实施代理间通信，Downstream会将绑定关系组合在一起，绑定/解除绑定命令将发送到Upstream交换机。因此，Federation Exchange只接收具有订阅的消息","categories":[],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://rabbit-mar.github.io/tags/RabbitMQ/"}]},{"title":"文件系统学习之路","slug":"文件系统学习之路","date":"2020-12-02T06:37:01.000Z","updated":"2021-02-18T15:00:26.706Z","comments":true,"path":"2020/12/02/文件系统学习之路/","link":"","permalink":"https://rabbit-mar.github.io/2020/12/02/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/","excerpt":"介绍两种文件系统：FastDFS 和 OSS，主要讲解FastDFS的原理及配置，oss过于简单，通过官方文档即可操作","text":"文件系统学习之路FastDFSgithub: https://github.com/happyfish100/fastdfs FastDFS是一个开源的高性能分布式文件系统。 它的主要功能包括：文件存储，文件同步和文件访问（文件上传和文件下载），它可以解决高容量和负载平衡问题。 FastDFS应满足基于照片共享站点和视频共享站点等文件的网站的要求。 FastDFS具有两个角色：跟踪器和存储。 跟踪器负责计划和负载平衡以访问文件。 存储器存储文件及其功能是文件管理，包括：文件存储，文件同步，提供文件访问界面。 它还管理元数据，这些元数据是表示为文件的键值对的属性。 例如：width = 1024，键是“ width”，值是“ 1024”。 跟踪器和存储包含一台或多台服务器。 跟踪器或存储群集中的服务器可以随时添加到群集中或从群集中删除，而不会影响联机服务。 跟踪器群集中的服务器是对等的。 存储服务器按文件卷/组进行组织以获得高容量。 存储系统包含一个或多个卷，这些卷的文件相互独立。 整个存储系统的容量等于所有卷容量的总和。 文件卷包含一个或多个存储服务器，这些服务器之间的文件相同。 文件卷中的服务器相互备份，并且所有这些服务器都在负载平衡中。 将存储服务器添加到卷时，该卷中已存在的文件会自动复制到该新服务器，复制完成后，系统会将该服务器在线切换为提供存储服务。 当整个存储容量不足时，您可以添加一个或多个卷以扩展存储容量。 为此，您需要添加一个或多个存储服务器。 FastDFS 架构 FastDFS上传过程当Tracker收到客户端上传文件的请求时，会为该文件分配一个可以存储文件的group，当选定了group后就要决定给客户端分配group中的哪一个storage server。当分配好storage server后，客户端向storage发送写文件请求，storage将会为文件分配一个数据存储目录。然后为文件分配一个file_id，最后根据以上的信息生成文件名存储文件。 写文件时，客户端将文件写至group内一个storage server即认为写文件成功，storage server写完文件后，会由后台线程将文件同步至同group内其他的storage server。 每个storage写文件后，同时会写一份binlog，binlog里不包含文件数据，只包含文件名等元信息，这份binlog用于后台同步，storage会记录向group内其他storage同步的进度，以便重启后能接上次的进度继续同步；进度以时间戳的方式进行记录，所以最好能保证集群内所有server的时钟保持同步。 storage的同步进度会作为元数据的一部分汇报到tracker上，tracker在选择读storage的时候会以同步进度作为参考 FastDFS下载过程跟upload file一样，在downloadfile时客户端可以选择任意tracker server。tracker发送download请求给某个tracker，必须带上文件名信息，tracke从文件名中解析出文件的group、大小、创建时间等信息，然后为该请求选择一个storage用来服务读请求。 安装FastDFS 下载环境所需的安装包 1234fastdfs: https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gzfastdfs-nginx-module: https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gzlibfastcommon: https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gznginx: https://nginx.org/download/nginx-1.18.0.tar.gz 安装环境 1yum install -y gcc gcc-c++ libevent 解压 libfastcommon 的压缩包 进入压缩包，执行 ./make.sh &amp;&amp; ./make.sh install 解压 fastdfs 的压缩包 进入压缩包执行 ./make.sh &amp;&amp; ./make.sh install 拷贝conf 文件夹下所有的文件到 /etc/fdfs/ 进入到 /etc/fdfs/ 目录下，修改tracker.conf文件 12# tracker工作空间，需要先创建base_path = /data/fastdfs/tracker 启动tracker服务 1/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf 修改 storage.conf 文件 12345group_name=&lt;group_name&gt;base_path=/data/fastdfs/storagestore_path0=/data/fastdfs/storagetracker_server=&lt;tracker_server_ip&gt;:22122http.server_port=8888 使用命令启动storage服务 1/usr/bin/fdfs_storaged /etc/fdfs/storage.conf 修改 client.conf 文件 12base_path = /data/fastdfs/clienttracker_server=&lt;tracker_server_ip&gt;:22122 使用命令测试上传test文件 1/usr/bin/fdfs_test /etc/fdfs/client.conf upload test.txt 解压fastdfs-nginx-module的压缩包 进入到 解压目录/src/ 下，编辑 config 文件 12ngx_module_incs=&quot;/usr/include&quot;CORE_INCS=&quot;$CORE_INCS /usr/include&quot; 拷贝mod_fastdfs.conf 到/etc/fdfs/目录下 安装nginx，在 configure 命令后添加 –add-module=&lt;fastdfs-nginx-module解压目录&gt;/src 进入到 /etc/fdfs/ 目录下，编辑mod_fastdfs.conf 12345base_path=/data/fastdfs/tmptracker_server=&lt;tracker_server_ip&gt;:22122group_name=&lt;group_name&gt;url_have_group_name = truestore_path0=/data/fastdfs/storage 进入到nginx的conf文件夹中，修改nginx.conf文件，添加以下内容 1234567891011server &#123; listen 8888; ## 该端口为storage.conf中的http.server_port相同 server_name localhost; location &lt;group_name&gt;/M00 &#123; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动nginx，使用外部浏览器访问上传的测试文件 缺点 水平扩容 运维复杂 开发复杂 OSS优点 SDK简单 提供强大的文件处理功能 零运维成本 图形化管理控制台 CDN加速","categories":[],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"https://rabbit-mar.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"ElasticSearch学习之路(五)——常见异常","slug":"ElasticSearch学习之路(五)——常见异常","date":"2020-11-25T08:47:44.000Z","updated":"2021-02-18T14:59:18.672Z","comments":true,"path":"2020/11/25/ElasticSearch学习之路(五)——常见异常/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/25/ElasticSearch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%BA%94)%E2%80%94%E2%80%94%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8/","excerpt":"ElasticSearch学习笔记的第五节，主要记录一些经常会遇到的异常，在此处积累并给出解决方案","text":"常见异常处理circuit_breaking_exception12345678910111213141516171819&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;circuit_breaking_exception&quot;, &quot;reason&quot;: &quot;[parent] Data too large, data for [&lt;http_request&gt;] would be [126208648/120.3mb], which is larger than the limit of [123273216/117.5mb], real usage: [126208496/120.3mb], new bytes reserved: [152/152b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=152/152b, model_inference=0/0b, accounting=0/0b]&quot;, &quot;bytes_wanted&quot;: 126208648, &quot;bytes_limit&quot;: 123273216, &quot;durability&quot;: &quot;TRANSIENT&quot; &#125; ], &quot;type&quot;: &quot;circuit_breaking_exception&quot;, &quot;reason&quot;: &quot;[parent] Data too large, data for [&lt;http_request&gt;] would be [126208648/120.3mb], which is larger than the limit of [123273216/117.5mb], real usage: [126208496/120.3mb], new bytes reserved: [152/152b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=152/152b, model_inference=0/0b, accounting=0/0b]&quot;, &quot;bytes_wanted&quot;: 126208648, &quot;bytes_limit&quot;: 123273216, &quot;durability&quot;: &quot;TRANSIENT&quot; &#125;, &quot;status&quot;: 429&#125; 解决： 修改 config/jvm.options 中的 Xms 和 Xmx 的值 在 elasticsearch.yml 配置文件加上 1234567891011# 避免发生OOM，发生OOM对集群影响很大的indices.breaker.total.limit: 80%# 有了这个设置，最久未使用（LRU）的 fielddata 会被回收为新数据腾出空间 indices.fielddata.cache.size: 10%# fielddata 断路器默认设置堆的 作为 fielddata 大小的上限。indices.breaker.fielddata.limit: 60%# request 断路器估算需要完成其他请求部分的结构大小，例如创建一个聚合桶，默认限制是堆内存indices.breaker.request.limit: 60% json_e_o_f_exception12345678910111213&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;json_e_o_f_exception&quot;, &quot;reason&quot;: &quot;Unexpected end-of-input: expected close marker for Object (start marker at [Source: (byte[])\\&quot;POST /bank/account/_bulk?pretty&amp;refresh HTTP/1.1\\r\\nContent-Type: application/json\\r\\nUser-Agent: PostmanRuntime/7.26.5\\r\\nAccept: */*\\r\\nPostman-Token: 3a1bab39-c730-4bc1-b54e-7db2fdc3e57f\\r\\nHost: 192.168.1.5:9200\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nContent-Length: 349846\\r\\n\\r\\n&#123;\\r\\n \\&quot;index\\&quot;: &#123;\\r\\n \\&quot;_id\\&quot;: \\&quot;1\\&quot;\\r\\n &#125;\\r\\n&#125;\\r\\n&#123;\\r\\n \\&quot;account_number\\&quot;: 1,\\r\\n \\&quot;balance\\&quot;: 39225,\\r\\n \\&quot;firstname\\&quot;: \\&quot;Amber\\&quot;,\\r\\n \\&quot;lastname\\&quot;: \\&quot;Duke\\&quot;,\\r\\n \\&quot;age\\&quot;: 32,\\r\\n \\&quot;gender\\&quot;: \\&quot;M\\&quot;,\\r\\n \\&quot;address\\&quot;: \\&quot;88\\&quot;[truncated 65036 bytes]; line: 1, column: 1])\\n at [Source: (byte[])\\&quot;POST /bank/account/_bulk?pretty&amp;refresh HTTP/1.1\\r\\nContent-Type: application/json\\r\\nUser-Agent: PostmanRuntime/7.26.5\\r\\nAccept: */*\\r\\nPostman-Token: 3a1bab39-c730-4bc1-b54e-7db2fdc3e57f\\r\\nHost: 192.168.1.5:9200\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nContent-Length: 349846\\r\\n\\r\\n&#123;\\r\\n \\&quot;index\\&quot;: &#123;\\r\\n \\&quot;_id\\&quot;: \\&quot;1\\&quot;\\r\\n &#125;\\r\\n&#125;\\r\\n&#123;\\r\\n \\&quot;account_number\\&quot;: 1,\\r\\n \\&quot;balance\\&quot;: 39225,\\r\\n \\&quot;firstname\\&quot;: \\&quot;Amber\\&quot;,\\r\\n \\&quot;lastname\\&quot;: \\&quot;Duke\\&quot;,\\r\\n \\&quot;age\\&quot;: 32,\\r\\n \\&quot;gender\\&quot;: \\&quot;M\\&quot;,\\r\\n \\&quot;address\\&quot;: \\&quot;88\\&quot;[truncated 65036 bytes]; line: 2, column: 1]&quot; &#125; ], &quot;type&quot;: &quot;json_e_o_f_exception&quot;, &quot;reason&quot;: &quot;Unexpected end-of-input: expected close marker for Object (start marker at [Source: (byte[])\\&quot;POST /bank/account/_bulk?pretty&amp;refresh HTTP/1.1\\r\\nContent-Type: application/json\\r\\nUser-Agent: PostmanRuntime/7.26.5\\r\\nAccept: */*\\r\\nPostman-Token: 3a1bab39-c730-4bc1-b54e-7db2fdc3e57f\\r\\nHost: 192.168.1.5:9200\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nContent-Length: 349846\\r\\n\\r\\n&#123;\\r\\n \\&quot;index\\&quot;: &#123;\\r\\n \\&quot;_id\\&quot;: \\&quot;1\\&quot;\\r\\n &#125;\\r\\n&#125;\\r\\n&#123;\\r\\n \\&quot;account_number\\&quot;: 1,\\r\\n \\&quot;balance\\&quot;: 39225,\\r\\n \\&quot;firstname\\&quot;: \\&quot;Amber\\&quot;,\\r\\n \\&quot;lastname\\&quot;: \\&quot;Duke\\&quot;,\\r\\n \\&quot;age\\&quot;: 32,\\r\\n \\&quot;gender\\&quot;: \\&quot;M\\&quot;,\\r\\n \\&quot;address\\&quot;: \\&quot;88\\&quot;[truncated 65036 bytes]; line: 1, column: 1])\\n at [Source: (byte[])\\&quot;POST /bank/account/_bulk?pretty&amp;refresh HTTP/1.1\\r\\nContent-Type: application/json\\r\\nUser-Agent: PostmanRuntime/7.26.5\\r\\nAccept: */*\\r\\nPostman-Token: 3a1bab39-c730-4bc1-b54e-7db2fdc3e57f\\r\\nHost: 192.168.1.5:9200\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: keep-alive\\r\\nContent-Length: 349846\\r\\n\\r\\n&#123;\\r\\n \\&quot;index\\&quot;: &#123;\\r\\n \\&quot;_id\\&quot;: \\&quot;1\\&quot;\\r\\n &#125;\\r\\n&#125;\\r\\n&#123;\\r\\n \\&quot;account_number\\&quot;: 1,\\r\\n \\&quot;balance\\&quot;: 39225,\\r\\n \\&quot;firstname\\&quot;: \\&quot;Amber\\&quot;,\\r\\n \\&quot;lastname\\&quot;: \\&quot;Duke\\&quot;,\\r\\n \\&quot;age\\&quot;: 32,\\r\\n \\&quot;gender\\&quot;: \\&quot;M\\&quot;,\\r\\n \\&quot;address\\&quot;: \\&quot;88\\&quot;[truncated 65036 bytes]; line: 2, column: 1]&quot; &#125;, &quot;status&quot;: 400&#125; 解决： 每个item都应该在一行上，如果分隔了会包括额外的换行符。 illegal_argument_exception12345678910111213&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;The bulk request must be terminated by a newline [\\\\n]&quot; &#125; ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;The bulk request must be terminated by a newline [\\\\n]&quot; &#125;, &quot;status&quot;: 400&#125; 解决： 在json数据后面最后添加一个回车","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"}]},{"title":"ElasticSearch学习之路(四)——数据同步","slug":"ElasticSearch学习之路(四)——数据同步","date":"2020-11-25T08:45:30.000Z","updated":"2021-02-18T14:59:18.642Z","comments":true,"path":"2020/11/25/ElasticSearch学习之路(四)——数据同步/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/25/ElasticSearch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E5%9B%9B)%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/","excerpt":"ElasticSearch学习笔记的第四节，主要介绍使用logstash将mysql数据导入到ES中","text":"logstash数据同步 下载logstash对应的版本的压缩包，上传到服务器 解压文件到 /opt/logstash/ 目录下 进入解压文件中，新建 sync 文件夹，用于存放数据同步的配置文件 下载对应版本的数据库连接包，放到 sync 文件夹内 编写SQL查询文件 search.sql 12345678SELECT column1, column2, i.updated_time as updated_timeFROM tableWHERE &lt;condition&gt; AND i.updated_time &gt;= :sql_last_value 编写配置文件 logstash-db-sync.conf 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950input &#123; jdbc &#123; # 设置 Mysql、Mariadb 数据库的url以及数据库名称 jdbc_connection_string =&gt; &quot;jdbc:mysql://&lt;mysql_ip&gt;:&lt;mysql_port&gt;/&lt;db_name&gt;?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=GMT%2B8&amp;useSSL=false&quot; # 用户名和密码 jdbc_user =&gt; &quot;&lt;username&gt;&quot; jdbc_password =&gt; &quot;&lt;password&gt;&quot; # 数据库驱动所在位置，可以是绝对路径也可以是相对路径 jdbc_driver_library =&gt; &quot;&lt;logstash安装目录&gt;/sync/mysql-connector-java-5.1.46.jar&quot; # 驱动类名 jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; # 开启分页 jdbc_paging_enabled =&gt; &quot;true&quot; # 分页每页数量，可以自定义 jdbc_page_size =&gt; &quot;10000&quot; # 执行的sql文件路径 statement_filepath =&gt; &quot;&lt;logstash安装目录&gt;/sync/foodie-items.sql&quot; # 设置定时任务间隔 schedule =&gt; &quot;* * * * *&quot; # 索引类型 type =&gt; &quot;_doc&quot; # 是否开启记录上次追踪的结果，也就是上次更新得时间，这个会记录到 last_run_metadata_path 的文件 use_column_value =&gt; true # 记录上一次的追踪值 last_run_metadata_path =&gt; &quot;&lt;logstash安装目录&gt;/sync/track_time&quot; # 如果 use_column_value 为 true, 配置本参数，追踪 column 名，可以是id，也可以是更新时间 tracking_column =&gt; &quot;updated_time&quot; # tracking_column 对应字段的类型 tracking_column_type =&gt; &quot;timestamp&quot; # 是否清除 last_run_metadata_path 的记录，true每次都从头开始查询所有 clean_run =&gt; false # 数据库字段名称大写转小写 lowercase_column_names =&gt; false &#125;&#125;output &#123; elasticsearch &#123; # es地址 hosts =&gt; [&quot;&lt;es_ip&gt;:&lt;es_port&gt;&quot;] # 同步的索引名 index =&gt; &quot;&lt;index_name&gt;&quot; # 设置 _doc ID和数据相同(sql查询中的id值) document_id =&gt; &quot;%&#123;id&#125;&quot; &#125; # 日志输出 stdout &#123; codec =&gt; json_lines &#125;&#125; 进入bin目录输出命令执行数据同步 1./logstash -f /opt/logstash/logstash-7.10.0/sync/logstash-db-sync.conf 自定义模板 使用api接口获取模板 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172GET _template/logstash&#123; &quot;logstash&quot;: &#123; &quot;order&quot;: 0, &quot;version&quot;: 60001, &quot;index_patterns&quot;: [ &quot;logstash-*&quot; ], &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;number_of_shards&quot;: &quot;1&quot;, &quot;refresh_interval&quot;: &quot;5s&quot; &#125; &#125;, &quot;mappings&quot;: &#123; &quot;dynamic_templates&quot;: [ &#123; &quot;message_field&quot;: &#123; &quot;path_match&quot;: &quot;message&quot;, &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot; &#125;, &quot;match_mapping_type&quot;: &quot;string&quot; &#125; &#125;, &#123; &quot;string_fields&quot;: &#123; &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;ignore_above&quot;: 256, &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;geoip&quot;: &#123; &quot;dynamic&quot;: true, &quot;properties&quot;: &#123; &quot;ip&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125;, &quot;latitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125;, &quot;location&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125;, &quot;longitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125; &#125; &#125;, &quot;@version&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;aliases&quot;: &#123;&#125; &#125;&#125; 修改该json文件为下列json文件，添加ik分词器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&#123; &quot;order&quot;: 0, &quot;version&quot;: 1, &quot;index_patterns&quot;: [&quot;foodie-*&quot;], &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;number_of_shards&quot;: &quot;1&quot;, &quot;refresh_interval&quot;: &quot;5s&quot; &#125; &#125;, &quot;mappings&quot;: &#123; &quot;dynamic_templates&quot;: [ &#123; &quot;message_field&quot;: &#123; &quot;path_match&quot;: &quot;message&quot;, &quot;mapping&quot;: &#123; &quot;norms&quot;: false, &quot;type&quot;: &quot;text&quot; &#125;, &quot;match_mapping_type&quot;: &quot;string&quot; &#125; &#125;, &#123; &quot;string_fields&quot;: &#123; &quot;mapping&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;norms&quot;: false, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;ignore_above&quot;: 256, &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;match&quot;: &quot;*&quot; &#125; &#125; ], &quot;properties&quot;: &#123; &quot;@timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;geoip&quot;: &#123; &quot;dynamic&quot;: true, &quot;properties&quot;: &#123; &quot;ip&quot;: &#123; &quot;type&quot;: &quot;ip&quot; &#125;, &quot;latitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125;, &quot;location&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125;, &quot;longitude&quot;: &#123; &quot;type&quot;: &quot;half_float&quot; &#125; &#125; &#125;, &quot;@version&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;aliases&quot;: &#123;&#125;&#125; 将上述的json文件拷贝至 sync/logstash-ik.json 文件中 在logstash运行配置文件中添加以下配置 123456789101112output &#123; elasticsearch &#123; # 定义模板名称 template_name =&gt; &quot;ik_template&quot; # 模板所在位置 template =&gt; &quot;&lt;logstash安装目录&gt;/sync/logstash-ik.json&quot; # 重写模板 template_overwrite =&gt; true # 默认为true，false关闭logstash自动管理模板功能，如果自定义模板，则设置为false manage_template =&gt; false &#125;&#125; 如果之前同步过数据需要重新创建新索引 运行logstash脚本 ※ 如果上述方式不生效，可以采用以下方式 使用api接口获取模板 修改该json文件为上述文件，添加ik分词器 使用api接口删除es自带模板 1DELETE _template/logstash?pretty 使用命令设置新模板 1234POST _template/logstash&#123; # …… 新json模板&#125; 启动logstash脚本","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"}]},{"title":"ElasticSearch学习之路(三)——ES的集群","slug":"ElasticSearch学习之路(三)——ES的集群","date":"2020-11-25T08:28:58.000Z","updated":"2021-02-18T14:59:18.561Z","comments":true,"path":"2020/11/25/ElasticSearch学习之路(三)——ES的集群/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/25/ElasticSearch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%B8%89)%E2%80%94%E2%80%94ES%E7%9A%84%E9%9B%86%E7%BE%A4/","excerpt":"ElasticSearch学习笔记的第三节，主要介绍ES的集群搭建及集群模式","text":"es 集群如果一个索引有5个分片，每个分片有一个备份化，当实现三台es集群的时候，每台服务器相互备份，主分片与备份分片不能在同一台服务器上。如果其中一台服务器宕机，其备份不会丢失。 搭建es集群 拷贝已安装的es文件夹到其他服务器上 修改config/elasticsearch.yml文件，添加以下配置 12345678node.name: es-node1# node.name: es-node2# node.name: es-node3node.master: truenode.data: truediscovery.seed_hosts: [&quot;ip1&quot;, &quot;ip2&quot;, &quot;ip3&quot;] 使用命令忽略注释查看配置 1more elasticsearch.yml | grep ^[^#] 添加es用户，给es安装目录授权 12useradd eschown -R es:es &lt;es安装目录&gt;/ 编辑 /etc/security/limits.conf ，添加以下配置 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 编辑 /etc/sysctl.conf 文件，添加以下配置 1vm.max_map_count=262145 刷新配置 1sysctl -p 切换到es用户，启动三台es服务 文档写原理当ES集群发生写操作的时候，客户端会选择其中一个节点进行处理，该节点被认为为协调节点，由该节点进行计算，该数据存在于哪一个分片上，进行文档路由并转发，并将数据同步给备份节点，写操作完成后返回协调节点响应给客户端。 文档读操作当ES集群发生读操作的时候，客户端会选择其中一个节点进行处理，该节点被认为为协调节点，由该节点进行计算，该数据存在于哪一个分片上，从主分片或者备份分片进行轮询读操作，并将数据返回给协调节点，响应给客户端。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"}]},{"title":"ElasticSearch学习之路(二)——ES的检索","slug":"ElasticSearch学习之路(二)——ES的检索","date":"2020-11-25T08:24:49.000Z","updated":"2021-02-18T14:59:18.505Z","comments":true,"path":"2020/11/25/ElasticSearch学习之路(二)——ES的检索/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/25/ElasticSearch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%BA%8C)%E2%80%94%E2%80%94ES%E7%9A%84%E6%A3%80%E7%B4%A2/","excerpt":"ElasticSearch学习笔记的第二节，主要记录ES的检索方式，主要以官网地址为主，后续会添加部分原理","text":"REST APIs操作官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/rest-apis.html 文档乐观锁控制使用if_seq_no(序列号，修改一次会累加)和if_primary_term(该数据在集群中的位置)来进行控制，在更新操作时添加上这两个参数 官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/optimistic-concurrency-control.html DSL搜索官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-your-data.html 官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html 使用QueryString的方式进行查询 1GET &lt;index&gt;/&lt;doc&gt;/_search?q=&lt;k1&gt;:&lt;v1&gt;&amp;q=&lt;k2&gt;:&lt;v2&gt; 使用结构化查询语句进行查询 12345678GET &lt;index&gt;/&lt;doc&gt;/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;k1&quot;: &quot;v1&quot; &#125; &#125;&#125; 深度分页 es中使用from和size来进行分页搜索，但是当我们的form+size超过一万时会抛出异常 官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#search-after 避免过度使用from和size来分页或一次请求太多结果。 搜索请求通常跨越多个分片。 每个分片都必须将其请求的命中点以及之前任何页面的命中点加载到内存中。 对于较深的页面或大量结果，这些操作会显着增加内存和CPU使用率，从而导致性能下降或节点故障。 默认情况下，您不能使用“from”到“size”翻页超过10,000个匹配项。 此限制是index.max_result_window索引设置所设置的保护措施。 如果您需要分页浏览超过10,000个匹配项，请改用search_after参数。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"}]},{"title":"ElasticSearch学习之路(一)——ES的安装","slug":"ElasticSearch学习之路(一)——ES的安装","date":"2020-11-25T08:21:23.000Z","updated":"2021-02-18T14:59:18.710Z","comments":true,"path":"2020/11/25/ElasticSearch学习之路(一)——ES的安装/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/25/ElasticSearch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%B8%80)%E2%80%94%E2%80%94ES%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"ElasticSearch的学习笔记第一节，记录ES的安装以及es-head的安装，ik分词器的安装","text":"elasticsearch 安装安装包安装 下载安装包上传到服务器中 解压文件存放在 /opt/es/ 目录下（根据个人） 进入到解压文件中，新建一个 data 文件夹 进入config文件夹， 编辑elasticsearch.yml文件，编辑完成后保存退出 12345678910cluster.name: esnode.name: es-node1path.data: /opt/es/&lt;es解压文件夹&gt;/datapath.logs: /opt/es/&lt;es解压文件夹&gt;/logsnetwork.host: 0.0.0.0http.port: 9200cluster.initial_master_nodes: [&quot;es-node1&quot;] 编辑 jvm.options文件 12-Xms128m-Xmx128m es 不允许root用户进行操作，新建一个 es 用户 1useradd es 给es解压文件夹进行授权 1chown -R es:es &#x2F;opt&#x2F;es&#x2F;&lt;es解压文件夹&gt; 编辑 /etc/security/limits.conf ，添加以下配置 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 编辑 /etc/sysctl.conf 文件，添加以下配置 1vm.max_map_count&#x3D;262145 刷新配置 1sysctl -p 切换到 es 用户 1su es 进入 bin 目录启动es 1.&#x2F;elasticsearch 如果出现AccessDeniedException，则切换到root用户重新授权 1234su rootchown -R es:es &#x2F;opt&#x2F;es&#x2F;&lt;es解压文件夹&gt;su es.&#x2F;elasticsearch 后台执行es 1.&#x2F;elasticsearch -d 安装es-head github：https://github.com/mobz/elasticsearch-head ※ 推荐使用chrome插件安装 ElasticSearch Head 如果出现跨域问题，修改安装包中的 elasticsearch.yml ，添加以下配置 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 分词器把文本转换为一个个的单词，分词称之为analysis，es默认支队英文语句做分词，中文不支持，每个中文都会被拆分为独立的个体。 使用API进行分词分析 12345678910POST _analyze&#123; &quot;analyzer&quot;: &quot;standard/simple/whitespace/stop/keyword&quot;, &quot;text&quot;: &quot;this is a test segement&quot;&#125;// standard: 默认分词，单词会被拆分，大小会转换为小写。// simple：按照非字母单词分词，大写转为小写。// whitespace：按照空格分词，忽略大小写。// stop：去除无意义单词，比如the/a/an/is...// keyword：不做分词，把整个文本作为一个单独的关键字 使用ik分词器github：https://github.com/medcl/elasticsearch-analysis-ik 手动安装 在github上下载对应版本的ik分词器压缩包 上传到服务器 创建目录 &lt;es安装目录&gt;/plugins/ik 解压ik分词器到创建的目录中 重启es elasticsearch 插件安装1./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v&lt;es版本&gt;/elasticsearch-analysis-ik-&lt;es版本&gt;.zip ik分词器使用1234567POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word/ik_smart&quot;, &quot;text&quot;: &quot;这是一条测试语句&quot;&#125;// k_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query；// ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase 查询。 自定义中文词库 进入IK分词器插件目录下的config文件夹中 编辑 IKAnalyzer.cfg.xml 文件，保存退出 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;custom/mydict.dic;custom/single_word_low_freq.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;custom/ext_stopword.dic&lt;/entry&gt;&lt;/properties&gt; 重启es服务 热更新IK分词 进入IK分词器插件目录下的config文件夹中 编辑 IKAnalyzer.cfg.xml 文件，保存退出 1234&lt;!--用户可以在这里配置远程扩展字典 --&gt;&lt;entry key=&quot;remote_ext_dict&quot;&gt;location&lt;/entry&gt;&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;&lt;entry key=&quot;remote_ext_stopwords&quot;&gt;location&lt;/entry&gt; 其中 location 是指一个 url，比如 http://yoursite.com/getCustomDict，该请求只需满足以下两点即可完成分词热更新。 该 http 请求需要返回两个头部(header)，一个是 Last-Modified，一个是 ETag，这两者都是字符串类型，只要有一个发生变化，该插件就会去抓取新的分词进而更新词库。 该 http 请求返回的内容格式是一行一个分词，换行符用 \\n 即可。 满足上面两点要求就可以实现热更新分词了，不需要重启 ES 实例。 可以将需自动更新的热词放在一个 UTF-8 编码的 .txt 文件里，放在 nginx 或其他简易 http server 下，当 .txt 文件修改时，http server 会在客户端请求该文件时自动返回相应的 Last-Modified 和 ETag。可以另外做一个工具来从业务系统提取相关词汇，并更新这个 .txt 文件。 重启es服务","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"}]},{"title":"自定义基于注解的Redis缓存","slug":"自定义基于注解的Redis缓存","date":"2020-11-15T07:02:37.000Z","updated":"2021-02-18T14:54:08.054Z","comments":true,"path":"2020/11/15/自定义基于注解的Redis缓存/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/15/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84Redis%E7%BC%93%E5%AD%98/","excerpt":"笔者由于使用Springboot自带的Cacheable注解的key值不方便自定义，于是自定义了一个RedisCache的注解","text":"自定义基于注解的Redis缓存笔者由于使用Springboot自带的Cacheable注解的key值不方便自定义，于是自定义了一个RedisCache的注解，作用于方法上，用于将结果保存在多个key值上，并且可通过#{参数名}的方式进行注入参数值，同时可设置ttl以及是否缓存null值等操作 采用kryo作为redis的值序列化导入依赖123456&lt;!-- kryo --&gt;&lt;dependency&gt; &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt; &lt;artifactId&gt;kryo&lt;/artifactId&gt; &lt;version&gt;$&#123;kryo.version&#125;&lt;/version&gt;&lt;/dependency&gt; Redis配置类笔者配置的Redis配置类，采用Lettuce连接池的单机配置，下方采用KryoRedisSerializer类作为值序列化工具 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293@Configurationpublic class RedisConfig &#123; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private Integer port; @Value(&quot;$&#123;spring.redis.password:&#125;&quot;) private String password; @Value(&quot;$&#123;spring.redis.database&#125;&quot;) private Integer database; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(factory); redisTemplate.setKeySerializer(new Jackson2JsonRedisSerializer&lt;&gt;(String.class)); redisTemplate.setValueSerializer(new KryoRedisSerializer&lt;&gt;(Object.class)); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125; @Bean public RedisConnectionFactory factory(RedisStandaloneConfiguration standaloneConfig) &#123; return new LettuceConnectionFactory(standaloneConfig); &#125; @Bean public RedisStandaloneConfiguration standaloneConfig() &#123; RedisStandaloneConfiguration standaloneConfiguration = new RedisStandaloneConfiguration(); standaloneConfiguration.setHostName(host); standaloneConfiguration.setPort(port); standaloneConfiguration.setPassword(password); standaloneConfiguration.setDatabase(database); return standaloneConfiguration; &#125; private static class KryoRedisSerializer&lt;T&gt; implements RedisSerializer&lt;T&gt; &#123; Logger logger = LoggerFactory.getLogger(KryoRedisSerializer.class); public static final byte[] EMPTY_BYTE_ARRAY = new byte[0]; private static final ThreadLocal&lt;Kryo&gt; kryos = ThreadLocal.withInitial(Kryo::new); private final Class&lt;T&gt; clazz; public KryoRedisSerializer(Class&lt;T&gt; clazz) &#123; super(); this.clazz = clazz; &#125; @Override public byte[] serialize(T t) throws SerializationException &#123; if (t == null) &#123; return EMPTY_BYTE_ARRAY; &#125; Kryo kryo = kryos.get(); kryo.setReferences(false); kryo.register(clazz); try (ByteArrayOutputStream baos = new ByteArrayOutputStream(); Output output = new Output(baos)) &#123; kryo.writeClassAndObject(output, t); output.flush(); return baos.toByteArray(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return EMPTY_BYTE_ARRAY; &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; if (bytes == null || bytes.length &lt;= 0) &#123; return null; &#125; Kryo kryo = kryos.get(); kryo.setReferences(false); kryo.register(clazz); try (Input input = new Input(bytes)) &#123; return (T) kryo.readClassAndObject(input); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return null; &#125; &#125;&#125; RedisCache 注解类其中每个属性都有注解 keys 缓存Keys值 cacheNull 是否缓存null值 ttl 生存时间 timeunit 时间单位 flush 是否每次刷新缓存 1234567891011121314151617181920@Target(&#123; ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)public @interface RedisCache &#123; // 缓存Keys值 String[] keys(); // 是否缓存null值 boolean cacheNull() default false; // 生存时间，默认为-1 int ttl() default -1; // 时间单位，默认秒 TimeUnit timeUnit() default TimeUnit.SECONDS; // 每访问一次刷新缓存，默认为false // 如果为true相当于没有获取缓存数据 boolean flush() default false;&#125; 切面类注解实现的主体，通过拦截RedisCache注解，采用Springboot的AOP功能，在方法执行前获取到执行RedisCache的方法，以及属性，在方法执行之后进行结果缓存 ※ 值得注意的是在替换#{参数名}的时候，时间复杂度为 M x N ，效率比较低，如果有更好的方法，欢迎读者留言或者联系我 ※ 还有就是在进行参数名替换时，要求参数为一个普通类型(具体参见isCommonType方法) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175@Aspect@Component@Lazy(false)public class RedisCacheAspect &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisCacheAspect.class); // 用于存放被调用的方法 private final ThreadLocal&lt;Method&gt; methodTL = new ThreadLocal&lt;&gt;(); @Autowired private RedisOperator redisOperator; @Pointcut(&quot;@annotation(com.marveal.cache.RedisCache)&quot;) private void point() &#123; &#125; @Around(&quot;point()&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; // 获取 RedisCache 注解 RedisCache redisCache = getRedisCacheAnnotation(joinPoint); // 获取解析后的key Set&lt;String&gt; keys = parseKey(joinPoint, redisCache); Assert.notEmpty(keys, &quot;RedisCache &gt;&gt; keys 不能为空&quot;); // redis中获取缓存值 Object data = getDateFromRedis(keys, methodTL.get()); // 1. 缓存中没有值 // 2. 缓存中有值，不需要刷新缓存 if (!ObjectUtils.isEmpty(data) &amp;&amp; !redisCache.flush()) &#123; return data; &#125; // 执行方法获取结果 data = joinPoint.proceed(); // 存入结果到redis中 cacheResult(redisCache, keys, data); return data; &#125; /** * 获取方法上的 RedisCache 注解 * * @param joinPoint 切点 * @return RedisCache 注解 * @throws NoSuchMethodException 没有获取到方法 */ private RedisCache getRedisCacheAnnotation(ProceedingJoinPoint joinPoint) throws NoSuchMethodException &#123; // 获取该注解的类 Class&lt;?&gt; clazz = joinPoint.getTarget().getClass(); // 获取该注解的方法名 String methodName = joinPoint.getSignature().getName(); // 获取该注解的方法参数 Class&lt;?&gt;[] paramTypes = ((MethodSignature) joinPoint.getSignature()).getParameterTypes(); // 根据类，方法，方法参数获取到具体的方法 Method method = clazz.getMethod(methodName, paramTypes); // 获取该方法，用于在解析json字符串时使用 methodTL.set(method); return method.getAnnotation(RedisCache.class); &#125; /** * 解析缓存keys值 * * @param joinPoint 切点 * @param redisCache RedisCache 注解 * @return 解析后的keys值 */ private Set&lt;String&gt; parseKey(ProceedingJoinPoint joinPoint, RedisCache redisCache) &#123; // 获取方法参数 Object[] params = joinPoint.getArgs(); // 获取参数名 String[] paramNames = ((MethodSignature) joinPoint.getSignature()).getParameterNames(); // 获取原始key值 String[] keys = redisCache.keys(); final int len = keys.length; // keys值为空列表报错 if (len &lt; 1) &#123; return null; &#125; // 如果没有参数，就返回原始keys值 if (ObjectUtils.isEmpty(params) || ObjectUtils.isEmpty(paramNames)) &#123; return new HashSet&lt;&gt;(Arrays.asList(keys)); &#125; Set&lt;String&gt; keysSet = new HashSet&lt;&gt;(); // 遍历keys数组,进行参数替换 for (String key : keys) &#123; keysSet.add(replaceKey(key, paramNames, params)); &#125; return keysSet; &#125; /** * 替换key字符串 #&#123;id&#125; 替换为真正的数据 * * @param key 源keys值 * @param paramNames 参数名 * @param params 参数值 * @return 替换后的key字符串 */ private String replaceKey(String key, String[] paramNames, Object[] params) &#123; final int len = paramNames.length; for (int i = 0; i &lt; len; i++) &#123; String oldStr = &quot;#&#123;&quot; + paramNames[i] + &quot;&#125;&quot;; boolean commonType = isCommonType(params[i]); if (key.contains(oldStr) &amp;&amp; commonType) &#123; key = key.replace(oldStr, String.valueOf(params[i])); &#125; else if (!commonType) &#123; LOGGER.error(&quot;&#123;&#125; is not a common type : [String, Integer, Float, Double, Long, Byte, Character, Boolean]&quot;, paramNames[i]); &#125; &#125; return key; &#125; /** * 判断对象是否为 普通对象 * * @param obj 对象 * @return true | false */ private boolean isCommonType(Object obj) &#123; return obj instanceof String || obj instanceof Integer || obj instanceof Float || obj instanceof Double || obj instanceof Long || obj instanceof Byte || obj instanceof Character || obj instanceof Boolean; &#125; /** * 缓存结果 * * @param redisCache RedisCache 注解 * @param cacheKeys 缓存值 * @param data 需要缓存的数据 */ private void cacheResult(RedisCache redisCache, Set&lt;String&gt; cacheKeys, Object data) &#123; // 结果为null, 要求不缓存null, 就不缓存 if (data == null &amp;&amp; !redisCache.cacheNull()) return; // 获取时间 int ttl = redisCache.ttl(); // 根据key值批量缓存 if (ttl &gt; 0) &#123; TimeUnit timeUnit = redisCache.timeUnit(); redisOperator.saveBatchWithEx(cacheKeys, data, ttl, timeUnit); &#125; else &#123; redisOperator.saveBatch(cacheKeys, data); &#125; &#125; /** * 从redis中获取数据 * * @param cacheKeys 缓存的key值列表 * @return 数据 */ private Object getDateFromRedis(Set&lt;String&gt; cacheKeys, Method method) throws ClassNotFoundException &#123; Class&lt;?&gt; returnType = method.getReturnType(); if (returnType == void.class) &#123; return null; &#125; // 获取数据 return redisOperator.get(cacheKeys); &#125;&#125; Redis 工具类笔者封装了一些方法进行调用 ※ 注意: 在从多个key值中获取值时，返回超过一半的相同数据 例如： 一个key，至少一个数据有值 三个key，返回两个是相同的数据 五个key，返回三个是相同的数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Componentpublic class RedisOperator &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; /** * 批量插入 * * @param cacheNames 缓存key值 * @param data 需要缓存的数据 */ public void saveBatch(Collection&lt;String&gt; cacheNames, Object data) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); for (String cacheName : cacheNames) &#123; map.put(cacheName, data); &#125; try &#123; redisTemplate.opsForValue().multiSet(map); &#125; catch (Exception e) &#123; throw new BusinessException(&quot;批量插入缓存失败&quot;); &#125; &#125; /** * lua脚本批量插入(含过期时间) * * @param cacheNames 缓存key值 * @param data 需要缓存的数据 * @param ttl 过期时间 * @param timeUnit 时间单位 */ public void saveBatchWithEx(Collection&lt;String&gt; cacheNames, Object data, int ttl, TimeUnit timeUnit) &#123; DefaultRedisScript&lt;Boolean&gt; redisScriptBoolean = new DefaultRedisScript&lt;&gt;(); redisScriptBoolean.setResultType(Boolean.class); redisScriptBoolean.setScriptSource( new ResourceScriptSource(new ClassPathResource(&quot;redis/script/saveBatchWithEx.lua&quot;))); long ex = timeUnit.toSeconds(ttl); Boolean success = redisTemplate.execute(redisScriptBoolean, new ArrayList&lt;&gt;(cacheNames), data, ex); if (success == null || !success) &#123; throw new BusinessException(&quot;执行lua脚本失败&quot;, ExceptionType.LUA_EXECUTE_EXCEPTION); &#125; &#125; /** * 从redis中获取数据 * 从多个key中获取数据，返回超过一半的相同数据 * 如果没有数据超过一半，则返回null值 * * @param cacheKeys 缓存的key值列表 * @return 数据 */ public Object get(Collection&lt;String&gt; cacheKeys) &#123; if (cacheKeys == null || cacheKeys.size() &lt; 1) return null; final int len = cacheKeys.size(); List&lt;Object&gt; resultList = redisTemplate.opsForValue().multiGet(cacheKeys); if (resultList == null || resultList.size() &lt; 1) &#123; return null; &#125; Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for (Object result : resultList) &#123; String md5Str = MD5Utils.getMD5Str(String.valueOf(result)); map.put(md5Str, map.getOrDefault(md5Str, 1) + 1); if (map.get(md5Str) &gt; len &gt;&gt; 1) &#123; return result; &#125; &#125; return null; &#125;&#125; 用于批量插入含过期时间的lua文件采用for循环的方式进行插入 123456local keys, data, ex = KEYS, ARGV[1], ARGV[2]local resultfor i,key in ipairs(keys) do result = redis.call(&#x27;setex&#x27;, key, ex, data)endreturn true 使用1234@RedisCache(keys = &#123;&quot;TEST:#&#123;id&#125;&quot;&#125;)public POJO query(Integer id) &#123; return mapper.select(id);&#125;","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"},{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"NGINX详解六：高可用——LVS+keepalived","slug":"NGINX详解六：高可用——LVS-keepalived","date":"2020-11-05T22:16:52.000Z","updated":"2021-02-18T14:52:49.660Z","comments":true,"path":"2020/11/06/NGINX详解六：高可用——LVS-keepalived/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E5%85%AD%EF%BC%9A%E9%AB%98%E5%8F%AF%E7%94%A8%E2%80%94%E2%80%94LVS-keepalived/","excerpt":"NGINX详解第六章——使用LVS+Keepalived搭建NGINX高可用集群","text":"Keepalived + LVS + NGINX高可用配置master节点 配置keepalived.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667! Configuration File for keepalivedglobal_defs &#123; router_id keep_005&#125;vrrp_instance VI_1 &#123; state MASTER interface enp0s3 virtual_router_id 41 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.200 &#125;&#125;# 配置集群地址访问的IP+端口，端口和NGINX保持一致，都是80virtual_server 192.168.1.200 80 &#123; # 健康检查的时间，单位：秒 delay_loop 6 # 配置负载均衡的算法，默认是轮询 lb_algo rr # 设置LVS的模式 NAT|TUN|DR lb_kind DR # 设置会话持久化的时间 persistence_timeout 5 # 协议 -t protocol TCP # 配置真实服务器 real_server 192.168.1.100 80 &#123; # 轮询权重配比 weight 1 # 设置健康检查 TCP_CHECK &#123; # 检查的80端口 connect_port 80 # 超时时间 2s connect_timeout 2 # 重试次数 2次 nb_get_retry 2 # 间隔时间 3s delay_before_retry 3 &#125; &#125; real_server 192.168.1.101 80 &#123; # 轮询权重配比 weight 1 # 设置健康检查 TCP_CHECK &#123; # 检查的80端口 connect_port 80 # 超时时间 2s connect_timeout 2 # 重试次数 2次 nb_get_retry 2 # 间隔时间 3s delay_before_retry 3 &#125; &#125;&#125; 清除LVS配置 ipvsadm -C ipvsadm -Ln 重启keepalived服务，查看LVS配置 systemctl restart keepalived ipvsadm -Ln 配置backup节点 配置keepalived.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667! Configuration File for keepalivedglobal_defs &#123; router_id keep_006&#125;vrrp_instance VI_1 &#123; state BACKUP interface enp0s3 virtual_router_id 41 priority 50 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.200 &#125;&#125;# 配置集群地址访问的IP+端口，端口和NGINX保持一致，都是80virtual_server 192.168.1.200 80 &#123; # 健康检查的时间，单位：秒 delay_loop 6 # 配置负载均衡的算法，默认是轮询 lb_algo rr # 设置LVS的模式 NAT|TUN|DR lb_kind DR # 设置会话持久化的时间 persistence_timeout 5 # 协议 -t protocol TCP # 配置真实服务器 real_server 192.168.1.100 80 &#123; # 轮询权重配比 weight 1 # 设置健康检查 TCP_CHECK &#123; # 检查的80端口 connect_port 80 # 超时时间 2s connect_timeout 2 # 重试次数 2次 nb_get_retry 2 # 间隔时间 3s delay_before_retry 3 &#125; &#125; real_server 192.168.1.101 80 &#123; # 轮询权重配比 weight 1 # 设置健康检查 TCP_CHECK &#123; # 检查的80端口 connect_port 80 # 超时时间 2s connect_timeout 2 # 重试次数 2次 nb_get_retry 2 # 间隔时间 3s delay_before_retry 3 &#125; &#125;&#125; 清除LVS配置 重启keepalived服务，查看LVS配置","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解六：高可用——LVS","slug":"NGINX详解六：高可用——LVS","date":"2020-11-05T22:14:24.000Z","updated":"2021-02-18T14:52:49.695Z","comments":true,"path":"2020/11/06/NGINX详解六：高可用——LVS/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E5%85%AD%EF%BC%9A%E9%AB%98%E5%8F%AF%E7%94%A8%E2%80%94%E2%80%94LVS/","excerpt":"NGINX详解第六章——使用LVS","text":"LVS负载均衡 LVS基于四层，工作效率高 单个Nginx承受不了压力，需要集群 LVS充当Nginx集群的调度者 Nginx接受请求来回，LVS可以只接受不响应 LVS网络拓扑图 LVS工作模式 NAT 每次请求服务器由LVS进行请求，处理完成后返回到LVS，返回的IP为LVS的虚拟IP（VIP） TUN 隧道模式。当使用TUN时，服务器必须有网卡，进行建立隧道。 DR 直接路由模式。请求处理后返回到Router中统一返回 搭建LVS-DR模式服务器IP约定 关闭LVS和NGINX服务器的网络配置管理器 systemctl stop NetworkManager 配置LVS服务器 进入到网卡文件，拷贝自己的网卡文件 cd /etc/sysconfig/network-scripts/ cp ifcfg-enp0s3 ifcfg-enp0s3:1 编辑拷贝后的网卡文件 vim ifcfg-enp0s3:1 12345BOOTPROTO&#x3D;&quot;static&quot;DEVICE&#x3D;&quot;enp0s3:1&quot;ONBOOT&#x3D;&quot;yes&quot;IPADDR&#x3D;192.168.1.200NETMASK&#x3D;255.255.255.0 重启网络服务，查看虚拟IP地址是否配置完成 systemctl restart network ip addr 安装集群管理工具，输入命令查看集群列表 yum install ipvsadm ipvsadm -Ln 配置NGINX服务器 进入到网卡文件，拷贝自己的环回地址配置文件 cd /etc/sysconfig/network-scripts/ cp ifcfg-lo ifcfg-lo:1 编辑拷贝的环回地址配置文件 vim ifcfg-lo:1 123456789DEVICE&#x3D;lo:1IPADDR&#x3D;192.168.1.200NETMASK&#x3D;255.255.255.255NETWORK&#x3D;127.0.0.0# If you&#39;re having problems with gated making 127.0.0.0&#x2F;8 a martian,# you can change this to something else (255.255.255.255, for example)BROADCAST&#x3D;127.255.255.255ONBOOT&#x3D;yesNAME&#x3D;loopback 输入命令刷新环回地址配置，查看IP地址配置是否生效 ifup lo ip addr 同样方法配置第二台NGINX服务器 针对ARP配置 arp-ignore ： ARP响应级别(处理请求) 0：只要本机配置了IP，就能响应请求1： 请求的目标地址到达对应的网络接口，才会响应请求 arp-announce ： ARP通告行为(返回响应) 0： 本机上人喝网络接口都向外通告，所有的网卡都能接受到通告1： 尽可能避免本网卡与不匹配的目标进行通告2： 只在本网卡通告 修改第一台NGINX服务的 sysctl.conf 文件 vim /etc/sysctl.conf 1234567&gt;# configuration for lvs &gt;net.ipv4.conf.all.arp_ignore &#x3D; 1 &gt;net.ipv4.conf.default.arp_ignore &#x3D; 1 &gt;net.ipv4.conf.lo.arp_ignore &#x3D; 1 &gt;net.ipv4.conf.all.arp_announce &#x3D; 2 &gt;net.ipv4.conf.default.arp_announce &#x3D; 2 &gt;net.ipv4.conf.lo.arp_announce &#x3D; 2 刷新配置 sysctl -p 添加host路由，查看是否配置成功 route add -host 192.168.1.200 dev lo:1 route -n 由于添加的路由为临时生效，所以需要添加到开机自启动中 echo “route add -host 192.168.1.200 dev lo:1” &gt;&gt; /etc/rc.local 第二台NGINX做同样的配置 使用ipvsadm配置集群规则 配置LVS服务器添加配置 ipvsadm -A -t 192.168.1.200:80 -s rr ipvsadm -a -t 192.168.1.200:80 -r 192.168.1.100:80 -g ipvsadm -a -t 192.168.1.200:80 -r 192.168.1.101:80 -g ipvsadm -Ln LVS持久化 在浏览器中请求192.168.1.200:80发现只171节点，由于LVS存在着持久化链接，使用 man ipvsadm 命令查看-p命令 Specify that a virtual service is persistent. If this option is specified,multiple requests from a client are redirected to the same real server selected for the first request. Optionally, the timeout of persistent sessions may be specified given in seconds, otherwise the default of 300 seconds will be used. This option may be used in conjunction with protocols such as SSL or FTP where it is important that clients consistently connect with the same real server. 指定虚拟服务是持久性的。 如果指定了此选项，则来自客户端的多个请求将重定向到为第一个请求选择的同一真实服务器。 （可选）可以以秒为单位指定持久会话的超时，否则将使用默认值300秒。 此选项可以与SSL或FTP等协议结合使用，在这些协议中，客户端始终与同一台真实服务器连接非常重要。 设置持久化时间 ipvsadm -E -t 192.168.1.200:80 -s rr -p 3 ipvsadm -Ln 再去访问同样没有变化，因为LVS中还存在着TCP的连接时间，修改TCP连接时间，等待过期时间结束，就可以发现出现效果 ipvsadm –set 1 1 1 ipvsadm -Lnc","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解六：高可用——keepalived","slug":"NGINX详解六：高可用——keepalived","date":"2020-11-05T22:05:46.000Z","updated":"2021-02-18T14:52:49.572Z","comments":true,"path":"2020/11/06/NGINX详解六：高可用——keepalived/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E5%85%AD%EF%BC%9A%E9%AB%98%E5%8F%AF%E7%94%A8%E2%80%94%E2%80%94keepalived/","excerpt":"NGINX详解的第六章——使用keepalived配置NGINX的高可用","text":"Nginx高可用nginx的高可用通过主备机的方式实现，如果主节点宕机后备用节点才会工作。 keepalived检测nginx状态，如果发生故障就会切换到备用机，并且发送信息给root用户 解决单点故障 组件免费 可以实现高可用HA机制 基于VRRP协议 虚拟路由冗余协议 VRRP全称为Virtual Router Redundancy Protocol，解决内网单机故障的路由协议，构建有多个路由器MASTER BACKUP，绑定虚拟IP（Virtual IP Address）。 keepalived 双机主备原理使用keepalived会有一个虚拟IP，用户直接请求到虚拟IP，Nginx绑定虚拟IP，那么访问虚拟IP就会直接访问到Nginx。如果Nginx挂掉后，由于虚拟IP会进行心跳检测，那么虚拟IP就会请求到备用机。 但是如果使用keepalived的方式实现高可用，那么Nginx服务器的硬件配置需要保持一致。如果主Nginx的配置高，可以处理100W个请求，那么如果主Nginx宕机后请求会打到备用机上，同样会导致备用机Nginx宕机。 安装keepalived 下载文件：https://www.keepalived.org/download.html 上传文件到服务器，解压文件，放置在 /opt/keepalived 进入安装目录，执行命令安装 123.&#x2F;configure \\--prefix&#x3D;&#x2F;opt&#x2F;keepalived&#x2F;keepalived \\--sysconf&#x3D;&#x2F;etc make &amp;&amp; make install # 编译安装 配置keepalived123456789101112131415161718192021222324252627282930313233343536373839404142434445# 全局配置global_defs &#123; # 发生故障后通知的邮箱地址 notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; # 通知的邮箱 notification_email_from Alexandre.Cassen@firewall.loc # smtp的服务器 smtp_server 192.168.200.1 # smtp连接超时时间 smtp_connect_timeout 30 # 路由ID，保证为全局唯一 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;# 基于vrrp协议的实例（计算机节点）vrrp_instance VI_1 &#123; # 表示的状态，当前为主结点 state MASTER # 当前实例绑定的网卡 interface eth0 # 保证主备节点一致，都采用51 virtual_router_id 51 # 优先级&#x2F;权重，优先级高的实例先上线 priority 100 # 主备之间同步检查的时间间隔，默认1s advert_int 1 # 认证授权的密码，防止非法节点的进入 authentication &#123; auth_type PASS auth_pass 1111 &#125; # VIP virtual_ipaddress &#123; 192.168.200.16 192.168.200.17 192.168.200.18 &#125;&#125; 最终配置 1234567891011121314151617181920! Configuration File for keepalivedglobal_defs &#123; router_id keep_005&#125;vrrp_instance VI_1 &#123; state MASTER interface enp0s3 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.2 &#125;&#125; 启动keepalived 进入安装目录执行 ./sbin/keepalived 启动前IP地址 启动后IP地址 将keepalived注册为系统服务 cp &lt;keepalived解压文件目录&gt;/keepalived/etc/init.d/keepalived /etc/init.d/ # 拷贝 keepalived到/etc/init.d/ cp &lt;keepalived解压文件目录&gt;/keepalived/etc/sysconfig/keepalived /etc/sysconfig/ # 拷贝keepalived到 /etc/sysconfig/ systemctl daemon-reload # 重新加载系统服务 使用kill -9 PID的方式停止之前启动的keepalived进程，使用systemctl start keepalived启动服务 keepalived实现双机主备高可用123456789101112131415161718192021# 主机配置 192.168.1.100! Configuration File for keepalivedglobal_defs &#123; router_id keep_100&#125;vrrp_instance VI_1 &#123; state MASTER interface enp0s3 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.5 &#125;&#125; 123456789101112131415161718192021# 备机配置 192.168.1.101! Configuration File for keepalivedglobal_defs &#123; router_id keep_101&#125;vrrp_instance VI_1 &#123; state BACKUP interface enp0s3 virtual_router_id 51 priority 80 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.5 &#125;&#125; 通过访问192.168.1.5 可发现调用 192.168.1.100 的nginx；停止100服务器上的keealived，则调用192.168.1.101 的nginx；重新启动100服务器上的keealived，则又重新调用192.168.1.100 的nginx。 keepalived配置nginx自动重启 vim check_nginx_alived.sh # 在/etc/keepalived/下编写脚本文件 123456789101112#! /bin/bashcount_nginxs=`ps -C nginx --no-header | wc -l`# 判断nginx是否宕机，如果宕机则重启if [ $count_nginxs -eq 0 ];then /opt/nginx/nginx/sbin/nginx # 等待3秒，如果没有启动成功，则停止keepalived，使其启动备用机 sleep 3 if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived fifi chmod +x check_nginx_alived.sh # 为脚本文件添加权限 vim keepalived.conf # 编辑 keepalived.conf 添加脚本监听，保存并退出 123456789101112vrrp_script check_nginx_alive &#123; script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_nginx_alived.sh&quot; interval 2 # 每隔两秒运行脚本 weight 10 # 如果脚本运行成功，则权重+10&#125;vrrp_instance VI_1 &#123; # ... track_script &#123; check_nginx_alive # 追踪nginx脚本，这个脚本的定义要在上面 &#125;&#125; systemctl restart keepalived # 重启keepalived keepalived双主热备原理双机主备带来的缺点：由于备用机只有在主节点宕机后才能使用，那么如果主节点极少存在宕机的可能，那么备用机就会造成资源的浪费。 那么就产生另一种双主热备的方式，两台Nginx主机互为主备 ※ 实现双主热备需要DNS服务器开启负载均衡 keepalived双主热备123456789101112131415161718192021222324252627282930313233343536# 主机配置 192.168.1.100! Configuration File for keepalivedglobal_defs &#123; router_id keep_100&#125;vrrp_instance VI_1 &#123; state MASTER interface enp0s3 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.5 &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP interface enp0s3 virtual_router_id 52 priority 80 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.6 &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536# 备机配置 192.168.1.101! Configuration File for keepalivedglobal_defs &#123; router_id keep_101&#125;vrrp_instance VI_1 &#123; state BACKUP interface enp0s3 virtual_router_id 51 priority 80 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.5 &#125;&#125;vrrp_instance VI_2 &#123; state MASTER interface enp0s3 virtual_router_id 52 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.1.6 &#125;&#125;","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解五：缓存","slug":"NGINX详解五：缓存","date":"2020-11-05T21:58:56.000Z","updated":"2021-02-18T14:52:49.806Z","comments":true,"path":"2020/11/06/NGINX详解五：缓存/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E4%BA%94%EF%BC%9A%E7%BC%93%E5%AD%98/","excerpt":"NGINX详解第五章——NGINX中的缓存","text":"Nginx 控制浏览器缓存expires指令过期时间，配置该参数后，浏览器的response headers中会多出cache-control: max-age=10，Date: &lt;当前时间&gt; ，Expires: &lt;当前时间+max-age时间&gt; 12345678910111213141516location &#x2F; &#123; root html; index index.html; expires 10s; # 表明晚上10点进行缓存过期 # expires @22h00m; # 表明过期时间为过去的一小时 # expires -1h; # 表明不使用缓存，即过期时间为0 # expires epoch; # 表明关闭过期机制 # expires off; # 表明永不过期 # expires max;&#125; Nginx的反向代理缓存1234567891011121314# proxy_cache_path 设置缓存保存的目录# keys_zone 共享内存空间# mycache:5m 内存空间名为mycache，大小为5M# max_size 设置缓存大小# inactive 清除缓存时间# use_temp_path 使用临时目录proxy_cache_path &#x2F;data&#x2F;nginx&#x2F;cache&#x2F;upstream_cache keys_zone&#x3D;mycache:5m max_size&#x3D;1g inactive&#x3D;2h use_temp_path&#x3D;off;server &#123; # 开启并使用缓存 proxy_cache mycache; # 针对200和304状态码的缓存设置过期时间 proxy_cache_valid 200 304 8h;&#125;","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解四：负载均衡","slug":"NGINX详解四：负载均衡","date":"2020-11-05T21:56:07.000Z","updated":"2021-02-18T14:52:49.771Z","comments":true,"path":"2020/11/06/NGINX详解四：负载均衡/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E5%9B%9B%EF%BC%9A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"NGINX详解第四章——NGINX的负载均衡","text":"四层负载均衡基于IP+端口的负载均衡，原理是转发请求到后台服务器，它只负责转发并记录当前连接是由哪个服务器处理的，后续的连接请求就会由同一台服务器处理，相当于长连接。基于传输层TCP/UDP F5 基于硬件的硬负载均衡 LVS Linux内核的四层负载均衡 Haproxy 四层负载均衡，同时支持七层负载均衡 Nginx 四层负载均衡，但主要以七层为主 七层负载均衡基于URL或者IP的负载均衡，工作于应用层，针对http的负载均衡 Nginx 七层负载均衡 Haproxy 七层负载均衡 apache 七层负载均衡 DNS地域负载均衡 负载均衡算法轮询加权ip_hash 将请求的IP地址进行hash，采用除模取余法进行决定访问哪台服务器 123456upstream backend &#123; ip_hash; server xxx.example.com; # ...&#125; 源码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123# src/http/modules/ngx_http_upstream_ip_hash_module.c// 在该方法中判断IP地址是IPv4还是IPv6// 如果是IPv4的话，iphp.addrlen = 3// 如果是IPv4的话，iphp.addrlen = 16// 无法判断的情况下默认为3// 同时赋值 iphp.hash初始值为89，iphp.tries为0;static ngx_int_tngx_http_upstream_init_ip_hash_peer(ngx_http_request_t *r, ngx_http_upstream_srv_conf_t *us)&#123; struct sockaddr_in *sin; struct sockaddr_in6 *sin6; ngx_http_upstream_ip_hash_peer_data_t *iphp; // ... switch (r-&gt;connection-&gt;sockaddr-&gt;sa_family) &#123; case AF_INET: sin = (struct sockaddr_in *) r-&gt;connection-&gt;sockaddr; iphp-&gt;addr = (u_char *) &amp;sin-&gt;sin_addr.s_addr; iphp-&gt;addrlen = 3; break; case AF_INET6: sin6 = (struct sockaddr_in6 *) r-&gt;connection-&gt;sockaddr; iphp-&gt;addr = (u_char *) &amp;sin6-&gt;sin6_addr.s6_addr; iphp-&gt;addrlen = 16; break; default: iphp-&gt;addr = ngx_http_upstream_ip_hash_pseudo_addr; iphp-&gt;addrlen = 3; &#125; iphp-&gt;hash = 89; iphp-&gt;tries = 0; iphp-&gt;get_rr_peer = ngx_http_upstream_get_round_robin_peer; return NGX_OK;&#125;// 此方法为hash算法的实现static ngx_int_tngx_http_upstream_get_ip_hash_peer(ngx_peer_connection_t *pc, void *data)&#123; // ... hash = iphp-&gt;hash; for ( ;; ) &#123; // 此处只将IP地址的前三位拿出进行计算 // 例如 192.168.1.2 ，则为 192 168 1 // 所以在同一个网段内的IP，其hash值相同 for (i = 0; i &lt; (ngx_uint_t) iphp-&gt;addrlen; i++) &#123; hash = (hash * 113 + iphp-&gt;addr[i]) % 6271; &#125; w = hash % iphp-&gt;rrp.peers-&gt;total_weight; peer = iphp-&gt;rrp.peers-&gt;peer; p = 0; while (w &gt;= peer-&gt;weight) &#123; w -= peer-&gt;weight; peer = peer-&gt;next; p++; &#125; n = p / (8 * sizeof(uintptr_t)); m = (uintptr_t) 1 &lt;&lt; p % (8 * sizeof(uintptr_t)); if (iphp-&gt;rrp.tried[n] &amp; m) &#123; goto next; &#125; ngx_log_debug2(NGX_LOG_DEBUG_HTTP, pc-&gt;log, 0, &quot;get ip hash peer, hash: %ui %04XL&quot;, p, (uint64_t) m); ngx_http_upstream_rr_peer_lock(iphp-&gt;rrp.peers, peer); if (peer-&gt;down) &#123; ngx_http_upstream_rr_peer_unlock(iphp-&gt;rrp.peers, peer); goto next; &#125; if (peer-&gt;max_fails &amp;&amp; peer-&gt;fails &gt;= peer-&gt;max_fails &amp;&amp; now - peer-&gt;checked &lt;= peer-&gt;fail_timeout) &#123; ngx_http_upstream_rr_peer_unlock(iphp-&gt;rrp.peers, peer); goto next; &#125; if (peer-&gt;max_conns &amp;&amp; peer-&gt;conns &gt;= peer-&gt;max_conns) &#123; ngx_http_upstream_rr_peer_unlock(iphp-&gt;rrp.peers, peer); goto next; &#125; break; next: if (++iphp-&gt;tries &gt; 20) &#123; ngx_http_upstream_rr_peers_unlock(iphp-&gt;rrp.peers); return iphp-&gt;get_rr_peer(pc, &amp;iphp-&gt;rrp); &#125; &#125; iphp-&gt;rrp.current = peer; pc-&gt;sockaddr = peer-&gt;sockaddr; pc-&gt;socklen = peer-&gt;socklen; pc-&gt;name = &amp;peer-&gt;name; peer-&gt;conns++; if (now - peer-&gt;checked &gt; peer-&gt;fail_timeout) &#123; peer-&gt;checked = now; &#125; ngx_http_upstream_rr_peer_unlock(iphp-&gt;rrp.peers, peer); ngx_http_upstream_rr_peers_unlock(iphp-&gt;rrp.peers); iphp-&gt;rrp.tried[n] |= m; iphp-&gt;hash = hash; return NGX_OK;&#125; 缺点 如果其中一台服务器宕机后，其他客户端就会重新进行hash取值，那么原来服务器上的会话都会丢失，相应缓存也会丢失，解决办法为一致性hash 一致性hashhash值为0~2的32次方，假定存在节点1-4，通过hash运算后位于hash环上的对应位置，用户IP通过hash运算后同样位于环上对应位置，那么用户访问的服务器为由顺时针旋转最近的服务器 如果存在一台服务器(节点3)的宕机，那么只有原访问节点三的用户会话丢失，其他用户的会话不会丢失 同样如果添加一台服务器(节点5)，那么只会丢失从逆时针旋转最近的服务器到新节点的会话信息，其他用户不会丢失 url_hash与IP的算法区别就在于，将hash的参数改为了请求的url，通过取模求余法，获取对应的服务器 12345upstream backend &#123; hash $request_uri; server xxx.example.com; # ...&#125; least_conn最小的连接数，根据每台服务器的连接数决定，哪个连接数小，就访问哪个服务器","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解三：NGINX配置","slug":"NGINX详解三：NGINX配置","date":"2020-11-05T21:50:23.000Z","updated":"2021-02-18T14:52:49.737Z","comments":true,"path":"2020/11/06/NGINX详解三：NGINX配置/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E4%B8%89%EF%BC%9ANGINX%E9%85%8D%E7%BD%AE/","excerpt":"NGINX详解第三章——NGINX相关配置介绍","text":"nginx.conf 配置结构 nginx.conf 核心配置文件详解user nobody默认worker工作进程由 nobody 用户执行，表明操作文件权限为 nobody 用户权限 work_processes 1;默认worker工作线程数，推荐为CPU核心数-1 error_log logs/error.log (notice / info); 表明错误日志的目录，默认初始化时配置的错误目录位置，若没有配置则默认 &lt;nginx安装目录&gt;/logs/error.log notice / info 表明日志的打印级别；nginx中的日志级别( debug / info / notice / warn / error / crit ) pid logs/nginx.pid表明nginx进程号文件所在位置，默认初始化时配置的错误目录位置，若没有配置则默认 &lt;nginx安装目录&gt;/logs/nginx.pid eventsuse epoll;linux默认使用epoll操作模式，不同的操作使用的模式也不同 worker_connections 1024;默认工作线程的最大连接数，根据实际情况配置 httpinclude mime.types;导入外部文件，引入外部配置，避免单个配置文件过大 default application/octet-stream;默认的类型 log_format main ‘$remote_addr - $remote-user [$time_local] “$request” ‘ …表明日志记录的格式，main 表示后面格式的名称， access_log logs/access.log main; 表明请求日志的目录，默认初始化时配置的请求目录位置，若没有配置则默认 &lt;nginx安装目录&gt;/logs/error.log main 为定义的格式的名称 sendfile on;启用文件的高效传输，提升传输性能 tcp_nopush on;sendfile 启用后才能启动这个配置，是指当数据量累积到一定大小的时候才发送，提高效率 keepalive_timeout 0;设置客户端和服务端请求的超时时间(单位秒)，保证客户端多次请求的时候不会重复建立新的连接，节约资源损耗 gzip on;开启压缩，例如http、css、js等，节约网络带宽，提高渲染速度，但是会消耗服务器性能 serverlisten 80;表明服务器监听端口 server_name localhost;表明服务器的IP或域名 location /表明路由， / 表示根 root html;表示root所在的目录位置，默认为 &lt;nginx安装目录&gt;/html 目录下 index index.html index.htm;表示网页的首页位置，为root目录下的文件位置 error_page 500 502 503 504 /50x.html;错误页面位置，表示服务器发生 500，502，503，504错误时，页面跳转至 root 下 50x.html 页面 GZIP压缩配置12345678# 开启gzip压缩传输功能gzip on;# 压缩最小字节，如果文件小于1字节，则不压缩gzip_min_length 1;# 压缩比(1-9)，压缩比越大，cpu资源消耗越大gzip_comp_level 3;# 需要压缩的类型gzip_types text&#x2F;plain application&#x2F;javascript application&#x2F;x-javascript text&#x2F;css text&#x2F;xml image&#x2F;png image&#x2F;svg+xml image&#x2F;gif image&#x2F;jpeg application&#x2F;json video&#x2F;mp4 audio&#x2F;mpeg; location 的匹配规格 空格 ：默认匹配，普通匹配 123location &#x2F; &#123; root &#x2F;home;&#125; = ： 精准匹配 123location &#x3D; &#x2F; &#123; root &#x2F;home;&#125; ~* ：匹配正则表达式，不区分大小写 1234# 符合图片后缀的匹配location ~* \\.(GIF|JPG|PNG|JEPG) &#123; root &#x2F;home;&#125; ~ ：匹配正则表达式，区分大小写 1234# 图片后缀小写的才能匹配location ~ \\.(gif|jpg|png|jepg) &#123; root &#x2F;home;&#125; ^~ ： 以某个字段路径开头 1234# 只有&#x2F;static&#x2F;img 路径下的资源才能访问location ^~ &#x2F;static&#x2F;img &#123; root &#x2F;home;&#125; Nginx 解决跨域问题 12345678# 允许跨域请求的域，*代表所有add_header &#39;Access-Control-Allow-Origin&#39; *; # 允许带上cookie请求add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;; # 允许请求的方法，比如GET&#x2F;POST&#x2F;PUT&#x2F;DELETEadd_header &#39;Access-Control-Allow-Methods&#39; *; # 允许请求的headeradd_header &#39;Access-Control-Allow-Headers&#39; *; Nginx 配置静态资源防盗链123456# 对源站点验证valid_referers *.&lt;域名&gt;;# 非法引入会进入下方判断if ($invalid_referer) &#123; return 404;&#125; upstream 指令参数 参考链接：https://nginx.org/en/docs/http/ngx_http_upstream_module.html max_conns限制服务器最大连接数，默认值为0（没有限制） slow_start慢启动，使服务器缓慢加入集群，让用户流量缓慢流入服务器，即weight慢慢升到10。默认值为0（没有开启） 该参数不能使用在hash和random load balancing中； 如果在upstream中只有一台server，则该参数无效。 down配置该参数的服务器无法访问 backup配置该参数的服务器表明为备用机，暂时无法被访问，只有其他服务器宕机后，备用机才会被访问到 max_fails最大失败次数，如果到达最大失败次数，则认为该服务器宕机，默认值为1 fail_timeout在达到max_fails后，在fail_timeout后重新恢复服务，默认值为10秒 keepalive保持一定数量的连接为长连接 使用nginx配置https域名证书安装ssl模块 nginx -V # 获取安装时的参数 进入到nginx解压后的文件夹中 重新执行configure，拷贝安装时的参数，添加–with-http-ssl-module 1234567891011121314.&#x2F;configure \\--prefix&#x3D;&#x2F;opt&#x2F;nginx&#x2F;nginx \\--conf-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;nginx&#x2F;conf&#x2F;nginx.conf \\--pid-path&#x3D;&#x2F;tmp&#x2F;nginx.pid \\--lock-path&#x3D;&#x2F;tmp&#x2F;nginx.lock \\--error-log-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;logs&#x2F;error.log \\--http-log-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;logs&#x2F;access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;client \\--http-proxy-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;proxy \\--http-fastcgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;fastcgi \\--http-uwsgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;uwsgi \\--http-scgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;scgi \\--with-http_ssl_module make # 编译 make install # 安装 配置ssl1234567891011121314151617#以下属性中以ssl开头的属性代表与证书配置有关，其他属性请根据自己的需要进行配置。server &#123; listen 443; #配置HTTPS的默认访问端口号为443。此处如果未配置HTTPS的默认访问端口，可能会造成Nginx无法启动。Nginx 1.15.0以上版本请使用listen 443 ssl代替listen 443和ssl on。 server_name www.certificatestests.com; #将www.certificatestests.com修改为您证书绑定的域名，例如：www.example.com。如果您购买的是通配符域名证书，要修改为通配符域名，例如：*.aliyun.com。 ssl_certificate cert&#x2F;domain name.pem; #将domain name.pem替换成您证书的文件名称。 ssl_certificate_key cert&#x2F;domain name.key; #将domain name.key替换成您证书的密钥文件名称。 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #使用此加密套件。 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #使用该协议进行配置。 ssl_prefer_server_ciphers on; location &#x2F; &#123; root html; #站点目录。 index index.html index.htm; &#125;&#125;","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解二：NGINX基本资料","slug":"NGINX详解二：NGINX基本资料","date":"2020-11-05T21:45:18.000Z","updated":"2021-02-18T14:52:49.445Z","comments":true,"path":"2020/11/06/NGINX详解二：NGINX基本资料/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E4%BA%8C%EF%BC%9ANGINX%E5%9F%BA%E6%9C%AC%E8%B5%84%E6%96%99/","excerpt":"NGINX详解第二章——NGINX的基本资料：进程模型、worker抢占机制、事件机制","text":"nginx进程模型 master：主进程 管理worker进程，接受外界信号（例如停止nginx、退出、重新加载），传递给worker 监控worker，如果worker出现异常退出，会重新起一个新进程 worker：工作进程，为master服务 修改工作线程数 修改 conf/nginx.conf 文件夹中的 work_processes ，修改完保存后重新加载nginx worker抢占机制由master进程fork出多个worker进程，客户端发起建立连接，多个worker进程争抢accept_mutex锁，抢到锁的worker进行建立连接、处理请求并返回。 nginx事件机制传统服务器事件机制模型由master进程fork出一个worker进程，当多个客户端访问worker进程时，如果第一个客户端连接上worker1进入了阻塞状态，那么master进程就会fork出一个woker2进程进行处理第二个客户端。由此类推，传统服务器事件机制模型属于一个同步阻塞模型，效率低，当并发达到几十万，那么会开很多的worker进程，资源开销十分大 nginx服务器事件机制模型由master进程fork出多个worker进程，当多个客户端访问worker进程时，如果第一个客户端连接上worker1进入了阻塞状态，worker1进程可以继续处理第二个客户端的请求。是一个异步非阻塞模型，linux上使用epoll模型，一个worker进程大概可以处理6-8w个请求 修改事件模型和工作进程连接数 修改 conf/nginx.conf文件夹，events下添加 use epoll; ，修改 worker_connections 10240;","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"NGINX详解一：NGINX的安装","slug":"NGINX详解一：NGINX的安装","date":"2020-11-05T21:40:11.000Z","updated":"2021-02-18T14:52:49.851Z","comments":true,"path":"2020/11/06/NGINX详解一：NGINX的安装/","link":"","permalink":"https://rabbit-mar.github.io/2020/11/06/NGINX%E8%AF%A6%E8%A7%A3%E4%B8%80%EF%BC%9ANGINX%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"NGINX详解的第一章——安装NGINX","text":"压缩包安装 下载对应版本的压缩包 移动到 /opt/nginx/ 目录下 yum install gcc-c++ # 安装gcc环境 yum install -y core pcre-devel # 安装PCRE库，用于解析正则表达式 yum install -y zlib zlib-devel # 安装zlib压缩和解压缩依赖 yum install -y openssl openssl-devel # 安装SSL安全的加密套接字协议层，也就是https mkdir /data/nginx/temp/ # 创建nginx临时文件 mkdir /data/nginx/logs/ # 创建nginx日志文件 在nginx目录下，输入如下命令，目的是创建makefile文件 12345678910111213.&#x2F;configure \\--prefix&#x3D;&#x2F;opt&#x2F;nginx&#x2F;nginx \\--conf-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;nginx&#x2F;conf&#x2F;nginx.conf \\--pid-path&#x3D;&#x2F;tmp&#x2F;nginx.pid \\--lock-path&#x3D;&#x2F;tmp&#x2F;nginx.lock \\--error-log-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;logs&#x2F;error.log \\--http-log-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;logs&#x2F;access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;client \\--http-proxy-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;proxy \\--http-fastcgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;fastcgi \\--http-uwsgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;uwsgi \\--http-scgi-temp-path&#x3D;&#x2F;data&#x2F;nginx&#x2F;temp&#x2F;scgi make # 编译 make instal # 安装 ./sbin/nginx # 进入安装目录启动nginx ./nginx -s stop # 停止 ./nginx -s reload # 重新加载","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"}]},{"title":"四种限流算法的基本实现","slug":"四种限流算法的基本实现","date":"2020-10-14T22:56:59.000Z","updated":"2021-02-18T14:47:14.767Z","comments":true,"path":"2020/10/15/四种限流算法的基本实现/","link":"","permalink":"https://rabbit-mar.github.io/2020/10/15/%E5%9B%9B%E7%A7%8D%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0/","excerpt":"此处使用四种限流方式进行基本的限流算法实现：计数器限流、滑动窗口限流、漏桶限流、令牌桶限流","text":"四种限流算法的基本实现此处使用四种限流方式进行基本的限流算法实现：计数器限流、滑动窗口限流、漏桶限流、令牌桶限流 每个方法中都使用了Timer计时器，来实现时间间隔，可通过 ScheduledThreadPoolExecutor 进行改进。 初始环境环境模拟 Filter 的方式进行限流 123456789# Filter.javapublic interface Filter &#123; // 初始化方法 default public void init()&#123;&#125; // 执行过滤方法 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain); // 销毁过滤器方法 default public void destroy()&#123;&#125;&#125; 1234# FilterChain.javapublic interface FilterChain &#123; void doFilter(ServletRequest request, ServletResponse response);&#125; 12345678910111213# ServletRequest.javapublic class ServletRequest &#123; private String msg; public ServletRequest(String msg) &#123; this.msg = msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; @Override public String toString() &#123; return &quot;ServletRequest&#123; msg=&#x27;&quot; + msg + &quot;&#125;&quot;; &#125;&#125; 12# ServletResponse.javapublic class ServletResponse &#123;&#125; 12345678910# AbstractLimiter.javapublic abstract class AbstractLimiter &#123; protected final int MAX_FLOW; public AbstractLimiter(int MAX_FLOW) &#123; this.MAX_FLOW = MAX_FLOW; &#125; public abstract void limit(ServletRequest request, ServletResponse response, FilterChain chain);&#125; 测试类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# Demo.javapublic class Demo &#123; public void test() &#123; // 过滤器 Filter filter = new Filter() &#123; AbstractLimiter limiter; @Override public void init() &#123; limiter = new CounterLimiter(100); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) &#123; limiter.limit(request, response, chain); &#125; &#125;; // 初始化过滤器 filter.init(); // 开始计时 long start = System.currentTimeMillis(); // 计数器 用来记录 执行了多少个请求 AtomicInteger counter = new AtomicInteger(0); // 定义线程池 ExecutorService pool = Executors.newFixedThreadPool(10); // 执行4000个请求 IntStream.range(0, 4000).forEach(i -&gt; &#123; try &#123; TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException ignored) &#123;&#125; pool.execute(() -&gt; &#123; filter.doFilter(new ServletRequest(i + &quot;&quot;), new ServletResponse(), new FilterChain() &#123; @Override public void doFilter(ServletRequest request, ServletResponse response) &#123; counter.incrementAndGet(); System.out.println(&quot;线程 &gt;&gt; &quot; + Thread.currentThread().getName() + &quot;执行第 &quot; + i + &quot;个请求&quot;); &#125; &#125;); &#125;); &#125;); // 输出结果 System.out.println(&quot;总耗时： &quot; + (System.currentTimeMillis() - start)); System.out.println(&quot;执行成功 &quot; + counter + &quot; 个请求&quot;); &#125; public static void main(String[] args) &#123; new Demo().test(); &#125;&#125; 计数器限流计数器算法，本质就是一个计数器。每通过一次请求计数器加1，当计数器大于最大限制(例如100)时，则不处理此次请求。 问题：如果在0.99秒时收到100个请求，在1.00秒时又发送100个请求，那么在单位时间内处理了200个请求，对于服务器来说为两倍压力，可能会瞬间压垮服务器。 12345678910111213141516171819202122232425262728293031323334# CounterLimiter.javapublic class CounterLimiter extends AbstractLimiter &#123; private static final int initFlow = 0; private final AtomicInteger flow; public CounterLimiter(int MAX_FLOW) &#123; super(MAX_FLOW); // 初始化流量 flow = new AtomicInteger(initFlow); new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; // 每秒重置流量 flow.set(initFlow); &#125; &#125;, 0, 1000); &#125; @Override public void limit(ServletRequest request, ServletResponse response, FilterChain chain) &#123; // 如果流量没到达最大流量 if (flow.get() &lt; MAX_FLOW) &#123; flow.incrementAndGet(); // flow增加 chain.doFilter(request, response); // 放行 &#125; else &#123; // 请求的其他操作.... System.out.println(&quot;请求 &gt;&gt;&gt; &quot; + Thread.currentThread().getName() + &quot; 被丢弃&quot;); &#125; &#125;&#125; 滑动窗口限流滑动窗口限流即初始一个滑动窗口(Slider)，每个窗口中假定有20个槽位，那么每50ms刷新窗口，将首个槽位弹出，压入新槽位。工作线程只需要判断滑动窗口内是否大于最大限流即可。 问题：同计数器限流类似，存在着突刺问题，例如在1秒内的前50ms就已经打满最大流量请求，那么剩下的0.95秒都得拒绝连接，形成突刺。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# RollingWindowLimiter.javapublic class RollingWindowLimiter extends AbstractLimiter &#123; // 滑块 private static Slider slider; // 初始量 private static final int initFlow = 0; // 当前槽位之前的槽位总和 private final AtomicInteger preCount; // 当前槽位 private AtomicInteger currCount; // 使定时器线程和工作线程相互独立，不然会出现多线程问题 private final AtomicBoolean flag = new AtomicBoolean(false); public RollingWindowLimiter(int MAX_FLOW) &#123; super(MAX_FLOW); // 初始化一个容量为20的滑块 slider = new Slider(20); // 初始化计数器 preCount = new AtomicInteger(initFlow); new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; flag.set(false); ArrayBlockingQueue&lt;AtomicInteger&gt; blocks = slider.blocks; try &#123; int size = blocks.size(); // 计算当前槽位之前的槽位大小 if (size &gt; 0)&#123; preCount.set(initFlow); blocks.forEach(num -&gt; preCount.addAndGet(num.get())); &#125; // 如果滑块容量已满 将第一个槽位弹出 if (size == slider.capacity) &#123; blocks.take(); &#125; // 初始一个槽位放入队列中 currCount = new AtomicInteger(initFlow); blocks.put(currCount); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; flag.set(true); &#125; &#125; &#125;, 0, 1000 / slider.capacity); &#125; @Override public void limit(ServletRequest request, ServletResponse response, FilterChain chain) &#123; // 如果容量没有达到最大容量 if (flag.get() &amp;&amp; preCount.get() + currCount.get() &lt; MAX_FLOW) &#123; currCount.incrementAndGet(); chain.doFilter(request, response); &#125; else &#123; // 请求的其他操作 System.out.println(System.currentTimeMillis() + &quot; 请求 &gt;&gt;&gt; &quot; + Thread.currentThread().getName() + &quot; 被丢弃 &gt;&gt; 容量 &quot; + (preCount.get() + currCount.get())); &#125; &#125; private static class Slider &#123; // 滑块容量 private final int capacity; // 滑块 private final ArrayBlockingQueue&lt;AtomicInteger&gt; blocks; public Slider(int capacity) &#123; this.capacity = capacity; this.blocks = new ArrayBlockingQueue&lt;&gt;(capacity); &#125; &#125;&#125; 漏桶限流漏桶算法概念如下： 将每个请求视作”水滴”放入”漏桶”进行存储； “漏桶”以固定速率向外”漏”出请求来执行如果”漏桶”空了则停止”漏水”； 如果”漏桶”满了则多余的”水滴”会被直接丢弃。 问题： 当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# LeakyBucketLimiter.javapublic class LeakyBucketLimiter extends AbstractLimiter &#123; // 漏桶 private final LeakyBucket leakyBucket; public LeakyBucketLimiter(int MAX_FLOW) &#123; super(MAX_FLOW); this.leakyBucket = new LeakyBucket(MAX_FLOW); &#125; @Override public void limit(ServletRequest request, ServletResponse response, FilterChain chain) &#123; int size = leakyBucket.bucket.size(); try &#123; // 如果水没满就继续加 if (size &lt; leakyBucket.capacity) &#123; leakyBucket.bucket.put(new Water(request, response, chain)); &#125; else &#123; // 请求的其他处理... System.out.println(System.currentTimeMillis() + &quot; 请求 &gt;&gt;&gt; &quot; + Thread.currentThread().getName() + &quot; 被丢弃 &gt;&gt; 容量 &quot; + size); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; private static class LeakyBucket &#123; // 桶容量 private final int capacity; // 速率 private static final int RATE = 10; // 真正的漏桶 private final ArrayBlockingQueue&lt;Water&gt; bucket; public LeakyBucket(int capacity) &#123; this.capacity = capacity; this.bucket = new ArrayBlockingQueue&lt;&gt;(capacity); new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; capacity / RATE; i++) &#123; Water water = bucket.take(); water.chain.doFilter(water.request, water.response); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125;, 0, 1000 * RATE / capacity); &#125; &#125; private static class Water &#123; private final ServletRequest request; private final ServletResponse response; private final FilterChain chain; public Water(ServletRequest request, ServletResponse response, FilterChain chain) &#123; this.request = request; this.response = response; this.chain = chain; &#125; &#125;&#125; 令牌桶限流令牌桶算法概念如下： 令牌以固定速率生成； 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行； 如果桶空了，那么尝试取令牌的请求会被直接丢弃。 ​ 令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# TokenBucketLimiter.javapublic class TokenBucketLimiter extends AbstractLimiter &#123; private final TokenBucket tokenBucket; public TokenBucketLimiter(int MAX_FLOW) &#123; super(MAX_FLOW); tokenBucket = new TokenBucket(MAX_FLOW); &#125; @Override public void limit(ServletRequest request, ServletResponse response, FilterChain chain) &#123; try &#123; Token token = tokenBucket.bucket.poll(3, TimeUnit.MILLISECONDS); if (token != null) &#123; chain.doFilter(request, response); &#125; else &#123; // 请求的其他操作... System.out.println(System.currentTimeMillis() + &quot; 请求 &gt;&gt;&gt; &quot; + Thread.currentThread().getName() + &quot; 被丢弃&quot;); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; private static class TokenBucket &#123; private final int capacity; private static final int RATE = 10; private final ArrayBlockingQueue&lt;Token&gt; bucket; public TokenBucket(int capacity) &#123; this.capacity = capacity; bucket = new ArrayBlockingQueue&lt;&gt;(capacity); new Timer().schedule(new TimerTask() &#123; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; capacity / RATE; i++) &#123; if (bucket.size() &lt; capacity) bucket.put(new Token()); else break; &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125;, 0, 1000 * RATE / capacity); &#125; &#125; private static class Token &#123; &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"编写自定义springboot starter","slug":"编写自定义springboot-starter","date":"2020-09-26T00:37:27.000Z","updated":"2021-02-18T14:46:15.467Z","comments":true,"path":"2020/09/26/编写自定义springboot-starter/","link":"","permalink":"https://rabbit-mar.github.io/2020/09/26/%E7%BC%96%E5%86%99%E8%87%AA%E5%AE%9A%E4%B9%89springboot-starter/","excerpt":"面试中遇到的一个题目，当时没答上，现在完成一个简单的自定义starter","text":"编写自定义springboot starter创建一个空项目模块 在空项目中创建两个模块my-spring-boot-starter-configurer此模块为自动配置模块，使用 spring initializer 构建 以下为pom.xml文件，引入 spring-boot-starter 和 spring-boot-autoconfigure-processor 依赖 1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.marveal.starter&lt;/groupId&gt; &lt;artifactId&gt;my-spring-boot-starter-configurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;my-spring-boot-starter-configurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure-processor&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写MyProperties.java文件该类的元素通过引入starter的application.properties文件来配置，默认为 marveal.my 开头 123456789101112131415161718192021222324252627package com.marveal.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = &quot;marveal.my&quot;)public class MyProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 编写MyService.java文件主要是对匹配的使用 12345678910111213141516171819package com.marveal.starter;public class MyService &#123; private MyProperties myProperties; public MyProperties getMyProperties() &#123; return myProperties; &#125; public void setMyProperties(MyProperties myProperties) &#123; this.myProperties = myProperties; &#125; public String hello()&#123; return myProperties.getPrefix() + &quot;hello world&quot; + myProperties.getSuffix(); &#125;&#125; 编写MyAutoConfiguration.java文件1234567891011121314151617181920212223package com.marveal.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration // 标注为配置类@ConditionalOnWebApplication // 配置为web项目生效@EnableConfigurationProperties(MyProperties.class) // 引入properties文件public class MyAutoConfiguration &#123; @Autowired private MyProperties myProperties; @Bean public MyService myService() &#123; MyService myService = new MyService(); myService.setMyProperties(myProperties); return myService; &#125;&#125; 编写spring.factories文件表明自动配置类的位置 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.marveal.starter.MyAutoConfiguration 目录结构 my-spring-boot-starter此模块为启动器模块，以后引入模块统统引入starter模块，用maven构建 以下为pom.xml文件 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.marveal.starter&lt;/groupId&gt; &lt;artifactId&gt;my-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.marveal.starter&lt;/groupId&gt; &lt;artifactId&gt;my-spring-boot-starter-configurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 目录结构 测试自定义starter创建一个springboot模块，笔者为my-starter-test 以下为pom.xml文件 123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.marveal.test&lt;/groupId&gt; &lt;artifactId&gt;my-starter-test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.3.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.marveal.starter&lt;/groupId&gt; &lt;artifactId&gt;my-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写controller文件123456789101112131415161718package com.marveal.test.controller;import com.marveal.starter.MyService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController &#123; @Autowired MyService myService; @RequestMapping(&quot;/hello&quot;) public String hello()&#123; return myService.hello(); &#125;&#125; 编写application.properties文件123marveal.my.prefix=**marveal.my.suffix=@@ 启动项目调用 localhost:8080/hello 接口 目录结构 参考资料bilibili视频：https://www.bilibili.com/video/BV1gW411W76m?p=71 springboot官网：https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-developing-auto-configuration github官方示例： https://github.com/snicoll/spring-boot-master-auto-configuration 源代码https://gitee.com/marveal_admin/custom-springboot-starter.git","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"},{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第113题: 路径总和 II","slug":"LeetCode-第113题-路径总和-II","date":"2020-09-25T22:10:12.000Z","updated":"2021-02-18T14:46:15.629Z","comments":true,"path":"2020/09/26/LeetCode-第113题-路径总和-II/","link":"","permalink":"https://rabbit-mar.github.io/2020/09/26/LeetCode-%E7%AC%AC113%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C-II/","excerpt":"给定一个二叉树和一个目标和，找到所有从根节点到叶子节点路径总和等于给定目标和的路径。","text":"路径总和 II给定一个二叉树和一个目标和，找到所有从根节点到叶子节点路径总和等于给定目标和的路径。 说明: 叶子节点是指没有子节点的节点。 示例:给定如下二叉树，以及目标和 sum = 22， 1234567 5 / \\ 4 8 / / \\ 11 13 4 / \\ / \\7 2 5 1 返回: 1234[ [5,4,11,2], [5,8,4,5]] 题目分析根据二叉树的遍历进行变换，在遍历过程中进行数值计算及存储 代码实现12345678910111213141516171819202122232425class Solution &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; solve(root, sum, new LinkedList&lt;&gt;()); return result; &#125; public void solve(TreeNode root, int sum, Deque&lt;Integer&gt; unit) &#123; if (root == null) &#123; return; &#125; sum -= root.val; unit.offerLast(root.val); if (root.left == null &amp;&amp; root.right == null &amp;&amp; sum == 0) &#123; result.add(new ArrayList&lt;&gt;(unit)); &#125; solve(root.left, sum, unit); solve(root.right, sum, unit); unit.pollLast(); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第106题: 从中序与后序遍历序列构造二叉树","slug":"LeetCode-第106题-从中序与后序遍历序列构造二叉树","date":"2020-09-25T19:22:01.000Z","updated":"2021-02-18T14:46:15.521Z","comments":true,"path":"2020/09/26/LeetCode-第106题-从中序与后序遍历序列构造二叉树/","link":"","permalink":"https://rabbit-mar.github.io/2020/09/26/LeetCode-%E7%AC%AC106%E9%A2%98-%E4%BB%8E%E4%B8%AD%E5%BA%8F%E4%B8%8E%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"根据一棵树的中序遍历与后序遍历构造二叉树。","text":"从中序与后序遍历序列构造二叉树根据一棵树的中序遍历与后序遍历构造二叉树。 ※ 注意: 你可以假设树中没有重复的元素。 例如，给出 中序遍历 inorder = [9,3,15,20,7] 后序遍历 postorder = [9,15,7,20,3] 返回如下的二叉树： 12345 3 / \\9 20 / \\ 15 7 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析已知到 中序遍历的序列为： 左节点 -&gt; 根节点 -&gt; 右节点 后序遍历的序列为： 左节点 -&gt; 右节点 -&gt; 根节点 由此可以推出后序遍历的最后一个节点必定为根节点，那么在中序遍历的序列中，可以将序列拆分为左右子树，例如： 12345postorder = [9,15,7,20,3], inorder = [9,3,15,20,7]root = 3leftTree = [9], rightTree = [15, 20, 7]root = 20针对右子数有 leftTree = [15], rightTree = [7] 代码实现123456789101112131415161718192021222324252627282930313233343536class Solution &#123; int post_idx; int[] inorder, postorder; HashMap&lt;Integer, Integer&gt; inorder_map = new HashMap&lt;&gt;(); public TreeNode buildTree(int[] inorder, int[] postorder) &#123; this.inorder = inorder; this.postorder = postorder; this.post_idx = postorder.length - 1; // 将中序序列存入到hashmap中加快查找效率 int idx = 0; for (int val : inorder) &#123; inorder_map.put(val , idx++); &#125; return buildTree(0, inorder.length - 1); &#125; private TreeNode buildTree(int in_start, int in_end) &#123; if (in_start &gt; in_end) &#123; return null; &#125; // 找到节点 TreeNode node = new TreeNode(postorder[post_idx]); int in_idx = inorder_map.get(postorder[post_idx]); post_idx--; // 找到右子数 node.right = buildTree(in_idx + 1, in_end); // 找到左子树 node.left = buildTree(in_start, in_idx - 1); return node; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第167题：两数之和 II - 输入有序数组","slug":"LeetCode第167题：两数之和-II-输入有序数组","date":"2020-07-19T19:49:15.000Z","updated":"2021-02-18T14:43:24.349Z","comments":true,"path":"2020/07/20/LeetCode第167题：两数之和-II-输入有序数组/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/20/LeetCode%E7%AC%AC167%E9%A2%98%EF%BC%9A%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C-II-%E8%BE%93%E5%85%A5%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84/","excerpt":"给定一个已按照升序排列 的有序数组，找到两个数使得它们相加之和等于目标数。","text":"167. 两数之和 II - 输入有序数组给定一个已按照升序排列 的有序数组，找到两个数使得它们相加之和等于目标数。 函数应该返回这两个下标值 index1 和 index2，其中 index1 必须小于 index2。 说明: 返回的下标值（index1 和 index2）不是从零开始的。 你可以假设每个输入只对应唯一的答案，而且你不可以重复使用相同的元素。 示例: 123输入: numbers = [2, 7, 11, 15], target = 9输出: [1,2]解释: 2 与 7 之和等于目标数 9 。因此 index1 = 1, index2 = 2 。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析双指针方式进行处理；L指针在首，R指针在尾；如果numbers[L] + numbers[R] &lt; target ；L指针右移；如果numbers[L] + numbers[R] &gt; target ；R指针左移； 代码实现1234567891011121314151617public int[] twoSum(int[] numbers, int target) &#123; int len = numbers.length; if (len == 2) return new int[]&#123;1,2&#125;; int L = 0, R = len - 1; while (L &lt; R) &#123; if (numbers[L] + numbers[R] == target) &#123; return new int[]&#123;L+1, R+1&#125;; &#125; else if (numbers[L] + numbers[R] &lt; target) &#123; L++; &#125; else &#123; R--; &#125; &#125; return null;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第312题：戳气球","slug":"LeetCode第312题：戳气球","date":"2020-07-18T18:59:57.000Z","updated":"2021-02-18T14:42:45.970Z","comments":true,"path":"2020/07/19/LeetCode第312题：戳气球/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/19/LeetCode%E7%AC%AC312%E9%A2%98%EF%BC%9A%E6%88%B3%E6%B0%94%E7%90%83/","excerpt":"有 n 个气球，编号为0 到 n-1，每个气球上都标有一个数字，这些数字存在数组 nums 中。","text":"312.戳气球有 n 个气球，编号为0 到 n-1，每个气球上都标有一个数字，这些数字存在数组 nums 中。 现在要求你戳破所有的气球。如果你戳破气球 i ，就可以获得 nums[left] * nums[i] * nums[right] 个硬币。 这里的 left 和 right 代表和 i 相邻的两个气球的序号。注意当你戳破了气球 i 后，气球 left 和气球 right 就变成了相邻的气球。 求所能获得硬币的最大数量。 说明: 你可以假设 nums[-1] = nums[n] = 1，但注意它们不是真实存在的所以并不能被戳破。 0 ≤ n ≤ 500, 0 ≤ nums[i] ≤ 100 示例: 1234输入: [3,1,5,8]输出: 167 解释: nums = [3,1,5,8] --&gt; [3,5,8] --&gt; [3,8] --&gt; [8] --&gt; [] coins = 3*1*5 + 3*5*8 + 1*3*8 + 1*8*1 = 167 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/burst-balloons著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析我们可以通过变换计算顺序，从「自顶向下」的记忆化搜索变为「自底向上」的动态规划。 令 dp[i] [j] 表示填满开区间 (i,j) 能得到的最多硬币数，那么边界条件是 i ≥ j−1，此时有 dp[i] [j]=0。 可以写出状态转移方程： 最终答案即为 dp[0] [n+1]。实现时要注意到动态规划的次序。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/burst-balloons/solution/chuo-qi-qiu-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现12345678910111213141516171819public int maxCoins(int[] nums) &#123; int len = nums.length; int[][] dp = new int[len + 2][len + 2]; int[] val = new int[len + 2]; System.arraycopy(nums, 0, val, 1, len); val[0] = val[len+1] = 1; for (int i = len-1; i &gt;= 0; i--) &#123; for (int j = i+2; j &lt;= len+1; j++) &#123; for (int k = i+1; k &lt; j; k++) &#123; int sum = val[i] * val[k] * val[j]; sum += dp[i][k] + dp[k][j]; dp[i][j] = Math.max(dp[i][j], sum); &#125; &#125; &#125; return dp[0][len+1];&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第97题：交错字符串","slug":"LeetCode第97题：交错字符串","date":"2020-07-18T00:09:02.000Z","updated":"2021-02-18T14:42:11.802Z","comments":true,"path":"2020/07/18/LeetCode第97题：交错字符串/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/18/LeetCode%E7%AC%AC97%E9%A2%98%EF%BC%9A%E4%BA%A4%E9%94%99%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"给定三个字符串 s1, s2, s3, 验证 s3 是否是由 s1 和 s2 交错组成的。","text":"97. 交错字符串给定三个字符串 s1, s2, s3, 验证 s3 是否是由 s1 和 s2 交错组成的。 示例 1: 输入: s1 = “aabcc”, s2 = “dbbca”, s3 = “aadbbcbcac”输出: true 示例 2: 输入: s1 = “aabcc”, s2 = “dbbca”, s3 = “aadbbbaccc”输出: false 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/interleaving-string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析动态规划 作者：gousiqi链接：https://leetcode-cn.com/problems/interleaving-string/solution/lei-si-lu-jing-wen-ti-zhao-zhun-zhuang-tai-fang-ch/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现123456789101112131415161718192021222324252627282930313233public boolean isInterleave(String s1, String s2, String s3) &#123; // 0 d b b c a &lt;-- s2 // 0 T F F F F F // a T F F F F F // a T T T T T F // b F T T F T F // c F F T T T T // c F T T T F T // // ^ // | // s1 int m = s1.length(), n = s2.length(), t = s3.length(); if (m + n != t) return false; boolean[][] dp = new boolean[m+1][n+1]; dp[0][0] = true; for (int i = 1; i &lt;= m &amp;&amp; s1.charAt(i-1) == s3.charAt(i-1); i++) &#123; dp[i][0] = true; &#125; for (int j = 1; j &lt;= n &amp;&amp; s2.charAt(j-1) == s3.charAt(j-1); j++) &#123; dp[0][j] = true; &#125; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; dp[i][j] = (dp[i-1][j] &amp;&amp; s1.charAt(i-1) == s3.charAt(i+j-1)) || (dp[i][j-1] &amp;&amp; s2.charAt(j-1) == s3.charAt(i+j-1)); &#125; &#125; return dp[m][n];&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第35题：搜索插入位置","slug":"LeetCode第35题：搜索插入位置","date":"2020-07-16T21:01:18.000Z","updated":"2021-02-18T14:41:37.605Z","comments":true,"path":"2020/07/17/LeetCode第35题：搜索插入位置/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/17/LeetCode%E7%AC%AC35%E9%A2%98%EF%BC%9A%E6%90%9C%E7%B4%A2%E6%8F%92%E5%85%A5%E4%BD%8D%E7%BD%AE/","excerpt":"给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。","text":"35. 搜索插入位置给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 你可以假设数组中无重复元素。 123456789101112131415示例 1:输入: [1,3,5,6], 5输出: 2 示例 2:输入: [1,3,5,6], 2输出: 1示例 3:输入: [1,3,5,6], 7输出: 4 示例 4:输入: [1,3,5,6], 0输出: 0 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/search-insert-position著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析典型的二分查找法，需要处理的是未存在位置的返回，可以先将插入位置设置为末尾，这样就不需要处理插入值在末尾的情况。 代码实现1234567891011121314151617public int searchInsert(int[] nums, int target) &#123; int len = nums.length; int L = 0, R = len - 1; int ans = len; while (L &lt;= R) &#123; int mid = L + ((R - L) &gt;&gt; 1); if (nums[mid] &lt; target) &#123; L = mid + 1; &#125; else if (nums[mid] &gt;= target) &#123; R = mid - 1; ans = mid; &#125; &#125; return ans;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第96题：不同的二叉搜索树","slug":"LeetCode第96题：不同的二叉搜索树","date":"2020-07-15T00:13:49.000Z","updated":"2021-02-18T14:40:56.984Z","comments":true,"path":"2020/07/15/LeetCode第96题：不同的二叉搜索树/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/15/LeetCode%E7%AC%AC96%E9%A2%98%EF%BC%9A%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/","excerpt":"给定一个整数 n，求以 1 ... n 为节点组成的二叉搜索树有多少种？","text":"96. 不同的二叉搜索树给定一个整数 n，求以 1 … n 为节点组成的二叉搜索树有多少种？ 示例: 输入: 3输出: 5解释: 给定 n = 3, 一共有 5 种不同结构的二叉搜索树: 123451 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\2 1 2 3 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/unique-binary-search-trees著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析 给定一个有序序列 1⋯n，为了构建出一棵二叉搜索树，我们可以遍历每个数字 i，将该数字作为树根，将 1⋯(i−1) 序列作为左子树，将 (i+1)⋯n 序列作为右子树。接着我们可以按照同样的方式递归构建左子树和右子树。 推导出的 G(n)G(n)函数的值在数学上被称为卡塔兰数 Cn。卡塔兰数更便于计算的定义如下: 结果表 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/unique-binary-search-trees/solution/bu-tong-de-er-cha-sou-suo-shu-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现动态规划123456789101112public int numTrees(int n) &#123; int[] G = new int[n + 1]; G[0] = 1; G[1] = 1; for (int i = 2; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= i; j++) &#123; G[i] += G[j - 1] * G[i - j]; &#125; &#125; return G[n];&#125; 数学1234567public int numTrees(int n) &#123; long C = 1; for (int i = 0; i &lt; n; i++) &#123; C = C * 2 * (2 * i + 1) / (i + 2); &#125; return (int) C;&#125; 结果表123456789101112131415161718192021222324public int numTrees(int n) &#123; switch(n)&#123; case 1: return 1; case 2: return 2; case 3: return 5; case 4: return 14; case 5: return 42; case 6: return 132; case 7: return 429; case 8: return 1430; case 9: return 4862; case 10: return 16796; case 11: return 58786; case 12: return 208012; case 13: return 742900; case 14: return 2674440; case 15: return 9694845; case 16: return 35357670; case 17: return 129644790; case 18: return 477638700; case 19: return 1767263190; default: return 0; &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第120题：三角形最小路径和","slug":"LeetCode第120题：三角形最小路径和","date":"2020-07-13T23:26:52.000Z","updated":"2021-02-18T14:40:18.239Z","comments":true,"path":"2020/07/14/LeetCode第120题：三角形最小路径和/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/14/LeetCode%E7%AC%AC120%E9%A2%98%EF%BC%9A%E4%B8%89%E8%A7%92%E5%BD%A2%E6%9C%80%E5%B0%8F%E8%B7%AF%E5%BE%84%E5%92%8C/","excerpt":"给定一个三角形，找出自顶向下的最小路径和。每一步只能移动到下一行中相邻的结点上。 相邻的结点 在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。","text":"120. 三角形最小路径和给定一个三角形，找出自顶向下的最小路径和。每一步只能移动到下一行中相邻的结点上。 相邻的结点 在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。 例如，给定三角形： [ [2], [3,4], [6,5,7], [4,1,8,3]]自顶向下的最小路径和为 11（即，2 + 3 + 5 + 1 = 11）。 说明： 如果你可以只使用 O(n) 的额外空间（n 为三角形的总行数）来解决这个问题，那么你的算法会很加分。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/triangle著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析采用动态规划法，根据上一层的所有路径和计算出当前层的路径和 复杂度分析 时间复杂度：O(n^2) ，其中 n 是三角形的行数。 空间复杂度：O(n^2) 。我们需要一个 n∗n 的二维数组存放所有的状态。 优化方案，可以将当前层的计算结果放在一维数组中，操作都在一位数组中进行。 复杂度分析 时间复杂度：O(n^2)，其中 n是三角形的行数。 空间复杂度：O(n)。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/triangle/solution/san-jiao-xing-zui-xiao-lu-jing-he-by-leetcode-solu/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现未优化版本12345678910111213141516171819202122232425262728293031323334public int minimumTotal(List&lt;List&lt;Integer&gt;&gt; triangle) &#123; //[ // [2], // [3,4], // [6,5,7], // [4,1,8,3] //] //[ // [2], // [5,6], // [11,10,13], // [15,11,18,16] //] int len = triangle.size(); int[][] dp = new int[len][len]; dp[0][0] = triangle.get(0).get(0); for (int i = 1; i &lt; len; i++) &#123; dp[i][0] = dp[i-1][0] + triangle.get(i).get(0); for (int j = 1; j &lt; i; j++) &#123; dp[i][j] = Math.min(dp[i-1][j-1], dp[i-1][j]) + triangle.get(i).get(j); &#125; dp[i][i] = dp[i-1][i-1] + triangle.get(i).get(i); &#125; int minTotal = dp[len-1][0]; for (int i = 1; i &lt; len; i++) &#123; minTotal = Math.min(minTotal, dp[len-1][i]); &#125; return minTotal;&#125; 优化版本12345678910111213141516171819202122232425262728293031public int minimumTotal(List&lt;List&lt;Integer&gt;&gt; triangle) &#123; //[ // [2], // [3,4], // [6,5,7], // [4,1,8,3] //] //[ // [15], // [11], // [18], // [16] //] int len = triangle.size(); int[] dp = new int[len]; dp[0] = triangle.get(0).get(0); for (int i = 1; i &lt; len; i++) &#123; dp[i] = dp[i - 1] + triangle.get(i).get(i); for (int j = i - 1; j &gt; 0; j--) &#123; dp[j] = Math.min(dp[j - 1], dp[j]) + triangle.get(i).get(j); &#125; dp[0] += triangle.get(i).get(0); &#125; int minTotal = dp[0]; for (int i = 1; i &lt; len; i++) &#123; minTotal = Math.min(minTotal, dp[i]); &#125; return minTotal;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode第350题： 两个数组的交集 II","slug":"LeetCode第350题：-两个数组的交集-II","date":"2020-07-12T22:59:48.000Z","updated":"2021-02-18T14:39:35.568Z","comments":true,"path":"2020/07/13/LeetCode第350题：-两个数组的交集-II/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/13/LeetCode%E7%AC%AC350%E9%A2%98%EF%BC%9A-%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86-II/","excerpt":"给定两个数组，编写一个函数来计算它们的交集。","text":"350. 两个数组的交集 II给定两个数组，编写一个函数来计算它们的交集。 示例 1： 12输入：nums1 = [1,2,2,1], nums2 = [2,2]输出：[2,2] 示例 2: 12输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4]输出：[4,9] 说明： 输出结果中每个元素出现的次数，应与元素在两个数组中出现次数的最小值一致。 我们可以不考虑输出结果的顺序。 进阶： 如果给定的数组已经排好序呢？你将如何优化你的算法？ 如果 nums1 的大小比 nums2 小很多，哪种方法更优？ 如果 nums2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？ 题目分析查询交集类似于一个查询是否存在的过程，可以采用哈希表加快查找效率。时间复杂度为O(m+n)，空间复杂度为O(min(m,n))。 或者采用先排序方式，进行数组比对。时间复杂度O(mlogm+nlogn)，空间复杂度O(min(m,n))。 代码实现哈希表法12345678910111213141516171819public int[] intersect(int[] nums1, int[] nums2) &#123; // 哈希表 int[] res = new int[Math.min(nums1.length, nums2.length)]; int idx = 0; Map&lt;Integer, Integer&gt; tmp = new HashMap&lt;&gt;(); for (int num : nums1) &#123; tmp.put(num, tmp.getOrDefault(num, 0) + 1); &#125; for (int val : nums2) &#123; Integer num = tmp.get(val); if (num != null &amp;&amp; num &gt; 0) &#123; res[idx++] = val; tmp.put(val, num - 1); &#125; &#125; return Arrays.copyOf(res, idx);&#125; 排序法1234567891011121314151617181920212223public int[] intersect(int[] nums1, int[] nums2) &#123; int[] res = new int[Math.min(nums1.length, nums2.length)]; int idx = 0; Arrays.sort(nums1); Arrays.sort(nums2); int idx1 = 0, idx2 = 0; int len1 = nums1.length, len2 = nums2.length; while (idx1 &lt; len1 &amp;&amp; idx2 &lt; len2) &#123; if (nums1[idx1] == nums2[idx2]) &#123; res[idx++] = nums1[idx1]; idx1++; idx2++; &#125; else if (nums1[idx1] &lt; nums2[idx2]) &#123; idx1++; &#125; else if (nums1[idx1] &gt; nums2[idx2]) &#123; idx2++; &#125; &#125; return Arrays.copyOf(res, idx);&#125; 结语如果 nums 2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中。那么就无法高效地对 nums2 进行排序，因此推荐使用方法一而不是方法二。在方法一中，nums2 只关系到查询操作，因此每次读取 nums2 中的一部分数据，并进行处理即可。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/intersection-of-two-arrays-ii/solution/liang-ge-shu-zu-de-jiao-ji-ii-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"SpringBoot整合Swagger2","slug":"SpringBoot整合Swagger2","date":"2020-07-11T21:25:02.000Z","updated":"2021-02-18T14:38:50.775Z","comments":true,"path":"2020/07/12/SpringBoot整合Swagger2/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/12/SpringBoot%E6%95%B4%E5%90%88Swagger2/","excerpt":"使用Gradle构建SpringBoot项目整合Swagger2，动态生成接口文档","text":"SpringBoot整合Swagger2准备工作使用IDEA创建一个Spring init项目，使用gradle构建项目，选中web模块和lombok模块 修改配置文件修改build.gradle文件springboot构建项目只支持Gradle5以上的版本，需要下载最新版本，笔者这边下载6.5版本的Gradle。 修改下载源为阿里的镜像源 1234repositories &#123; maven &#123; url &quot;http://maven.aliyun.com/nexus/content/groups/public/&quot; &#125; mavenCentral()&#125; 添加swagger2.9.2依赖 1234dependencies &#123; compile group: &#x27;io.springfox&#x27;, name: &#x27;springfox-swagger2&#x27;, version: &#x27;2.9.2&#x27; compile group: &#x27;io.springfox&#x27;, name: &#x27;springfox-swagger-ui&#x27;, version: &#x27;2.9.2&#125; 修改application.yaml编写swagger相关配置属性 1234567swagger: title: swagger学习 description: swagger学习案例 version: 1.0.0 name: marveal url: http://www.marvr.top email: marveal_rab@163.com 编写配置类创建一个config文件夹存放config类文件 编写SwaggerConfig类123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableSwagger2@EnableWebMvc@ComponentScan(basePackages = &#123;&quot;com.marveal.swagger.controller&quot;&#125;)public class SwaggerConfig&#123; @Value(&quot;$&#123;swagger.title&#125;&quot;) private String title; @Value(&quot;$&#123;swagger.description&#125;&quot;) private String description; @Value(&quot;$&#123;swagger.version&#125;&quot;) private String version; @Value(&quot;$&#123;swagger.name&#125;&quot;) private String name; @Value(&quot;$&#123;swagger.url&#125;&quot;) private String url; @Value(&quot;$&#123;swagger.email&#125;&quot;) private String email; @Bean public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()); &#125; private ApiInfo apiInfo() &#123; Contact contact = new Contact(name, url, email); return new ApiInfoBuilder() .title(title) .description(description) .contact(contact) .version(version) .build(); &#125;&#125; 编写WebMvcConfig类1234567891011@Configurationclass WebMvcConfig implements WebMvcConfigurer &#123; public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;swagger-ui.html&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/&quot;); registry.addResourceHandler(&quot;/webjars/**&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/webjars/&quot;); &#125;&#125; swagger-ui.html位于springfox-swagger-ui的resources目录下 编写controller类创建一个controller文件夹，存放controller类文件 123456789@RestController@Api(value = &quot;用户模块&quot;, tags = &quot;用户模块&quot;)public class UserController &#123; @ApiOperation(&quot;swagger测试&quot;) @RequestMapping(value = &quot;/hello&quot;, method = RequestMethod.GET) public String index()&#123; return &quot;hello swagger&quot;; &#125;&#125; 查看结果运行项目，如果没有报错的话，访问 http://localhost:8080/swagger-ui.html#/ 查看结果，出现如下页面表示整合成功","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"},{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"Gradle","slug":"Gradle","permalink":"https://rabbit-mar.github.io/tags/Gradle/"}]},{"title":"LeetCode 第378题: 有序矩阵中第K小的元素","slug":"LeetCode-第378题-有序矩阵中第K小的元素","date":"2020-07-02T05:32:29.000Z","updated":"2021-02-18T14:37:49.194Z","comments":true,"path":"2020/07/02/LeetCode-第378题-有序矩阵中第K小的元素/","link":"","permalink":"https://rabbit-mar.github.io/2020/07/02/LeetCode-%E7%AC%AC378%E9%A2%98-%E6%9C%89%E5%BA%8F%E7%9F%A9%E9%98%B5%E4%B8%AD%E7%AC%ACK%E5%B0%8F%E7%9A%84%E5%85%83%E7%B4%A0/","excerpt":"给定一个 n x n 矩阵，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。 请注意，它是排序后的第 k 小元素，而不是第 k 个不同的元素","text":"378. 有序矩阵中第K小的元素给定一个 n x n 矩阵，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。请注意，它是排序后的第 k 小元素，而不是第 k 个不同的元素。 示例：matrix = [[ 1, 5, 9],[10, 11, 13],[12, 13, 15]],k = 8,返回 13。 提示：你可以假设 k 的值永远是有效的，1 ≤ k ≤ n2 。 问题分析采用暴力解法：将二维数组转换为一维数组，然后将一位数组进行排序，返回对应下标的值。 采用二分查找法：我们知道整个二维数组中 matrix[0][0] 为最小值，matrix[n - 1][n - 1] 为最大值，现在我们将其分别记作 l 和 r。 可以发现一个性质：任取一个数 mid 满足 l≤mid≤r，那么矩阵中不大于 mid 的数，肯定全部分布在矩阵的左上角。 例如下图，取 mid=8mid=8： 我们可以看到，矩阵中大于 mid 的数就和不大于 mid 的数分别形成了两个板块，沿着一条锯齿线将这个矩形分开。其中左上角板块的大小即为矩阵中不大于 mid 的数的数量。 由此可解 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/solution/you-xu-ju-zhen-zhong-di-kxiao-de-yuan-su-by-leetco/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现暴力法12345678910111213public int kthSmallest(int[][] matrix, int k) &#123; int len = matrix.length; int[] nums = new int[len * len]; int idx = 0; for (int[] ints : matrix) &#123; for (int j = 0; j &lt; len; j++) &#123; nums[idx++] = ints[j]; &#125; &#125; Arrays.sort(nums); return nums[k-1];&#125; 二分查找法12345678910111213141516171819202122232425262728293031323334public int kthSmallest(int[][] matrix, int k) &#123; int len = matrix.length; int L = matrix[0][0], R = matrix[len - 1][len - 1]; int mid = 0; while (L &lt; R) &#123; mid = L + ((R - L) &gt;&gt; 1); // 等效于(L+R)&gt;&gt;1,使用这种是为了防止L+R溢出 int count = check(matrix, mid, k, len); if ( count &gt;= k ) &#123; R = mid; &#125; else &#123; L = mid + 1; &#125; &#125; return L;&#125;int check(int[][] matrix, int mid, int k, int len) &#123; int count = 0; for (int i = 0; i &lt; len; i++) &#123; if (matrix[i][0] &gt; mid) &#123; return count; &#125; for (int j = 0; j &lt; len; j++) &#123; if (matrix[i][j] &lt;= mid) &#123; count++; &#125; else &#123; j = len; &#125; &#125; &#125; return count;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第480题: 滑动窗口中位数","slug":"LeetCode-第480题-滑动窗口中位数","date":"2020-06-06T02:21:17.000Z","updated":"2021-02-18T14:36:10.526Z","comments":true,"path":"2020/06/06/LeetCode-第480题-滑动窗口中位数/","link":"","permalink":"https://rabbit-mar.github.io/2020/06/06/LeetCode-%E7%AC%AC480%E9%A2%98-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%AD%E4%BD%8D%E6%95%B0/","excerpt":"中位数是有序序列最中间的那个数。如果序列的大小是偶数，则没有最中间的数；此时中位数是最中间的两个数的平均数。","text":"480. 滑动窗口中位数中位数是有序序列最中间的那个数。如果序列的大小是偶数，则没有最中间的数；此时中位数是最中间的两个数的平均数。 例如： [2,3,4]，中位数是 3[2,3]，中位数是 (2 + 3) / 2 = 2.5 给你一个数组 nums，有一个大小为 k 的窗口从最左端滑动到最右端。窗口中有 k 个数，每次窗口向右移动 1 位。你的任务是找出每次窗口移动后得到的新窗口中元素的中位数，并输出由它们组成的数组。 示例：给出 nums = [1,3,-1,-3,5,3,6,7]，以及 k = 3。 12345678窗口位置 中位数 --------------- ----- [1 3 -1] -3 5 3 6 7 1 1 [3 -1 -3] 5 3 6 7 -1 1 3 [-1 -3 5] 3 6 7 -1 1 3 -1 [-3 5 3] 6 7 3 1 3 -1 -3 [5 3 6] 7 5 1 3 -1 -3 5 [3 6 7] 6 因此，返回该滑动窗口的中位数数组 [1,-1,-1,3,5,6]。 提示： 你可以假设 k 始终有效，即：k 始终小于输入的非空数组的元素个数。 与真实值误差在 10 ^ -5 以内的答案将被视作正确答案。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/sliding-window-median著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路分析提供个人的一些想法，通过遍历数组，取出滑动窗口的子数组进行排序，然后以直接定位的方式拿到中位数 时间复杂度: 取决与排序的时间复杂度O(N*排序时间复杂度)空间复杂度：O(K) 代码实现这里直接使用Java中自带的排序方式，快速排序 1234567891011121314public double[] medianSlidingWindow(int[] nums, int k) &#123; // [1 3 -1] -3 5 3 6 7 ==&gt; 1 3 -1 -3 5 [3 6 7] // 0 5 int len = nums.length; double[] res = new double[len - k + 1]; for (int i = 0; i &lt; len - k + 1; i++) &#123; int[] tmp = Arrays.copyOfRange(nums, i, i + k); Arrays.sort(tmp); res[i] = k % 2==0 ? ((double) tmp[k&gt;&gt;1] + (double) tmp[(k&gt;&gt;1) - 1])/2 : tmp[k&gt;&gt;1]; &#125; return res;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第1014题: 最佳观光组合","slug":"LeetCode-第1014题-最佳观光组合","date":"2020-06-04T21:26:44.000Z","updated":"2021-02-18T14:35:31.446Z","comments":true,"path":"2020/06/05/LeetCode-第1014题-最佳观光组合/","link":"","permalink":"https://rabbit-mar.github.io/2020/06/05/LeetCode-%E7%AC%AC1014%E9%A2%98-%E6%9C%80%E4%BD%B3%E8%A7%82%E5%85%89%E7%BB%84%E5%90%88/","excerpt":"给定正整数数组 A,返回一对（A[i] + A[j] + i - j）能取得的最大值","text":"1014. 最佳观光组合给定正整数数组 A，A[i] 表示第 i 个观光景点的评分，并且两个景点 i 和 j 之间的距离为 j - i。 一对景点（i &lt; j）组成的观光组合的得分为（A[i] + A[j] + i - j）：景点的评分之和减去它们两者之间的距离。 返回一对观光景点能取得的最高分。 示例： 输入：[8,1,5,2,6]输出：11解释：i = 0, j = 2, A[i] + A[j] + i - j = 8 + 5 + 0 - 2 = 11 提示： 2 &lt;= A.length &lt;= 50000 1 &lt;= A[i] &lt;= 1000 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/best-sightseeing-pair著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析 A[i] + A[j] + i - j ==&gt; (A[i] + i) + (A[j] - j) 这个公式变形成A[i]+i+A[j]-j，这样就可以看成是左A[i]+i和右A[j]-j两部分和的最大值。 代码实现123456789public int maxScoreSightseeingPair(int[] A) &#123; int res = Integer.MIN_VALUE, len = A.length; int part = A[0]; // (A[i] + i) for (int i = 1; i &lt; len; i++) &#123; res = Math.max(res, part + A[i] - i); part = Math.max(part, A[i] + i); &#125; return res;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第1344题: 时钟指针的夹角","slug":"LeetCode-第1344题-时钟指针的夹角","date":"2020-06-02T22:32:11.000Z","updated":"2021-02-18T14:34:50.331Z","comments":true,"path":"2020/06/03/LeetCode-第1344题-时钟指针的夹角/","link":"","permalink":"https://rabbit-mar.github.io/2020/06/03/LeetCode-%E7%AC%AC1344%E9%A2%98-%E6%97%B6%E9%92%9F%E6%8C%87%E9%92%88%E7%9A%84%E5%A4%B9%E8%A7%92/","excerpt":"给你两个数 hour 和 minutes 。请你返回在时钟上，由给定时间的时针和分针组成的较小角的角度（60 单位制）。","text":"1344. 时钟指针的夹角给你两个数 hour 和 minutes 。请你返回在时钟上，由给定时间的时针和分针组成的较小角的角度（60 单位制）。 示例 1： 输入：hour = 12, minutes = 30输出：165 示例 2： 输入：hour = 3, minutes = 30输出；75 示例 3： 输入：hour = 3, minutes = 15输出：7.5 示例 4： 输入：hour = 4, minutes = 50输出：155 示例 5： 输入：hour = 12, minutes = 0输出：0 提示： 1 &lt;= hour &lt;= 12 0 &lt;= minutes &lt;= 59 与标准答案误差在 10^-5 以内的结果都被视为正确结果。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/angle-between-hands-of-a-clock著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析数学题 可以将钟表想象为0-360的左边轴，其中一小格表示6，一大格表示30； 那么就可以通过hour和minute算出 h 和 m 两个位置； h位置需要通过minute的大小精确；30的minute相当于时针的(30/60)*5；那么就可以得到 h=minutes/60+hour)*30 m的位置就是 minutes*6 m-h就可以得到两者之间的角度，最后再调节一下负数的情况就行了 代码实现1234567public double angleClock(int hour, int minutes) &#123; double hAngle = ((double) minutes/60+hour)*30; double h = hAngle &gt; 360 ? hAngle-360 : hAngle; double m = minutes * 6; double res = Math.abs(m-h); return res &gt; 180 ? 360-res : res;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第121题: 买卖股票的最佳时机","slug":"LeetCode-第121题-买卖股票的最佳时机","date":"2020-06-02T07:18:20.000Z","updated":"2021-02-18T14:33:49.474Z","comments":true,"path":"2020/06/02/LeetCode-第121题-买卖股票的最佳时机/","link":"","permalink":"https://rabbit-mar.github.io/2020/06/02/LeetCode-%E7%AC%AC121%E9%A2%98-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA/","excerpt":"给定一个数组，它的第 i 个元素是一支给定股票第 i天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票一次），设计一个算法来计算你所能获取的最大利润。","text":"121. 买卖股票的最佳时机给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 如果你最多只允许完成一笔交易（即买入和卖出一支股票一次），设计一个算法来计算你所能获取的最大利润。 注意：你不能在买入股票前卖出股票。 示例 1: 1234输入: [7,1,5,3,6,4]输出: 5解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 示例 2: 123输入: [7,6,4,3,1]输出: 0解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析 假设给定的数组为：[7, 1, 5, 3, 6, 4] 在题目中，我们只要用一个变量记录一个历史最低价格 minprice，我们就可以假设自己的股票是在那天买的。那么我们在第 i 天卖出股票能得到的利润就是 prices[i] - minprice。 因此，我们只需要遍历价格数组一遍，记录历史最低点，然后在每一天考虑这么一个问题：如果我是在历史最低点买进的，那么我今天卖出能赚多少钱？当考虑完所有天数之时，我们就得到了最好的答案。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/121-mai-mai-gu-piao-de-zui-jia-shi-ji-by-leetcode-/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 复杂度分析 时间复杂度：O(n)，只需要遍历一次。 空间复杂度：O(1)，只使用了常数个变量。 代码实现1234567891011public int maxProfit(int[] prices) &#123; int minPrice = Integer.MAX_VALUE; int maxProfit = 0; for (int price : prices) &#123; if (price &lt; minPrice) minPrice = price; else if (price - minPrice &gt; maxProfit) maxProfit = price - minPrice; &#125; return maxProfit;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第1431题: 拥有最多糖果的孩子","slug":"LeetCode-第1431题-拥有最多糖果的孩子","date":"2020-05-31T18:21:33.000Z","updated":"2021-02-18T14:33:11.745Z","comments":true,"path":"2020/06/01/LeetCode-第1431题-拥有最多糖果的孩子/","link":"","permalink":"https://rabbit-mar.github.io/2020/06/01/LeetCode-%E7%AC%AC1431%E9%A2%98-%E6%8B%A5%E6%9C%89%E6%9C%80%E5%A4%9A%E7%B3%96%E6%9E%9C%E7%9A%84%E5%AD%A9%E5%AD%90/","excerpt":"儿童节特惠——给你一个数组 candies 和一个整数 extraCandies ，其中 candies[i] 代表第 i 个孩子拥有的糖果数目。","text":"1431. 拥有最多糖果的孩子儿童节特惠 给你一个数组 candies 和一个整数 extraCandies ，其中 candies[i] 代表第 i 个孩子拥有的糖果数目。 对每一个孩子，检查是否存在一种方案，将额外的 extraCandies 个糖果分配给孩子们之后，此孩子有 最多 的糖果。注意，允许有多个孩子同时拥有 最多 的糖果数目。 示例 1：输入：candies = [2,3,5,1,3], extraCandies = 3输出：[true,true,true,false,true]解释：孩子 1 有 2 个糖果，如果他得到所有额外的糖果（3个），那么他总共有 5 个糖果，他将成为拥有最多糖果的孩子。孩子 2 有 3 个糖果，如果他得到至少 2 个额外糖果，那么他将成为拥有最多糖果的孩子。孩子 3 有 5 个糖果，他已经是拥有最多糖果的孩子。孩子 4 有 1 个糖果，即使他得到所有额外的糖果，他也只有 4 个糖果，无法成为拥有糖果最多的孩子。孩子 5 有 3 个糖果，如果他得到至少 2 个额外糖果，那么他将成为拥有最多糖果的孩子。 示例 2：输入：candies = [4,2,1,1,2], extraCandies = 1输出：[true,false,false,false,false]解释：只有 1 个额外糖果，所以不管额外糖果给谁，只有孩子 1 可以成为拥有糖果最多的孩子。 示例 3：输入：candies = [12,1,12], extraCandies = 10输出：[true,false,true] 提示：2 &lt;= candies.length &lt;= 1001 &lt;= candies[i] &lt;= 1001 &lt;= extraCandies &lt;= 50 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/kids-with-the-greatest-number-of-candies著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析第一次循环遍历，找出数组中的最大值；第二次循环遍历加上糖果数如果大于等于最大值就插入true； 代码实现12345678910111213public List&lt;Boolean&gt; kidsWithCandies(int[] candies, int extraCandies) &#123; int len = candies.length; int max = candies[0]; for (int i = 1; i &lt; len; i++) &#123; max = Math.max(max , candies[i]); &#125; List&lt;Boolean&gt; res = new ArrayList&lt;&gt;(); for (int candy : candies) &#123; res.add(candy + extraCandies &gt;= max); &#125; return res;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"就这？LinkedList这就没难度——撕容器(二)","slug":"就这？LinkedList这就没难度——撕容器(二)","date":"2020-05-31T01:06:53.000Z","updated":"2021-02-18T14:27:43.219Z","comments":true,"path":"2020/05/31/就这？LinkedList这就没难度——撕容器(二)/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/31/%E5%B0%B1%E8%BF%99%EF%BC%9FLinkedList%E8%BF%99%E5%B0%B1%E6%B2%A1%E9%9A%BE%E5%BA%A6%E2%80%94%E2%80%94%E6%92%95%E5%AE%B9%E5%99%A8(%E4%BA%8C)/","excerpt":"根据LinkedList的新增，查收，删除，修改进行代码分析，难度低","text":"LinkedListLinkedList的成员变量 一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。 被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化。 12345678// 链表大小transient int size = 0;// 头结点transient Node&lt;E&gt; first;// 尾结点transient Node&lt;E&gt; last; Node类从这里可以看出来LinkedList是一个双向链表 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; LinkedList的构造方法一共有两个构造方法：一个空链表；一个根据容器创建的链表 根据容器创建的链表调用addAll方法将所有的元素插入到链表中；addAll方法中首先检查起始下标，然后将容器先转为数组，检索到要插入下标的元素，查看node方法，采用了双向查找，如果大于1/2就从尾结点开始查找，小于1/2就从头结点开始找；遍历数组，使用尾插法添加元素；维护size变量，modCount加1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// 构造一个空链表public LinkedList() &#123;&#125;// 根据容器创建一个链表public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;// --------------------public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;// ---------------------public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true;&#125;// -------------------------private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;// -------------------------private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;// ---------------------------Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; LinkedList的添加方法LinkedList中默认的添加方法为尾插法； 但是提供了addFirst方法进行头插； 1234567891011121314151617181920212223242526272829303132public boolean add(E e) &#123; linkLast(e); return true;&#125;// ------------------void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;// ---------------------public void addFirst(E e) &#123; linkFirst(e);&#125;// ----------------------private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125; LinkedList的获取方法LinkedList提供了通过下标获取的方法，同样先验证下标，再访问下标结点的值。 1234public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125; LinkedList的删除方法LinkedList提供了remove方法，默认是移除头结点。 1234567891011121314151617181920212223242526public E remove() &#123; return removeFirst();&#125;// -----------------------public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;// ------------------------private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125; 也可以根据元素，下标移除元素，都是从头结点开始遍历 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;// -------------------------------E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;// ---------------------------------public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; 也可以通过clear方式，移除所有元素；通过遍历的方式将node的三个部分置null 12345678910111213141516public void clear() &#123; // Clearing all of the links between nodes is &quot;unnecessary&quot;, but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++;&#125; 总结 LinkedList本质是一个双向链表 在新增和删除的使用同样维护着一个modCount 查找通过判断中端来选择从哪边查找 移除默认从头结点开始","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"连ArrayList都要撕——撕容器(一)","slug":"连ArrayList都要撕——撕容器(一)","date":"2020-05-31T00:12:11.000Z","updated":"2021-02-18T14:27:43.343Z","comments":true,"path":"2020/05/31/连ArrayList都要撕——撕容器(一)/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/31/%E8%BF%9EArrayList%E9%83%BD%E8%A6%81%E6%92%95%E2%80%94%E2%80%94%E6%92%95%E5%AE%B9%E5%99%A8(%E4%B8%80)/","excerpt":"剖析ArrayList的实现，通过初始化，新增，修改，删除来查看ArrayList的主要方法","text":"ArrayList本次撕代码基于（jdk11） 了解ArrayList的成员变量通过查看ArrayList的成员变量可以发现，ArrayList底层实现是Object数组，而且默认初始化大小为10。默认最大的数组大小为Integer.MAX_VALUE - 8 = 2147483639，实际在默认情况下堆区会优先抛出OOM 1234567891011121314151617181920// 初始容量private static final int DEFAULT_CAPACITY = 10;// 用于空实例的共享空数组实例private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;// 共享的空数组实例，用于默认大小的空实例// 与EMPTY_ELEMENTDATA区别开，当插入第一个元素时，需要膨胀多少private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;// 存储ArrayList元素的数组缓冲区// ArrayList的容量是此数组缓冲区的长度// 添加第一个元素时，任何具有elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA的空ArrayList都将扩展为DEFAULT_CAPACITY。transient Object[] elementData; // non-private to simplify nested class access// ArrayList的大小private int size;// 要分配的最大数组大小（除非必要）。 一些虚拟机在数组中保留一些头字。 尝试分配更大的阵列可能会导致OutOfMemoryError：请求的阵列大小超出VM限制private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; ArrayList的创建ArrayList的构造方法有三种； 123456789public ArrayList(int initialCapacity) &#123; // 指定初始化容量&#125;public ArrayList() &#123; // 空参构造&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; // 根据一个容器构造&#125; 带初始化容量的构造方法；默认创建了一个容量为10的数组 123456789public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125; 空参构造；将DEFAULTCAPACITY_EMPTY_ELEMENTDATA空数组赋值给elementData； 官方注释 Constructs an empty list with an initial capacity of ten. 构造一个初始容量为10的空列表。但实际上在初始化时并没有分配空间 123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 根据一个容器构造；首先调用了AbstractCollection类的toArray方法 123456789101112public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // defend against c.toArray (incorrectly) not returning Object[] // (see e.g. https://bugs.openjdk.java.net/browse/JDK-6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; AbstractCollection类的toArray方法；通过迭代器将对象转为数组；在finishToArray方法中有数组的扩容，且最大数组长度为Integer.MaxValue(2147483647) 1234567891011public Object[] toArray() &#123; // Estimate size of array; be prepared to see more or fewer elements Object[] r = new Object[size()]; Iterator&lt;E&gt; it = iterator(); for (int i = 0; i &lt; r.length; i++) &#123; if (! it.hasNext()) // fewer elements than expected return Arrays.copyOf(r, i); r[i] = it.next(); &#125; return it.hasNext() ? finishToArray(r, it) : r;&#125; ArrayList的add方法modCount为AbstractList类的一个成员变量；主要是为了防止并发情况下对容器结构的修改，如果被修改就抛出异常，在这称为“fail-fast”快速失败。同样add方法返回的布尔值没有意义，不管怎样都返回true。 modCount官方注释： The number of times this list has beenstructurally modified. Structural modifications are those that change the size of the list, or otherwise perturb it in such a fashion that iterations in progress may yield incorrect results. 已对该列表进行结构修改的次数。 结构修改是指更改列表大小或以其他方式干扰列表的方式，即正在进行的迭代可能会产生错误的结果。 This field is used by the iterator and list iterator implementation returned by the iterator and listIterator methods. If the value of this field changes unexpectedly, the iterator (or list iterator) will throw a ConcurrentModificationException in response to the next, remove, previous, set or add operations. This provides fail-fast behavior, rather than non-deterministic behavior in the face of concurrent modification during iteration. 迭代器和listIterator方法返回的迭代器和列表迭代器实现使用此字段。如果此字段的值意外更改，则迭代器（或列表迭代器）将抛出ConcurrentModificationException，以响应next, remove, previous, set或者add操作。面对迭代过程中的并发修改，这提供了快速故障行为，而不是不确定的行为。 Use of this field by subclasses is optional. If a subclass wishes to provide fail-fast iterators (and list iterators), then it merely has to increment this field in its add(int, E) and remove(int) methods (and any other methods that it overrides that result in structural modifications to the list). A single call to add(int, E) or remove(int) must add no more than one to this field, or the iterators (and list iterators) will throw bogus ConcurrentModificationExceptions. If an implementation does not wish to provide fail-fast iterators, this field may be ignored. 子类对该字段的使用是可选的。如果子类希望提供快速失败的迭代器（和列表迭代器），则只需在其add（int，E）和remove（int）方法（以及任何其他覆盖该方法导致结构化的方法）中递增此字段即可。修改列表）。一次调用add（int，E）或remove（int）不得在此字段中添加不超过一个，否则迭代器（和列表迭代器）将抛出虚假的ConcurrentModificationExceptions。如果实现不希望提供快速失败迭代器，则可以忽略此字段。 12345public boolean add(E e) &#123; modCount++; add(e, elementData, size); return true;&#125; 查看其中调用的add方法；这个add方法是私用的，只供内部调用；当数组里面元素的长度和数组长度一致时就要调用grow方法进行扩容；否则就在s位置上插入元素并将size加1 官方注解： This helper method split out from add(E) to keep method bytecode size under 35 (the -XX:MaxInlineSize default value), which helps when add(E) is called in a C1-compiled loop. 此辅助方法从add(E)中分离出来，以使方法的字节码大小保持在35以下（-XX：MaxInlineSize默认值），这有助于在C1编译循环中调用add(E) 关于-XX：MaxInlineSize的介绍——https://www.cnblogs.com/xyz-star/p/10152564.html C1是即时编译器(JIT)的编译器(compiler)，还有一个C2；C1的编译速度较快，C2所编译的方法运行速度较快； 123456private void add(E e, Object[] elementData, int s) &#123; if (s == elementData.length) elementData = grow(); elementData[s] = e; size = s + 1;&#125; 查看grow方法；其中有调用了grow方法，继续跟踪； 调用了Arrays工具类中的CopyOf方法，其中含有一个newCapacity的方法，这是数组的扩容算法，将新数组扩容为原来的1.5倍，如果新分配的数组超过了MAX_ARRAY_SIZE（Integer.MaxValue-8），就分配一个hugeCapacity，最大不超过Integer.MaxValue； 又调用了copyOf方法；在这个方法中就可以看到copyOf方法使用HotSpotIntrinsicCandidate注解；其中如果元素的数据类型是引用类型，就直接new一个新的数组；如果是基本数据类型(int,log,float,double,byte,short,char,boolean)就调用了newInstance方法； 追踪newInstance方法调用了newArray方法；根据指定的数据类型创建一个新数组； 查看newArray方法；直接调用了jvm的c++代码； 回去再去查看System.arraycopy方法；同样调用了jvm的c++代码； JDK的源码中，被@HotSpotIntrinsicCandidate标注的方法，在HotSpot中都有一套高效的实现，该高效实现基于CPU指令，运行时，HotSpot维护的高效实现会替代JDK的源码实现，从而获得更高的效率。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162private Object[] grow() &#123; return grow(size + 1);&#125;// ------------------private Object[] grow(int minCapacity) &#123; return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity));&#125;//-------------------private int newCapacity(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 1.5倍oldCapacity if (newCapacity - minCapacity &lt;= 0) &#123;// 越界 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) return Math.max(DEFAULT_CAPACITY, minCapacity); if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return minCapacity; &#125; return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;// -------------------public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123; return (T[]) copyOf(original, newLength, original.getClass());&#125;// -------------------// Copies the specified array, truncating or padding with nulls (if necessary) so the copy has the specified length. For all indices that are valid in both the original array and the copy, the two arrays will contain identical values. For any indices that are valid in the copy but not the original, the copy will contain null. Such indices will exist if and only if the specified length is greater than that of the original array. The resulting array is of the class newType.// 复制指定的数组，截断或使用null填充（如果需要），以便副本具有指定的长度。 对于在原始数组和副本中均有效的所有索引，两个数组将包含相同的值。 对于副本中有效但原始索引无效的任何索引，副本将包含null。 当且仅当指定长度大于原始数组的长度时，此类索引才会存在。 结果数组属于newType类。@HotSpotIntrinsicCandidatepublic static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings(&quot;unchecked&quot;) T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125;// -------------------/**Creates a new array with the specified component type and length. Invoking this method is equivalent to creating an array as follows:int[] x = &#123;length&#125;;Array.newInstance(componentType, x);The number of dimensions of the new array must not exceed 255.*//**用指定的组件类型和长度创建一个新数组。 调用此方法等效于如下创建数组：int [] x = &#123;length&#125;;Array.newInstance（componentType，x）;新数组的维数不能超过255。*/public static Object newInstance(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException &#123; return newArray(componentType, length);&#125;//------------------------@HotSpotIntrinsicCandidateprivate static native Object newArray(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException;// ----------------------@HotSpotIntrinsicCandidatepublic static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); ArrayList的get方法查看get方法；调用了checkIndex方法，使用了ForceInline注解，不触发方法内联的规格，然后调用了Preconditions.checkIndex方法，小于0或者大于等于length就抛出异常，否则就访问下标；再通过elementData方法获取下标的数据； 内联概念：把函数调用的方法直接内嵌到方法内部，减少函数调用的次数 函数的调用过程： 调用某个函数实际上将程序执行顺序转移到该函数所存放在内存中某个地址，将函数的程序内容执行完后，再返回到 转去执行该函数前的地方。这种转移操作要求在转去前要保护现场并记忆执行的地址，转回后先要恢复 现场，并按原来保存地址继续执行。也就是我们常说的压栈和出栈。 应用场景：当我们在调用频率很高的地方经常调用一个其他函数，但是函数体很小，函数频繁的函数跳转影响性能。这时候jvm能够自动识别热点函数，到达阀值触发jit优化。对其进行内联。 https://www.jianshu.com/p/8c207a5f2774 12345678910111213141516171819202122public E get(int index) &#123; Objects.checkIndex(index, size); return elementData(index);&#125;// ----------------------@ForceInlinepublic static int checkIndex(int index, int length) &#123; return Preconditions.checkIndex(index, length, null);&#125;// ---------------------@HotSpotIntrinsicCandidatepublic static &lt;X extends RuntimeException&gt; int checkIndex(int index, int length, BiFunction&lt;String, List&lt;Integer&gt;, X&gt; oobef) &#123; if (index &lt; 0 || index &gt;= length) throw outOfBoundsCheckIndex(oobef, index, length); return index;&#125;// ----------------------E elementData(int index) &#123; return (E) elementData[index];&#125; ArrayList的remove方法同样首先检查下标是否合法，再拷贝了一份数组给es数组，然后调用了fastRemove方法；修改次数加1，再去执行数组的拷贝(从es的i+1的位置拷贝到i的位置，实际上是值的覆盖)，最后将最后一个位置赋值为null； 123456789101112131415161718public E remove(int index) &#123; Objects.checkIndex(index, size); final Object[] es = elementData; @SuppressWarnings(&quot;unchecked&quot;) E oldValue = (E) es[index]; fastRemove(es, index); return oldValue;&#125;//-----------------------private void fastRemove(Object[] es, int i) &#123; modCount++; final int newSize; if ((newSize = size - 1) &gt; i) System.arraycopy(es, i + 1, es, i, newSize - i); es[size = newSize] = null;&#125; ArrayList的clear方法先将size赋值给to，再将size置为0，i置为0，遍历赋值为null； 123456public void clear() &#123; modCount++; final Object[] es = elementData; for (int to = size, i = size = 0; i &lt; to; i++) es[i] = null;&#125; 与Vector的区别Vector在每个入口方法中都添加了synchronized关键字，锁粒度大。并且同时维护着modCount变量 总结 ArrayList中有一个modCount，在并发情况下被修改可以触发fail-fast快速失败，在add和remove的时候会加1 ArrayList中的扩容为1.5倍扩容，没有设置阈值，超过就size就扩容 ArrayList的主要方法为System.arraycopy，将原数组拷贝到新数组，添加删除会调用 ArrayList的删除是将下标位置上的值置为null","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第101题: 对称二叉树","slug":"LeetCode-第101题-对称二叉树","date":"2020-05-30T20:17:11.000Z","updated":"2021-02-18T14:27:43.424Z","comments":true,"path":"2020/05/31/LeetCode-第101题-对称二叉树/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/31/LeetCode-%E7%AC%AC101%E9%A2%98-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"给定一个二叉树，检查它是否是镜像对称的。","text":"101. 对称二叉树给定一个二叉树，检查它是否是镜像对称的。 例如，二叉树 [1,2,2,3,4,4,3] 是对称的 但是下面这个 [1,2,2,null,3,null,3] 则不是镜像对称的: 进阶： 你可以运用递归和迭代两种方法解决这个问题吗？ 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/symmetric-tree著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析探究二叉树常见的为递归； 在这题目中可以申请两条路径，让left.right和right.left相比，让left.left与right.right相比； 代码实现1234567891011public boolean isSymmetric(TreeNode root) &#123; if (root == null) return true; return check(root.left, root.right);&#125;public boolean check(TreeNode left, TreeNode right)&#123; if (left == null &amp;&amp; right == null) return true; if (left == null || right == null || left.val != right.val) return false; return check(left.right, right.left) &amp;&amp; check(left.left, right.right);&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第84题: 柱状图中最大的矩形","slug":"LeetCode-第84题-柱状图中最大的矩形","date":"2020-05-30T02:57:37.000Z","updated":"2021-02-18T14:24:55.144Z","comments":true,"path":"2020/05/30/LeetCode-第84题-柱状图中最大的矩形/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/30/LeetCode-%E7%AC%AC84%E9%A2%98-%E6%9F%B1%E7%8A%B6%E5%9B%BE%E4%B8%AD%E6%9C%80%E5%A4%A7%E7%9A%84%E7%9F%A9%E5%BD%A2/","excerpt":"给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。 求在该柱状图中，能够勾勒出来的矩形的最大面积。","text":"给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。 求在该柱状图中，能够勾勒出来的矩形的最大面积。 以上是柱状图的示例，其中每个柱子的宽度为 1，给定的高度为 [2,1,5,6,2,3]。 图中阴影部分为所能勾勒出的最大矩形面积，其面积为 10 个单位。 示例: 输入: [2,1,5,6,2,3]输出: 10 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/largest-rectangle-in-histogram著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析根据题型进行一个模式匹配——单调栈； 只要后一个比前一个大就入栈；直到后一个比前一个小就弹栈；同时通过设置两个哨兵减少算法的复杂度，但是用到了O(n)的空间。 复杂度分析 时间复杂度：O*(*N) 空间复杂度：O*(*N) 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/largest-rectangle-in-histogram/solution/zhu-zhuang-tu-zhong-zui-da-de-ju-xing-by-leetcode-/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现1234567891011121314151617181920212223public int largestRectangleArea(int[] heights) &#123; int len = heights.length; if (len &lt; 1) return 0; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int[] newHeights = new int[len + 2]; System.arraycopy(heights, 0, newHeights, 1, len); heights = newHeights; len += 2; stack.addLast(0); int area = 0; for (int i = 1; i &lt; len; i++) &#123; while (heights[stack.peekLast()] &gt; heights[i]) &#123; int height = heights[stack.removeLast()]; int distance = i - stack.peekLast() - 1; area = Math.max(area, height*distance); &#125; stack.addLast(i); &#125; return area;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"缓存三大问题——缓存穿透&缓存击穿&缓存雪崩","slug":"缓存三大问题——缓存穿透-缓存击穿-缓存雪崩","date":"2020-05-29T02:18:29.000Z","updated":"2021-02-18T14:24:06.136Z","comments":true,"path":"2020/05/29/缓存三大问题——缓存穿透-缓存击穿-缓存雪崩/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/29/%E7%BC%93%E5%AD%98%E4%B8%89%E5%A4%A7%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/","excerpt":"整理缓存的三大问题——缓存穿透&缓存击穿&缓存雪崩；是什么和解决方案，提供分布式情况下缓存的解决方案和思考","text":"缓存穿透&amp;缓存击穿&amp;缓存雪崩一个缓存系统必定需要解决的三大问题：缓存穿透&amp;缓存击穿&amp;缓存雪崩。这三大问题的实质都是因为某种缘故而将流量打在数据库。 缓存穿透是什么缓存穿透是指客户端发起请求，请求字段不在Redis中而打到数据库，不管数据库是否有数据都得承接流量。如果大批量的数据打到数据库就会直接导致数据库服务器宕机。 解决办法解决访问不存在数据的常见解决办法就是采用布隆过滤器，布隆过滤器初始一个足够大的bitmap，请求数据通过hash算法访问bitmap来判断是否含有值。详情参见博文——布隆过滤器的原理及其手写一个简单的布隆过滤器 缓存击穿是什么缓存雪崩是指在某一时刻某一个热点key失效，导致该key的所有数据在一瞬间请求到数据库，造成数据库的瞬间瘫痪。 解决办法 设置key不失效。设置一些热点key不过期，就不会导致key失效的问题 添加二级缓存。或者添加二级缓存，一级缓存中的key失效后，二级缓存能够立刻分担流量。然后二级缓存再同步key到一级缓存 缓存雪崩是什么缓存雪崩和缓存击穿类似，是指大批量的key在某个时间点失效，导致流量打在数据库。 解决办法在给key设置过期时间的时候加上一个随机值，创造一个窗口期，分担流量。 总结 在小流量的情况下，缓存击穿的问题没有必要解决，意义不大并且浪费性能，如果非要到解决缓存穿透的问题也只有在分布式的情况下。这里可以提供两种方案： 分布式锁解决。 在访问redis查询后没有的情况下，先不访问数据库，而去访问分布式锁，抢到锁的请求去执行，然后更新redis 流量控制。（最佳方案） 在访问redis中没有的情况下，放行定量的请求去数据库访问，然后刷回redis 对于缓存穿透的问题至少要做好事前、事中、事后的准备和考虑。 事前：设置热点key不失效，大批量使用key采用过期时间加随机值的方案；做好缓存集群，保证缓存服务高可用 事中：添加二级缓存，做好服务限流、降级、熔断等策略 事后：RDB+AOF持久化策略，快速重新上线，提供服务。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]},{"title":"基于Redis分布式锁的演变及实现","slug":"基于Redis分布式锁的演变及实现","date":"2020-05-29T01:31:29.000Z","updated":"2021-02-18T14:29:22.508Z","comments":true,"path":"2020/05/29/基于Redis分布式锁的演变及实现/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/29/%E5%9F%BA%E4%BA%8ERedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E6%BC%94%E5%8F%98%E5%8F%8A%E5%AE%9E%E7%8E%B0/","excerpt":"对Redis实现分布式锁的总结和自我的认识，文章中借鉴了部分官网的原句，后面会有所补充","text":"基于Redis分布式锁的演变及实现实现锁必须满足三个特性：①互斥； ②共享；③多任务； 即多个用户不能同时访问同一个共享资源 redis分布式锁的实现关键在于setnx命令，其语义为只在键 key 不存在的情况下， 将键 key 的值设置为 value ，若键 key 已经存在， 则 SETNX 命令不做任何动作。 第一轮演进通过setnx就可以画出一个简单的分布式锁雏形。当客户端执行业务之前，先去redis中设置一把锁，当下一个线程来访问时，也去Redis中setnx；但是由于第一次设置的锁并没有释放，所以第二线程会访问失败无法执行业务代码。直到第一个线程删除锁。 12345678910111213public String main()&#123; String lockKey = &quot;lockKey&quot;; Boolean lock = template.opsForValue().setIfAbsent(lockKey, &quot;123&quot;); if (lock != null &amp;&amp; !lock) &#123; // 加锁失败 return &quot;error&quot;; &#125; // doSomething System.out.println(&quot;doSomething&quot;); template.delete(lockKey); // 删除锁 return &quot;success&quot;;&#125; 第二轮演进根据第一轮的模型，思考有什么缺点: 如果说第一个线程在执行业务代码的时候出现了异常，直接退出程序，没有删除锁，那么就会形成死锁，其他线程无法再次加锁 解决方案: 给锁加上过期时间，当超过时间redis就自动删除key 1template.opsForValue().setIfAbsent(lockKey, &quot;123&quot;, 10, TimeUnit.SECONDS); 第三轮演进根据第二轮模型，思考其问题: 当多个线程访问时，如果第一个线程执行远程调用的时候花费了11s，超出了预设的过期时间，那么在第10秒的时候Redis就已经将线程1创建的key删除，线程2就会创建锁；但是在第11秒时，Redis删除key，此时的key为线程2的key；那么此时锁的互斥性被破坏，使得锁失效。 解决方案: 给每个线程设置唯一标识，删除key时先判断是否为唯一标识，再删除；这样能解决删除同一个key的问题。 开一个子线程设置一个定时器，当过去时间超过预设的2/3时，重新设置时间。例如规定的阈值为10s，那么每三秒检测redis中的key，如果key还存在就再延长2/3为6秒。 1234567891011121314151617181920212223242526272829303132333435363738394041public String main()&#123; String lockKey = &quot;lockKey&quot;; String randId = UUID.randomUUID().toString(); // 定时器 Timer timer = new Timer(&quot;lock_timer&quot;); try &#123; Boolean lock = template.opsForValue().setIfAbsent(lockKey, randId, 10, TimeUnit.SECONDS); if (lock != null &amp;&amp; !lock) &#123; // 加锁失败 return &quot;error&quot;; &#125; // 开始定时器 new Thread(()-&gt; timer.schedule(new LockTimer(template, lockKey), 3000)).start(); // doSomething System.out.println(&quot;doSomething&quot;); &#125;finally &#123; if (Objects.equals(template.opsForValue().get(lockKey), randId)) &#123; template.delete(lockKey); // 删除锁 &#125; &#125; return &quot;success&quot;;&#125;class LockTimer extends TimerTask &#123; private StringRedisTemplate template; private String key; private int threshold = 10; private int delay = 1000 * threshold / 3; LockTimer(StringRedisTemplate template, String key) &#123; this.template = template; this.key = key; &#125; @Override public void run() &#123; Long time = template.getExpire(key); if (time !=null &amp;&amp; time &lt; delay) template.expire(key, threshold * 2 / 3, TimeUnit.SECONDS); &#125;&#125; 基于第三轮演进的案例——秒杀场景下基于第三轮的系统架构，可以实现一个分布式情况下简略的秒杀场景；客户端通过nginx做的负载均衡访问到两台tomcat上，两个接口调用第三方Redis实现秒杀情景。 在第三轮演进中可以发现，每次进来一个新线程都会去新建一个定时器，为了节省资源，将定时器定为单例，其他代码和第三轮演进类似；(由于已经实现分布式锁，所以每次执行定时器只有一个子线程，所以不需要加锁) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private static final String LOCK_KEY = &quot;lockKey&quot;;@Value(&quot;$&#123;server.port&#125;&quot;)private int port;@RequestMapping(&quot;/&quot;)public String main() &#123; String randId = UUID.randomUUID().toString(); Integer stock; try &#123; stock = (Integer) template.opsForValue().get(&quot;stock&quot;); if (stock != null &amp;&amp; stock &lt;= 0) &#123; return &quot;end&quot;; &#125; Boolean lock = template.opsForValue().setIfAbsent(LOCK_KEY, randId, 10, TimeUnit.SECONDS); if (lock != null &amp;&amp; !lock) &#123; // 加锁失败 return &quot;error&quot;; &#125; // 开始定时器 new Thread(() -&gt; MyTimer.getTimer().schedule(LockTimer.getTimer(template, randId), 4000)).start(); // doSomething Long num = template.opsForValue().decrement(&quot;stock&quot;); if (num != null) &#123; stock = Math.toIntExact(num); System.out.println(port + &quot;\\t剩余数量： &quot; + stock); &#125; &#125; finally &#123; if (Objects.equals(template.opsForValue().get(LOCK_KEY), randId)) &#123; template.delete(LOCK_KEY); // 删除锁 &#125; &#125; return &quot;success&quot;;&#125;static class LockTimer extends TimerTask &#123; private static LockTimer lockTimer; private RedisTemplate&lt;String, Object&gt; template; private String randId; private LockTimer(RedisTemplate&lt;String, Object&gt; template, String randId) &#123; this.randId = randId; this.template = template; &#125; public static LockTimer getTimer(RedisTemplate&lt;String, Object&gt; template, String randId) &#123; if (lockTimer == null) &#123; return new LockTimer(template, randId); &#125; return lockTimer; &#125; @Override public void run() &#123; String val = (String) template.opsForValue().get(&quot;LOCK_KEY&quot;); if (randId.equals(val)) template.expire(LOCK_KEY, 10, TimeUnit.SECONDS); &#125;&#125;static class MyTimer extends Timer &#123; private static MyTimer timer; private MyTimer() &#123; super(); &#125; public static MyTimer getTimer() &#123; if (timer == null) &#123; return new MyTimer(); &#125; return timer; &#125;&#125; 然后给Redis设置初值；开启nginx；启动8080端口、8081端口；开启jmeter压测；在控制台查看报告 Redis： 1234127.0.0.1:6379&gt; set stock 100 OK 127.0.0.1:6379&gt; get stock &quot;100&quot; nginx： 12345678910upstream tomcats &#123; server 127.0.0.1:8080; server 127.0.0.1:8081; &#125; server &#123; location / &#123; proxy_pass http://tomcats; &#125; # 省略其他配置... &#125; 启动8080\\8081服务 jmeter设置线程组压测(200个线程、时间间隔0秒、发四组) 查看控制台输出 12345678080 剩余数量： 988080 剩余数量： 97# 省略部分输出...8080 剩余数量： 608080 剩余数量： 588080 剩余数量： 558080 剩余数量： 54 1234568081 剩余数量： 998081 剩余数量： 96# 省略部分输出...8081 剩余数量： 598081 剩余数量： 578081 剩余数量： 56 可以发现两个tomcat一共接受800个线程请求，由于加锁大部分请求被挡在外面，发生了少买的情况。并且在同一时间并发数越高的情况下，请求被打回的情况越多。那么如何改进呢？我们可以借助锁升级过程中的一个思想，如果没有拿到锁就自旋，自选10次还是拿不到锁就退出。 代码实现也比较简单，只需要将上面的判断库存的过程和获取锁的过程放在while循环中即可： 123456789101112131415Boolean lock = false;int count = 10;while (lock != null &amp;&amp; !lock) &#123; // 加锁失败 stock = (Integer) template.opsForValue().get(&quot;stock&quot;); if (stock != null &amp;&amp; stock &lt;= 0) &#123; System.out.println(&quot;卖完了！！！&quot;); return &quot;end&quot;; &#125; lock = template.opsForValue().setIfAbsent(LOCK_KEY, randId, 10, TimeUnit.SECONDS); if (lock != null &amp;&amp; !lock) &#123; // 加锁失败 if (count-- &lt;= 0) return &quot;网络繁忙,请稍后再试&quot;; Thread.sleep(20); &#125;&#125; 同样采用上面的配置进行压测就可以看到200*4个请求的利用率大幅提高 1234567898080 剩余数量： 998080 剩余数量： 95# 省略部分输出...8080 剩余数量： 38080 剩余数量： 2卖完了！！！卖完了！！！# ....# 8080端口共处理202个请求 12345678910118081 剩余数量： 988081 剩余数量： 97# 省略部分输出...8081 剩余数量： 58081 剩余数量： 18081 剩余数量： 0卖完了！！！卖完了！！！卖完了！！！# ...# 8081端口共处理212个请求 可根据实际情况具体调节自旋间隔时间和自旋次数 在并发高库存量少的情况下不需要使用自旋，通常不会出现少买的情况 并发低库存量大的情况下可以取消自旋次数 redisson分布式锁的使用什么是redisson 摘自redis官网介绍： Redis提供一种更规范的算法来实现Redis的分布式锁，提出了一种称为Redlock的算法，该算法实现了DLM( 分布式锁管理器)，我们认为它比普通的单实例方法更安全。 而Redisson是基于Redlock算法的Java语言实现 Redlock算法官方介绍 In the distributed version of the algorithm we assume we have N Redis masters. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Redis masters on different computers or virtual machines in order to ensure that they’ll fail in a mostly independent way. In order to acquire the lock, the client performs the following operations: It gets the current time in milliseconds. It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3. If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock). 在算法的分布式版本中，我们假设我们有N个Redis主节点。这些节点是完全独立的，因此我们不使用复制或任何其他隐式协调系统。我们已经描述了如何在单个实例中安全地获取和释放锁。我们认为该算法将使用此方法在单个实例中获取和释放锁，这是理所当然的。在我们的示例中，我们将N = 5设置为一个合理的值，因此我们需要在不同的计算机或虚拟机上运行5个Redis主服务器，以确保它们将以大多数独立的方式发生故障。 为了获取锁，客户端执行以下操作： 它以毫秒为单位获取当前时间。 它尝试在所有N个实例中顺序使用所有实例中相同的键名和随机值来获取锁定。在第2步中，在每个实例中设置锁定时，客户端使用的超时时间小于总锁定自动释放时间，以便获取该超时时间。例如，如果自动释放时间为10秒，则超时时间可能在5到50毫秒之间。这样可以防止客户端长时间与处于故障状态的Redis节点进行通信：如果某个实例不可用，我们应该尝试与下一个实例尽快进行通信。 客户端通过从当前时间中减去在步骤1中获得的时间戳，来计算获取锁所花费的时间。当且仅当客户端能够在大多数实例（至少3个）中获取锁时， ，并且获取锁所花费的总时间小于锁有效时间，则认为已获取锁。 如果获取了锁，则将其有效时间视为初始有效时间减去经过的时间，如步骤3中所计算。 如果客户端由于某种原因（无法锁定N / 2 + 1个实例或有效时间为负）而未能获得该锁，它将尝试解锁所有实例（即使它认为不是该实例）能够锁定）。 后面会单独撕Redisson源码，这里的Redlock算法很重要，理解这块可以帮助理解Redisson源码 Redisson使用redisson的github上有较为详细的使用方式 导入maven 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt;&lt;/dependency&gt; 使用 123456789101112131415161718192021222324252627282930@Beanpublic Redisson redisson()&#123; Config config = new Config(); config.useSingleServer() .setAddress(&quot;redis://192.168.5.129:6379&quot;) .setPassword(&quot;password&quot;) .setDatabase(0); return (Redisson) Redisson.create(config);&#125;// -------------------------------@Resourceprivate Redisson redisson;public String redisson() &#123; RLock rLock = redisson.getLock(LOCK_KEY); boolean locked = false; try &#123; if (locked = rLock.tryLock(5, TimeUnit.SECONDS)) &#123; // do something return &quot;success&quot;; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if (locked) &#123; rLock.unlock(); &#125; &#125; return &quot;网络繁忙,稍后再试&quot;;&#125; 总结Redisson分布式锁的整体思路及问题 当客户端访问带redisson时，redisson先去尝试加锁，如果加锁不成功就自旋，如果加锁成功就会开启一个后台线程，每隔10秒检测该线程是否还持有锁，如果还持久就要对锁进行续期。 但由于Redis是有个弱一致性架构，master会先返回结果，再进行同步(官网中称异步)。当master结点获得锁后宕机，此时从结点替代主节点，然而从节点中未能及时同步master的锁信息，而导致锁条件被破坏。然而官方提供了一个最终一致性的解决方案(尚未实现)，具体内容可以参照博文——Redis学习之路(四)——Redis持久化理念 摘自 https://redis.io/topics/distlock (Why failover-based implementations are not enough) The simplest way to use Redis to lock a resource is to create a key in an instance. The key is usually created with a limited time to live, using the Redis expires feature, so that eventually it will get released (property 2 in our list). When the client needs to release the resource, it deletes the key. 使用Redis锁定资源的最简单方法是在实例中创建密钥。使用Redis过期功能，通常会在有限的生存时间内创建密钥，以便最终将其释放（我们列表中的属性2）。当客户端需要释放资源时，它将删除密钥。 Superficially this works well, but there is a problem: this is a single point of failure in our architecture. What happens if the Redis master goes down? Well, let’s add a slave! And use it if the master is unavailable. This is unfortunately not viable. By doing so we can’t implement our safety property of mutual exclusion, because Redis replication is asynchronous. 从表面上看，这很好，但是存在一个问题：这是我们架构中的单点故障。如果Redis主服务器宕机了怎么办？好吧，让我们添加一个奴隶！如果主服务器不可用，请使用它。不幸的是，这是不可行的。这样，我们就无法实现互斥的安全属性，因为Redis复制是异步的。 There is an obvious race condition with this model: Client A acquires the lock in the master. The master crashes before the write to the key is transmitted to the slave. The slave gets promoted to master. Client B acquires the lock to the same resource A already holds a lock for. SAFETY VIOLATION! 此模型有一个明显的竞争条件： 客户端A获取主服务器中的锁。 在将密钥写入传输到从机之前，主机崩溃。 奴隶晋升为主人。 客户端B获取对相同资源A的锁定，而该资源A已经为其持有了锁定。安全违规！ Sometimes it is perfectly fine that under special circumstances, like during a failure, multiple clients can hold the lock at the same time. If this is the case, you can use your replication based solution. Otherwise we suggest to implement the solution described in this document. 有时候，在特殊情况下（例如在故障期间），多个客户端可以同时持有锁是完全可以的。在这种情况下，您可以使用基于复制的解决方案。 由于暂时没有Redis的最终一致性的实现，所以如果必须解决整个问题建议采用zookeeper 如何提高Redis分布式锁的性能 Redis本身是内存数据库，而且采用多路复用的IO模型，一般来说性能瓶颈不会出现在Redis端 减小锁粒度。尽可能的减少锁持有的时间 lua脚本。尽可能采用一次服务通信","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"},{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第78/90题: 子集","slug":"LeetCode-第78-90题-子集","date":"2020-05-28T22:57:53.000Z","updated":"2021-02-18T14:29:30.434Z","comments":true,"path":"2020/05/29/LeetCode-第78-90题-子集/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/29/LeetCode-%E7%AC%AC78-90%E9%A2%98-%E5%AD%90%E9%9B%86/","excerpt":"给定一组元素的整数数组 nums，返回该数组所有可能的子集（幂集）。","text":"78/90: 子集第78题: 给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 说明：解集不能包含重复的子集。 示例： 123456789101112输入: nums = [1,2,3]输出:[ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], []] 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/subsets著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 第90题： 给定一个可能包含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 说明：解集不能包含重复的子集。 示例： 12345678910输入: [1,2,2]输出:[ [2], [1], [1,2,2], [2,2], [1,2], []] 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/subsets-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析可以发现两个题目的区别就在于原数组中是否含有重复元素。这里提供两种解题思路： 迭代法一个数组的子集可以拆分为当个元素的子集，例如初始为1，子集为空集和1，当添加一个2时，只需要将1的子集中添加2即可。力扣官方的图和自画图： 复杂度分析 时间复杂度：O(N×2N)，生成所有子集，并复制到输出结果中。 空间复杂度：O(N×2N)，这是子集的数量。 对于给定的任意元素，它在子集中有两种情况，存在或者不存在（对应二进制中的 0 和 1）。因此，N 个数字共有 2N个子集。 字典排序（二进制排序）子集将每个子集映射到长度为 n 的位掩码中，其中第 i 位掩码 nums[i] 为 1，表示第 i 个元素在子集中；如果第 i 位掩码 nums[i] 为 0，表示第 i 个元素不在子集中。力扣官方的图和自画图： 代码实现迭代法(含重复)1234567891011121314public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); res.add(new ArrayList&lt;&gt;()); for (int num : nums) &#123; int size = res.size(); for (int j = 0; j &lt; size; j++) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(res.get(j)); list.add(num); res.add(list); &#125; &#125; return res;&#125; 字典排序（二进制排序）子集（不含重复）12345678910111213141516public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; Arrays.sort(nums); Set&lt;List&lt;Integer&gt;&gt; res = new LinkedHashSet&lt;&gt;(); int len = nums.length; for (int i = 0; i &lt; (1&lt;&lt;len); i++) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; len; j++) &#123; if ( ((i&gt;&gt;j) &amp; 1) == 1) list.add(nums[j]); &#125; res.add(list); &#125; return new ArrayList&lt;&gt;(res);&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第394题: 字符串解码","slug":"LeetCode-第394题-字符串解码","date":"2020-05-27T22:07:31.000Z","updated":"2021-02-18T14:21:16.311Z","comments":true,"path":"2020/05/28/LeetCode-第394题-字符串解码/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/28/LeetCode-%E7%AC%AC394%E9%A2%98-%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%A7%A3%E7%A0%81/","excerpt":"给定一个经过编码的字符串，返回它解码后的字符串。","text":"394. 字符串解码给定一个经过编码的字符串，返回它解码后的字符串。 编码规则为: k[encoded_string]，表示其中方括号内部的encoded_string 正好重复 k 次。注意 k 保证为正整数。 你可以认为输入字符串总是有效的；输入字符串中没有额外的空格，且输入的方括号总是符合格式要求的。 此外，你可以认为原始数据不包含数字，所有的数字只表示重复的次数 k ，例如不会出现像 3a 或 2[4] 的输入。 示例:s = “3[a]2[bc]”, 返回 “aaabcbc”.s = “3[a2[c]]”, 返回 “accaccacc”.s = “2[abc]3[cd]ef”, 返回 “abcabccdcdcdef”. 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/decode-string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析根据题目模式匹配，应该有两种思路，一种通过栈，一种通过递归的方式。 下面只介绍栈的实现: 栈 本题中可能出现括号嵌套的情况，比如 2[a2[bc]]，这种情况下我们可以先转化成 2[abcbc]，在转化成 abcbcabcbc ，以下是具体做法。 如果当前的字符为数位，解析出一个数字（连续的多个数位）并进栈 如果当前的字符为左括号，直接进栈 如果当前的字符为右括号，开始出栈，此时取出栈顶的数字，就是这个字符串应该出现的次数，我们根据这个次数和字符串构造出新的字符串并进栈 代码实现1234567891011121314151617181920212223242526public String decodeString(String s)&#123; StringBuilder res = new StringBuilder(); int multi = 0; Stack&lt;Integer&gt; s_num = new Stack&lt;&gt;(); Stack&lt;String&gt; s_str = new Stack&lt;&gt;(); for (char ch : s.toCharArray()) &#123; if (ch == &#x27;[&#x27;) &#123; s_num.push(multi); s_str.push(res.toString()); multi = 0; res = new StringBuilder(); &#125; else if (ch == &#x27;]&#x27;) &#123; StringBuilder tmp = new StringBuilder(); int cur_multi = s_num.pop(); tmp.append(String.valueOf(res).repeat(Math.max(0, cur_multi))); res = new StringBuilder(s_str.pop() + tmp); &#125; else if ( Character.isDigit(ch) ) &#123; multi = multi*10 + Integer.parseInt(ch+&quot;&quot;); &#125; else &#123; res.append(ch); &#125; &#125; return res.toString();&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"撕它——ThreadLocal！干就完了","slug":"撕它——ThreadLocal！干就完了","date":"2020-05-27T07:03:12.000Z","updated":"2021-02-18T14:20:25.064Z","comments":true,"path":"2020/05/27/撕它——ThreadLocal！干就完了/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/27/%E6%92%95%E5%AE%83%E2%80%94%E2%80%94ThreadLocal%EF%BC%81%E5%B9%B2%E5%B0%B1%E5%AE%8C%E4%BA%86/","excerpt":"从ThreadLocal的简介讲到用法，再到原理，每一行源代码分析，再到内存泄漏的问题分析","text":"ThreadLocal开篇什么是threadLocal下面是jdk1.8(jdk1.8_131)中的注释介绍: 123456789101112131415161718192021222324252627282930313233343536373839404142/** * This class provides thread-local variables. These variables differ from * their normal counterparts in that each thread that accesses one (via its * &#123;@code get&#125; or &#123;@code set&#125; method) has its own, independently initialized * copy of the variable. &#123;@code ThreadLocal&#125; instances are typically private * static fields in classes that wish to associate state with a thread (e.g., * a user ID or Transaction ID). * * &lt;p&gt;For example, the class below generates unique identifiers local to each * thread. * A thread&#x27;s id is assigned the first time it invokes &#123;@code ThreadId.get()&#125; * and remains unchanged on subsequent calls. * &lt;pre&gt; * import java.util.concurrent.atomic.AtomicInteger; * * public class ThreadId &#123; * // Atomic integer containing the next thread ID to be assigned * private static final AtomicInteger nextId = new AtomicInteger(0); * * // Thread local variable containing each thread&#x27;s ID * private static final ThreadLocal&amp;lt;Integer&amp;gt; threadId = * new ThreadLocal&amp;lt;Integer&amp;gt;() &#123; * &amp;#64;Override protected Integer initialValue() &#123; * return nextId.getAndIncrement(); * &#125; * &#125;; * * // Returns the current thread&#x27;s unique ID, assigning it if necessary * public static int get() &#123; * return threadId.get(); * &#125; * &#125; * &lt;/pre&gt; * &lt;p&gt;Each thread holds an implicit reference to its copy of a thread-local * variable as long as the thread is alive and the &#123;@code ThreadLocal&#125; * instance is accessible; after a thread goes away, all of its copies of * thread-local instances are subject to garbage collection (unless other * references to these copies exist). * * @author Josh Bloch and Doug Lea * @since 1.2 */ 翻译一下: 此类提供线程局部变量。 这些变量与普通变量不同，因为每个访问一个线程（通过其get或set方法）的线程都有其自己的，独立初始化的变量副本。 ThreadLocal实例通常是类中的私有静态字段，其状态和线程相关联（例如，用户ID或交易ID）。只要线程是活动的并且ThreadLocal实例是可访问的，则每个线程都对其线程局部变量的副本持有隐式引用。 线程消失后，其线程本地实例的所有副本都将进行垃圾回收（除非存在对这些副本的其他引用） 根据第一段进行一段小程序解释一下: 起一个线程在ThreadLocal中设置一个值，然后在另一个线程中去获取ThrealLocal中的值。 123456789101112131415161718private static void t1() throws InterruptedException &#123; ThreadLocal&lt;String&gt; tl = new ThreadLocal&lt;&gt;(); new Thread(()-&gt; &#123; tl.set(&quot;123&quot;); System.out.println(&quot;set: &quot; + tl.get()); &#125;).start(); Thread.sleep(2000); // 等待设置线程结束 new Thread(()-&gt; System.out.println(&quot;get: &quot; + tl.get())).start(); Thread.sleep(2000); // 等待获取线程结束&#125;/**set: 123get: null*/ 可以发现，第二个线程无法获取第一个线程中的值，实现了线程的数据隔离 有什么用 减少同一个线程内多个函数或组件之间一些公共变量的传值。 例如spring中transactional注解的实现。当我们需要控制事务时，需要将数据库连接从service层传递到dao层进行处理。那么我就需要在获取连接时，将数据库连接放在ThreadLocal中，那么在dao层获取连接时，保证了为同一个连接。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class DBUtil &#123; //数据库连接池 private static BasicDataSource source; //为不同的线程管理连接 private static ThreadLocal&lt;Connection&gt; local; static &#123; try &#123; // 数据库连接池初始化工作 // ... //初始化线程本地 local = new ThreadLocal&lt;&gt;(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static Connection getConnection() throws SQLException &#123; if(local.get()!=null)&#123; // 直接返回线程本地的connection return local.get(); &#125;else&#123; //获取Connection对象 Connection connection = source.getConnection(); //把Connection放进ThreadLocal里面 local.set(connection); //返回Connection对象 return connection; &#125; &#125; //关闭数据库连接 public static void closeConnection() &#123; //从线程中拿到Connection对象 Connection connection = local.get(); try &#123; if (connection != null) &#123; //恢复连接为自动提交 connection.setAutoCommit(true); //这里不是真的把连接关了,只是将该连接归还给连接池 connection.close(); //既然连接已经归还给连接池了,ThreadLocal保存的Connction对象也已经没用了 local.remove(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; ThreadLocal实现原理查看整个ThreadLocal的结构图 根据ThreadLocal的使用来剖析 1. 创建一个ThreadLocal当我们创建一个ThreadLocal时，为一个空构造方法什么都做 12public ThreadLocal() &#123;&#125; 2. 向ThreadLocal中set一个值当调用一个set时，首先获取到当前线程。然后从当前线程中获取了一个ThreadLocalMap对象。如果存在map，就set(this, value)，不存在就create一个Map 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); // 获取当前线程 ThreadLocalMap map = getMap(t); // 通过当前线程获取ThreadLocalMap对象 if (map != null) map.set(this, value); // 存在map就set值 else createMap(t, value); // 不存在map就create一个map&#125; 重点: map中的key为this，也就是说key为ThreadLocal 根据流程查看getMap方法，直接返回线程类的一个成员变量threadLocals。 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 重点: threadLocals为每个线程的成员变量，也就是说每个线程独有一份 然后回到流程查看set方法。首先就是三个临时变量 tab(线程中ThreadLocals)，len(ThreadLocals的长度)，i(下标)；然后一个for循环，这个for循环实际上是哈希表中的线性搜索法；将下标为i位置的entry取出来，只要不为null，就将其赋值给临时变量k，如果说key相等就把ThreadLocal中的value替换掉；如果k为空(说明ThreadLocal的强引用被回收，后面有图解释)，就把下标为i位置上的entry替换为新的值；for循环退出，表示找到了一个空位，插入新值；如果没有清理掉陈旧的槽位并且entry的数量超过阈值就rehash。 线性搜索法: 当通过一个下标(i)获取到一个值时，如果发生了哈希冲突，就将这个下标向后挪动一位，如果超过了数组长度就从0开始，类似于环状，直到找到一个空位可以插入。 1234567891011121314151617181920212223242526272829private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at least as common to use set() to create new entries as it is to replace existing ones, in which case, a fast path would fail more often than not. // 我们不像get()那样使用快速路径，因为使用set()创建新entry和替换现有entry一样普遍，在这种情况下，快速路径失败的可能性会更大 Entry[] tab = table; // 线程中的ThreadLocals int len = tab.length; // 线程中的ThreadLocal的个数 int i = key.threadLocalHashCode &amp; (len-1); // 类似于 hash%(len-1)，hash表的取余定位法 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 线性搜索法 ThreadLocal&lt;?&gt; k = e.get(); // 赋值给临时变量 if (k == key) &#123; // 存在key就替换value e.value = value; return; &#125; if (k == null) &#123; // ThreadLocal的强引用被回收 replaceStaleEntry(key, value, i); // 将此位置上的entry替换为新的entry return; &#125; &#125; // 找到空位 tab[i] = new Entry(key, value); int sz = ++size; // entry的数量加1 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) // 如果没有清理槽位并且entry的数量超过阈值就进行rehash rehash();&#125; 通过查看nextIndex方法，可以知道for循环为线性搜索法，如果小于len就向后搜索，如果超过就从0开始。 123private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125; 再去查看replaceStaleEntry(替换陈旧的entry)方法。首先四个临时变量tab(ThreadLocals)、len(ThreadLocal的长度)、e(临时变量entry)、slotToExpunge(清除槽位的下标); jdk注释: 123456789101112131415/*** Replace a stale entry encountered during a set operation* with an entry for the specified key. The value passed in* the value parameter is stored in the entry, whether or not* an entry already exists for the specified key.** As a side effect, this method expunges all stale entries in the* &quot;run&quot; containing the stale entry. (A run is a sequence of entries* between two null slots.)** @param key the key* @param value the value to be associated with key* @param staleSlot index of the first stale entry encountered while searching for key.*/ 将设置操作期间遇到的陈旧entry替换为指定键的entry。 无论是否已存在指定键的entry，在value参数中传递的值都存储在entry中。 副作用是，此方法删除了包含过时条目的“运行”中的所有过时条目。 （运行是两个空槽之间的一系列输入） 由于哈希表采用线性搜索的方式，所以每次只处理两个空槽之间的连续空间 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** replaceStaleEntry(key, value, i)*/private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run.We clean out whole runs at a time to avoid continual incremental rehashing due to garbage collector freeing up refs in bunches (i.e., whenever the collector runs). // 备份以检查当前运行中是否有过时的entry。我们一次清理整个运行，以避免由于垃圾收集器释放成堆的引用（即每当收集器运行时）而导致的连续增量重新哈希。 int slotToExpunge = staleSlot; // 初始化为需要替换的下标 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) // 从需要替换的下标向前(左)线性搜索 if (e.get() == null) slotToExpunge = i; // entry不为null，key为null，将下标赋值 // Find either the key or trailing null slot of run, whichever occurs first // 查找运行的键或尾随空槽，以先到者为准 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; // 从需要替换的下标向后线性搜索 ThreadLocal&lt;?&gt; k = e.get(); // If we find key, then we need to swap it with the stale entry to maintain hash table order. The newly stale slot, or any other stale slot encountered above it, can then be sent to expungeStaleEntry to remove or rehash all of the other entries in run. // 如果找到key，则需要将其与旧entry交换以维护哈希表的顺序。然后可以将新的旧插槽或其上方遇到的任何其他旧插槽调用expungeStaleEntry，以删除或重新哈希运行中的所有其他entry if (k == key) &#123; // 交换entry e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // Start expunge at preceding stale entry if it exists // 如果先前的陈旧entry存在就开始清除 if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);// 先清理entry再清理槽位 return; &#125; // If we didn&#x27;t find stale entry on backward scan, the first stale entry seen while scanning for key is the first still present in the run. // 如果在向后扫描中未找到过时的entry，则在扫描key时看到的第一个过时的entry仍然是运行中的第一个过时的entry。 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // If key not found, put new entry in stale slot // 如果找不到key，则将新条目放入陈旧的插槽中 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them // 如果有其他过时的entry正在运行，请将它们清除 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 下方给出一个示例图，可通过假设方式弄清程序 查看expungeStaleEntry(清理旧槽)方法；在这里可以看到清理槽位的方式，先将value赋值为null，再将下标所在的entry赋值为null；再重新rehash两个空槽之间的位置 12345678910111213141516171819202122232425262728293031323334353637private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot // 清理槽位 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null // 重新hash，知道遇到下一个null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; // 线性搜索 ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; // 清理槽位 e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); // 重新hash if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until null because multiple entries could have been stale. // 与Knuth 6.4算法R不同，我们必须扫描到null为止，因为可能已经过时了多个entry。 while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 解释一下rehash的实现 由于开始通过hash计算出的下标存在冲突，就将冲突的entry向后放。由于最开始占位的entry被清除掉，所以如果后面的值hash出来和被清理掉的entry的hash一样，就将后面的值放在被清理的位置上，后面紧接着的同理 再去查看cleanSomeSlots方法；这个方法中只要找到有可清理的对象，就会触发清除。并且扫描的次数为log2n次 官方注释: 12345678&gt;/**&gt;* Heuristically scan some cells looking for stale entries. This is invoked when either a new element is added, or another stale one has been expunged. It performs a logarithmic number of scans, as a balance between no scanning (fast but retains garbage) and a number of scans proportional to number of elements, that would find all garbage but would cause some insertions to take O(n) time.&gt;*&gt;* @param i a position known NOT to hold a stale entry. The scan starts at the element after i.&gt;* @param n scan control: &#123;@code log2(n)&#125; cells are scanned, unless a stale entry is found, in which case &#123;@code log2(table.length)-1&#125; additional cells are scanned. When called from insertions, this parameter is the number of elements, but when from replaceStaleEntry, it is the table length. (Note: all this could be changed to be either more or less aggressive by weighting n instead of just using straight log n. But this version is simple, fast, and seems to work well.)&gt;* @return true if any stale entries have been removed.&gt;*/ 启发式扫描某些单元以查找陈旧条目。 当添加了新元素或已删除另一旧元素时，将调用此方法。 它执行对数扫描，作为无扫描（快速但保留垃圾）和与元素数量成比例的扫描数量之间的平衡，这会发现所有垃圾，但会导致某些插入花费O（n）时间。 123456789101112131415private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); // 触发清理(清理两个空槽之间的连续空间) &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); // logn次扫描 return removed;&#125; 查看rehash方法；首先清理空槽，然后判断如果说entry的数量超过了threshold的四分之三，就重新调整大小。例如初始threshold为10，size大于等于8，就要resize 12345678private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis // 使用较低的阈值加倍以避免滞后 if (size &gt;= threshold - threshold / 4) resize();&#125; 通过查看expungeStaleEntries方法可以知道，这个方法会触发整个entry的扫描。 123456789private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) // 获取到需要清除的对象 expungeStaleEntry(j); &#125;&#125; 查看resize方法；ThreadLocalMap的扩容为两倍oldsize； 123456789101112131415161718192021222324252627private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; // 判断是否清理 e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); // 与expungeStaleEntry方法中的rehash相似 while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 至此，所有的map.set方法相关联的代码全部拉通，可以发现整个set过程不断的进行判断entry不为空，key为空的现象，这是为了避免内存泄漏，下方会解释 在set中还有一种情况为map为null的情况，即第一次set的时候触发。查看createMap方法调用了ThreadLocalMap的构造方法。 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 跟踪ThreadLocalMap构造方法。初始化table为entry数组，初始长度为16；第一次set不存在冲突就直接插入；再调用setThreshold方法设置了阈值。 1234567ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; // INITIAL_CAPACITY = 16 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125; 跟踪setThreshold方法；可以发现阈值为长度的三分之二，按照初始值16来算为10。(这阈值不是真正的阈值，在调用resize之前可以看到，真正的阈值为threshold的四分之三) 123private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; 至此，整个ThrealLocal的set方法全部跟踪完毕。 3. 从ThreadLocal中get值跟踪ThreadLocal.get方法可以看到通过getEntry方法直接获取ThreadLocal的值；如果为空就返回一个初始值； 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 跟踪map.getEntry方法，如果找到了就直接返回，没有就调用了getEntryAfterMiss方法 jdk注释： 1234567891011/*** Get the entry associated with key. This method* itself handles only the fast path: a direct hit of existing* key. It otherwise relays to getEntryAfterMiss. This is* designed to maximize performance for direct hits, in part* by making this method readily inlinable.** @param key the thread local object* @return the entry associated with key, or null if no such*/ 获取与键关联的条目。该方法本身仅处理快速路径：直接命中现有密钥。否则，它将中继到getEntryAfterMiss。这样做的目的是最大程度地提高直接打击的性能，部分原因是使此方法易于操作。 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) // 如果存在hash冲突的情况下，需要向后找 return e; else return getEntryAfterMiss(key, i, e);&#125; 跟踪getEntryAfterMiss方法可以知道；根据当前下标，向后遍历，找到就返回，key为null就触发删除，不然就找下一个；(线性搜索法) 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) // 返回值 return e; if (k == null) // 清理entry expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; 最后查看初始化setInitialValue方法；首先调用initialValue方法获取value值，再将该值写入到ThreadLocalMap；最后再返回value值。 12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 在initialValue方法中可以看到默认的初始值为null；但是修饰词是protected，意味着该方法可以被重写。 123protected T initialValue() &#123; return null;&#125; 至此get方法跟踪完成 4. 将ThreadLocal中的值删除掉删除方法对应着remove方法中；就直接调用了ThreadLocalMap的remove方法； 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 在ThreadLocalMap的remove方法中；同样是通过线性搜索法进行查找key，找到就调用clear方法，然后再删除空闲的entry。 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; clear方法调用了Reference类中的clear方法，直接置为null 123public void clear() &#123; this.referent = null;&#125; ThreadLocalMap的hash方法ThreadLocalMap的nextHashCode方法通过调用原子类的getAndAdd方法 12345678910private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; jdk注释: 12345/*** The difference between successively generated hash codes - turns* implicit sequential thread-local IDs into near-optimally spread* multiplicative hash values for power-of-two-sized tables.*/ 连续生成的哈希码之间的差异-将隐式顺序线程本地ID转换为用于2的幂次方表的近似最佳分布的乘法哈希值。 Entry虚引用在ThreadLocal中定义了一个静态内部类Entry继承虚引用 12345678910static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; jdk注释: 123456789/*** The entries in this hash map extend WeakReference, using* its main ref field as the key (which is always a* ThreadLocal object). Note that null keys (i.e. entry.get()* == null) mean that the key is no longer referenced, so the* entry can be expunged from table. Such entries are referred to* as &quot;stale entries&quot; in the code that follows.*/ 此哈希映射中的entry使用其主要引用字段作为键（始终是ThreadLocal对象）扩展WeakReference。 请注意，空键（即entry.get（）== null）意味着不再引用该键，因此可以从表中删除该entry。 在下面的代码中，此类条目称为“stale entries”。 问题总结为什么Entry是虚引用通过分析源代码可以画出部分结构图 当 ThreadLocal tl = new ThreadLocal() 这条强引用被显式置为null或者退出栈帧时，会被GC回收。当发生GC过后，由于key指向ThreadLocal对象，key值会被置为null，但是value无法被回收。所以在代码中(在get和set时)有很多的 e!=null &amp;&amp; key==null 的判断，原因就是防止内存泄漏，然而只有在entry==null时才会被回收。 判断后还会发生内存泄漏吗答案是会的，每个线程中都有一个直接指向Entry数组的强引用，也就是说只要Thread不被回收，这块内存就不会被释放。但是在线程池中不同，线程用完不会被回收，而是回到线程池中继续等待。所以在使用完ThreadLocal后显式调用remove方法，清除该ThreadLocal的内存。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第974题: 和可被 K 整除的子数组","slug":"LeetCode-第974题-和可被-K-整除的子数组","date":"2020-05-26T21:19:02.000Z","updated":"2021-02-18T14:19:31.514Z","comments":true,"path":"2020/05/27/LeetCode-第974题-和可被-K-整除的子数组/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/27/LeetCode-%E7%AC%AC974%E9%A2%98-%E5%92%8C%E5%8F%AF%E8%A2%AB-K-%E6%95%B4%E9%99%A4%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84/","excerpt":"给定一个整数数组 A，返回其中元素之和可被 K 整除的（连续、非空）子数组的数目。","text":"974. 和可被 K 整除的子数组给定一个整数数组 A，返回其中元素之和可被 K 整除的（连续、非空）子数组的数目。 示例：输入：A = [4,5,0,-2,-3,1], K = 5输出：7 解释：有 7 个子数组满足其元素之和可被 K = 5 整除：[4, 5, 0, -2, -3, 1], [5], [5, 0], [5, 0, -2, -3], [0], [0, -2, -3], [-2, -3] 提示： 1 &lt;= A.length &lt;= 30000 -10000 &lt;= A[i] &lt;= 10000 2 &lt;= K &lt;= 10000 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/subarray-sums-divisible-by-k著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析找出连续的子数组 前缀和 ==&gt; 时间复杂度为O(n2)，空间复杂度为O(1) ==&gt; 超时 pass掉 哈希表 ==&gt; 时间复杂度O(n)， 空间复杂度O(min(n,k)) 问题: 如何建立哈希表 我们令 P[i] = A[0] + A[1] + … + A[i]。那么每个连续子数组的和 sum(i,j) 就可以写成 P[j] - P[i-1]（其中 0 &lt; i &lt; j）的形式。此时，判断子数组的和能否被 K 整除就等价于判断 (P[j] - P[i-1]) mod K == 0，根据 同余定理，只要P[j] mod K == P[i−1 ]mod K，就可以保证上面的等式成立。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/subarray-sums-divisible-by-k/solution/he-ke-bei-k-zheng-chu-de-zi-shu-zu-by-leetcode-sol/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 所以我们将数组前缀和进行取模作为Key，出现次数作为Value 举一个具体的例子，给定数组为 A = [4,5,0,-2,-3,1]以及 K = 5，那么前缀和 P = [4,9,9,7,4,5]，对 K 取模即[4,4,4,2,4,0]，那么可以哈希表中包含的键值对为(0,2),(2,1),(4,4)：以(4,4) 为例： 对于 c4 = 4，对应的前缀和为 P[0], P[1], P[2], P[4]，那么一共有 6 个和能被 K 整除的连续子数组，分别是A[1:1] , A[1:2] , A[1:4] , A[2:2] , A[2:4] , A[4:4]，其中 A[i:j] 表示下标从 i 到 j 的子数组。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041/** * 哈希表 * 时间复杂度O(n) 空间复杂度O(n) */public int subarraysDivByK(int[] A, int K) &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); int sum = 0; for (int elem : A) &#123; sum += elem; int tmp = Math.floorMod(sum, K); map.put(tmp, map.getOrDefault(tmp, 0) + 1); &#125; int cnt = 0; for (Integer val : map.values()) &#123; cnt += val*(val - 1) &gt;&gt; 1; &#125; return cnt;&#125; /** * 前缀和数组 --&gt; 超时 * 时间复杂度O(n^2) 空间复杂度O(1) */// public int subarraysDivByK(int[] A, int K) &#123;// int len = A.length;//// int cnt = 0;// for (int i = 0; i &lt; len; i++) &#123;// int tmp = A[i];// if (tmp % K == 0) cnt++;// for (int j = i + 1; j &lt; len; j++) &#123;// tmp = tmp + A[j];// if (tmp % K == 0) cnt++;// &#125;// &#125;// return cnt;// &#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"Java四种引用类型","slug":"Java四种引用类型","date":"2020-05-26T07:14:05.000Z","updated":"2021-02-18T14:18:44.238Z","comments":true,"path":"2020/05/26/Java四种引用类型/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/26/Java%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/","excerpt":"java的四种引用类型:强引用、软引用、弱引用、虚引用","text":"四种引用类型1. 强引用(StrongReference)Object o = new Object(); 当引用不存在时，对象才能被回收掉，即使OOM也不会回收掉。 但是当显式的设置对象为null，或让其超出对象的生命周期范围，则GC任务该对象不存在引用，这时就回收这个对象。具体什么时候取决于GC算法。 12345678910111213public static void t1() throws IOException &#123; T t = new T(); t = null; Runtime.getRuntime().gc(); System.in.read();&#125;class T&#123; @Override protected void finalize() throws Throwable &#123; System.out.println(&quot;啊~~~我死掉了！！&quot;); &#125;&#125; Q：要是不写System.in.read()，会怎样 A: 当main线程执行结束后，JVM也会停止，JVM中的GC线程来不及执行就被关闭了。 Q：(C++自己释放内存) 重写finalized方法，导致频繁FGC，OOM A: 把耗时操作放在finalized内，会导致回收时间变长，导致对象生命周期变长 当方法的内部有一个强引用，这个引用保存在Java栈中，而引用内容保存在Java堆中，当这个方法运行结束后，就会退出方法栈，而引用对象的引用数为0，这个对象会被回收。 如果这个强引用是个全局变量，就需要在不用这个对象时赋值为null。 123456789// （jdk1.8_131）ArrayList.java 553行public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0;&#125; 2. 软引用(SoftReference)内存布局 当一个对象具有软引用时，如果有足够的内存空间，垃圾回收器就不会回收它；如果内存不足，就会被回收掉 12345678public static void t2_1()&#123; SoftReference&lt;Byte[]&gt; sr = new SoftReference&lt;&gt;(new Byte[1024 * 1024 * 10]);// 10M System.out.println(sr.get()); Runtime.getRuntime().gc(); System.out.println(sr.get()); Byte[] bytes = new Byte[1024 * 1024 * 15]; // 15M System.out.println(sr.get());&#125; 当我们添加 -Xmx20m 参数时 ==&gt; 最大堆内存为20M，当分配一个10M的软引用对象时，堆内还够放，当再次分配15M内存时，堆内不够放，就会GC掉软引用对象 | 20M | ==&gt; | 10M | 10M | ==&gt; | 15M | 5M | 输出:[Ljava.lang.Byte;@1540e19d[Ljava.lang.Byte;@1540e19dnull 软引用可以和引用队列联合使用，如果软引用对象被回收，JVM就会把这个软引用加入到与之关联的引用队列中。 1234567891011121314151617public static void t2_2()&#123; ReferenceQueue queue = new ReferenceQueue(); SoftReference&lt;Byte[]&gt; sr = new SoftReference&lt;&gt;(new Byte[1024 * 1024 * 10], queue); System.out.println(sr.get()); Runtime.getRuntime().gc(); System.out.println(sr.get()); Byte[] bytes = new Byte[1024 * 1024 * 15]; System.out.println(sr.get()); Reference poll = queue.poll(); System.out.println(poll);&#125;/**[Ljava.lang.Byte;@1540e19d[Ljava.lang.Byte;@1540e19dnulljava.lang.ref.SoftReference@677327b6*/ 当内存不足时，JVM首先将软引用对象引用置为null，然后通知垃圾回收器回收 1234if (没存不足)&#123; object = null; System.gc();&#125; 也就是说，垃圾收集线程会在虚拟机抛出 OutOfMemoryError 之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对那些刚构建的或刚使用过的”较新的”软对象会被虚拟机尽可能保留，这就是引入引用队列 ReferenceQueue 的原因。 使用场景: 缓存(内存足够就在，内存不够就GC掉) 3. 弱引用(WeakReference)内存布局 弱引用比软引用拥有更短暂的生命周期，在GC线程中只要被扫描到就会被回收。 1234567891011public static void t3()&#123; WeakReference&lt;T&gt; wr = new WeakReference&lt;&gt;(new T()); System.out.println(wr.get()); Runtime.getRuntime().gc(); System.out.println(wr.get());&#125;/**com.marveal.T@1540e19dnull啊~~~我死掉了！！*/ 弱引用可以和一个引用队列联合使用，如果一个弱引用对象被垃圾回收器回收，JVM就会把这个弱引用对象加入到与之关联的引用队列中。(如果该对象存在强引用才加入引用队列，如果没有就直接回收) 1234567891011121314151617181920212223242526272829// 由于list强引用着弱引用对象，当发生GC时，就将其放入到引用队列中public static final ReferenceQueue&lt;T&gt; queue = new ReferenceQueue&lt;&gt;();public static void t3_2() throws InterruptedException &#123; List&lt;WeakReference&lt;T&gt;&gt; list = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; WeakReference&lt;T&gt; wr = new WeakReference&lt;&gt;(new T(), queue); System.out.println(&quot;弱引用对象&quot; + i + &quot;创建成功\\t&quot; + wr); list.add(wr); &#125; Runtime.getRuntime().gc(); Thread.sleep(2000); Reference&lt;? extends T&gt; reference; while ( (reference = queue.poll()) != null) &#123; System.out.println(&quot;弱引用对象&quot; + reference.get()); &#125;&#125;/**弱引用对象0创建成功 java.lang.ref.WeakReference@1540e19d弱引用对象1创建成功 java.lang.ref.WeakReference@677327b6弱引用对象2创建成功 java.lang.ref.WeakReference@14ae5a5啊~~~我死掉了！！啊~~~我死掉了！！啊~~~我死掉了！！弱引用对象null弱引用对象null弱引用对象null*/ 123456789101112131415161718192021222324// 对象只存在弱引用对象，直接被回收public static final ReferenceQueue&lt;T&gt; queue = new ReferenceQueue&lt;&gt;();public static void t3_2() throws InterruptedException &#123; for (int i = 0; i &lt; 3; i++) &#123; WeakReference&lt;T&gt; wr = new WeakReference&lt;&gt;(new T(), queue); System.out.println(&quot;弱引用对象&quot; + i + &quot;创建成功\\t&quot; + wr); &#125; Runtime.getRuntime().gc(); Thread.sleep(2000); Reference&lt;? extends T&gt; reference; while ( (reference = queue.poll()) != null) &#123; System.out.println(&quot;弱引用对象&quot; + reference.get()); &#125;&#125;/**弱引用对象0创建成功 java.lang.ref.WeakReference@1540e19d弱引用对象1创建成功 java.lang.ref.WeakReference@677327b6弱引用对象2创建成功 java.lang.ref.WeakReference@14ae5a5啊~~~我死掉了！！啊~~~我死掉了！！啊~~~我死掉了！！*/ 弱引用对象调用get()会直接变为强引用对象 1234567891011public static void t3_3() throws InterruptedException &#123; WeakReference&lt;String&gt; wr = new WeakReference&lt;&gt;(&quot;123&quot;); System.out.println(wr.get()); System.gc(); Thread.sleep(2000); System.out.println(wr.get());&#125;/**123123*/ 4. 虚引用(PhantomReference)虚引用用于直接管理内存。当获取操作系统内存得数据时，JVM会拷贝一份到自己内存，触发GC时，将当前的虚引用放入到引用队列中，然后清空操作系统的内存。(管理GC用，自己用不着) 虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 线程1不断往list中add，所以需要设置-Xmx200mpublic static final ReferenceQueue&lt;T&gt; queue = new ReferenceQueue&lt;&gt;();public static final List&lt;Byte[]&gt; list = new LinkedList&lt;&gt;();public static void t4() throws InterruptedException &#123; PhantomReference&lt;T&gt; pr = new PhantomReference&lt;&gt;(new T(), queue); System.out.println(pr.get()); // 无法获取 new Thread(()-&gt;&#123; while (true) &#123; try &#123; list.add(new Byte[1024 * 1024 * 5]); Thread.sleep(100); System.out.println(&quot;new对象了&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; while (true) &#123; Reference&lt;? extends T&gt; reference = queue.poll(); if (reference != null) &#123; System.out.println(&quot;对象被回收了\\t&quot;+ reference); &#125; &#125; &#125;).start(); Thread.sleep(1000);&#125;/**nullnew对象了new对象了啊~~~我死掉了！！new对象了new对象了对象被回收了 java.lang.ref.PhantomReference@665f7be8new对象了new对象了...*/ 虚引用并不会决定对象的生命周期。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。 如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 总结 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会/显式设置为null 对象的一般状态 JVM停止运行时终止/对象为null/引用计数为0 软引用 当内存不足时 对象缓存 内存不足时终止 弱引用 正常垃圾回收时 对象缓存/防止内存溢出 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止 下篇文章会讲到ThreadLocal中弱引用的使用 图表参考作者：零壹技术栈链接：https://juejin.im/post/5b82c02df265da436152f5ad来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第287题:寻找重复数","slug":"LeetCode-第287题-寻找重复数","date":"2020-05-25T21:35:49.000Z","updated":"2021-02-18T14:18:44.312Z","comments":true,"path":"2020/05/26/LeetCode-第287题-寻找重复数/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/26/LeetCode-%E7%AC%AC287%E9%A2%98-%E5%AF%BB%E6%89%BE%E9%87%8D%E5%A4%8D%E6%95%B0/","excerpt":"给定一个包含 n + 1 个整数的数组 nums，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。假设只有一个重复的整数，找出这个重复的数。","text":"287. 寻找重复数给定一个包含 n + 1 个整数的数组 nums，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。假设只有一个重复的整数，找出这个重复的数。 示例 1:输入: [1,3,4,2,2]输出: 2 示例 2:输入: [3,1,3,4,2]输出: 3 说明： 不能更改原数组（假设数组是只读的）。 只能使用额外的 O(1) 的空间。 时间复杂度小于 O(n2) 。 数组中只有一个重复的数字，但它可能不止重复出现一次。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/find-the-duplicate-number著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析寻找重复的数最简单的方式就是两层for循环，但是时间复杂度为O(n) ==&gt; pass掉 最快的查找O(1)时间复杂度为哈希表，但是只能使用O(1)的额外空间 ==&gt; pass掉 紧着的查找O(log n)时间复杂度的二分，分治。数组无序无法实现O(log n)的二分 ==&gt; pass掉; 分治: 判断最下一层只需要比较一次，比较倒数第三层需要比较2 2 次，比较第二层需要4 4 次 ==&gt; pass掉 查找O(n)时间复杂度的链式查找，如何实现 ==&gt; 快慢指针 我们先设置慢指针 slow 和快指针fast ，慢指针每次走一步，快指针每次走两步，根据「Floyd 判圈算法」两个指针在有环的情况下一定会相遇，此时我们再将slow 放置起点 0，两个指针每次同时移动一步，相遇的点就是答案。 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/find-the-duplicate-number/solution/xun-zhao-zhong-fu-shu-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 例如 {1,3,4,2,2,5} 代码实现123456789101112131415public int findDuplicate(int[] nums) &#123; int slow = 0, fast = 0; do &#123; slow = nums[slow]; fast = nums[nums[fast]]; &#125; while (slow != fast); slow = 0; while (slow != fast) &#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第146题: LRU缓存机制","slug":"LeetCode-第146题-LRU缓存机制","date":"2020-05-25T00:05:32.000Z","updated":"2021-02-18T14:16:52.342Z","comments":true,"path":"2020/05/25/LeetCode-第146题-LRU缓存机制/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/25/LeetCode-%E7%AC%AC146%E9%A2%98-LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/","excerpt":"运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。","text":"146. LRU缓存机制运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。 获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。写入数据 put(key, value) - 如果密钥已经存在，则变更其数据值；如果密钥不存在，则插入该组「密钥/数据值」。当缓存容量达到上限时，它应该在写入新数据之前删除最久未使用的数据值，从而为新的数据值留出空间。 进阶:你是否可以在 O(1) 时间复杂度内完成这两种操作？ 示例: 1234567891011LRUCache cache = new LRUCache( 2 /* 缓存容量 */ );cache.put(1, 1);cache.put(2, 2);cache.get(1); // 返回 1cache.put(3, 3); // 该操作会使得密钥 2 作废cache.get(2); // 返回 -1 (未找到)cache.put(4, 4); // 该操作会使得密钥 1 作废cache.get(1); // 返回 -1 (未找到)cache.get(3); // 返回 3cache.get(4); // 返回 4 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/lru-cache著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析O(1)的时间复杂度 =&gt; 哈希表 删除最近最久未使用的数据值 =&gt; 队列FIFO =&gt; 弊端: 当更新某个元素时需要将该元素挪到队尾，单个元素的操作只有链表操作最好 =&gt; 选择双向链表 到此，选型就是哈希表+双向链表 ( HashMap&lt;key, DLinkedNode&gt; ) 当put一个值时: 先判断是否含有该结点 有就修改该结点，并将该节点挪到尾结点前 没有就向hash表中记录一个双向链表的结点；向双向链表尾结点前添加一个结点 当get一个值时: 先判断是否含有该结点 没有直接返回-1 有就将该结点挪到尾结点前；返回value 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889class DLinkedNode&#123; public int key; public int value; DLinkedNode prev; DLinkedNode next; public DLinkedNode() &#123; this.prev = null; this.next = null; &#125; public DLinkedNode(int key, int value) &#123; this(); this.key = key; this.value = value; &#125;&#125;class LRUCache &#123; private int capacity; private HashMap&lt;Integer, DLinkedNode&gt; cache; private DLinkedNode head; private DLinkedNode tail; public LRUCache(int capacity) &#123; this.capacity = capacity; cache = new HashMap&lt;&gt;(capacity); head = new DLinkedNode(); tail = new DLinkedNode(); head.next = tail; tail.prev = head; &#125; public int get(int key) &#123; if (capacity == 0) return -1; DLinkedNode tmp; if ((tmp = cache.get(key)) == null) &#123; return -1; &#125; else &#123; delNode(tmp); addNode(tmp); return tmp.value; &#125; &#125; public void put(int key, int value) &#123; if (capacity == 0) return; DLinkedNode node; if ((node = cache.get(key)) == null) &#123; if (cache.size() &gt;= capacity) delNode(head.next); // 新增 addNode(new DLinkedNode(key, value)); &#125; else &#123; // 修改 modNode(node, value); &#125; &#125; public void addNode(DLinkedNode node) &#123; node.next = tail; node.prev = tail.prev; tail.prev.next = node; tail.prev = node; cache.put(node.key, node); &#125; public void modNode(DLinkedNode node, int value)&#123; delNode(node); addNode(new DLinkedNode(node.key, value)); &#125; public void delNode(DLinkedNode node)&#123; DLinkedNode next = node.next; DLinkedNode prev = node.prev; if (next != null &amp;&amp; prev != null) &#123; prev.next = next; next.prev = prev; &#125; cache.remove(node.key); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"布隆过滤器的原理及其手写一个简单的布隆过滤器","slug":"布隆过滤器的原理及其手写一个简单的布隆过滤器","date":"2020-05-24T06:26:30.000Z","updated":"2021-02-18T14:15:05.026Z","comments":true,"path":"2020/05/24/布隆过滤器的原理及其手写一个简单的布隆过滤器/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/24/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"归纳总结布隆过滤器的原理，及其优缺点；实现一个简单的布隆过滤器","text":"布隆过滤器简介布隆过滤器（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 原理如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。链表、树、散列表（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为 O(n),O(\\log n),O(1)。 布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。 例如当我新增一个key1时，通过三次hash值计算，将三个位置置为1，当新增一个key2时，通过三次hash值计算，将另外三个位置置为1 但是当我新增一个key3时，通过三次hash计算出的位置都已经被置为1了，所以布隆过滤器存在hash冲突，只能保证数据一定不在里面，不能保证数据一定在里面(false is always false, the true is not always true) 优缺点优点:相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数（O(k)）。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。 布隆过滤器可以表示全集，其它任何数据结构都不能； k和m相同，使用同一组散列函数的两个布隆过滤器的交并[来源请求]运算可以使用位操作进行。 缺点:但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。 另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。 在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。 如果选择 代码实现布隆过滤器的使用: https://juejin.im/post/5de1e37c5188256e8e43adfc 手动实现简易过滤器: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class MyBloom &#123; private Integer defaultSize; private Integer seed; private BitSet bin; public MyBloom() &#123; this.defaultSize = 1 &lt;&lt; 24; // 1024 * 1024 * 8 8M this.seed = 1 &lt;&lt; 24; this.bin = new BitSet(this.defaultSize); &#125; public MyBloom(Integer defaultSize) &#123; this.defaultSize = defaultSize; this.seed = defaultSize; this.bin = new BitSet(defaultSize); &#125; public MyBloom(Integer defaultSize, Integer seed) &#123; this.defaultSize = defaultSize; this.seed = seed &gt; defaultSize ? defaultSize : seed; this.bin = new BitSet(seed); &#125; private void put(Object key)&#123; bin.set(hash(key, 0), true); bin.set(hash(key, 10), true); bin.set(hash(key, 20), true); &#125; private boolean judge(Object key) &#123; return bin.get(hash(key, 0)) &amp; bin.get(hash(key, 10)) &amp; bin.get(hash(key, 20)); &#125; private Integer hash(Object key, int step)&#123; step = step &gt; 31 ? 31 : step; step = step &lt; 0 ? 0 : step; int hashCode = key.hashCode(); return Math.abs((hashCode &gt;&gt; step | hashCode &lt;&lt; (32-step)) % this.seed); &#125; public static void main(String[] args) &#123; MyBloom myBloom = new MyBloom(); int i = 0; try &#123; for (i = 0; i &lt; 1000000000; i++) &#123; myBloom.put(i+&quot;&quot;); &#125; for (i = 1000000000; i &lt; 2000000000; i++) &#123; boolean judge = myBloom.judge(i+&quot;&quot;); if (!judge) System.out.println(i); &#125; &#125; catch (Exception e) &#123; System.out.println(i); e.printStackTrace(); &#125; System.out.println(&quot;success&quot;); &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"}]},{"title":"LeetCode 第4题: 寻找两个正序数组的中位数","slug":"LeetCode-第4题-寻找两个正序数组的中位数","date":"2020-05-24T02:59:06.000Z","updated":"2021-02-18T14:15:05.174Z","comments":true,"path":"2020/05/24/LeetCode-第4题-寻找两个正序数组的中位数/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/24/LeetCode-%E7%AC%AC4%E9%A2%98-%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0/","excerpt":"给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。 请你找出这两个正序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。 你可以假设 nums1 和 nums2 不会同时为空。","text":"4. 寻找两个正序数组的中位数给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。 请你找出这两个正序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。 你可以假设 nums1 和 nums2 不会同时为空。 示例 1:nums1 = [1, 3]nums2 = [2]则中位数是 2.0 示例 2:nums1 = [1, 2]nums2 = [3, 4]则中位数是 (2 + 3)/2 = 2.5 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/median-of-two-sorted-arrays著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析划分数组 为了使用划分的方法解决这个问题，需要理解「中位数的作用是什么」。在统计中，中位数被用来： 将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。 我们可以参照以下方式划分数组，保证: 当 A 和 B 的总长度是偶数时，如果可以确认： len(left_part)=len(right_part) max(left_part)≤min(right_part) 当 A 和 B 的总长度是奇数时，如果可以确认： len(left_part)=len(right_part)+1 max(left_part)≤min(right_part) 123 left_part | right_part A[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1] B[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] 通过比较left_part的最大值和right_part的最小值，进行划分数组的思想 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-s-114/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现1234567891011121314151617181920212223242526public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; if (nums1.length &gt; nums2.length) return findMedianSortedArrays(nums2, nums1); int m = nums1.length, n = nums2.length; int left = 0, right = m; int lmax = 0, rmin = 0; while (left &lt;= right) &#123; int i = (left+right)&gt;&gt;1; int j = ((m+n+1)&gt;&gt;1) - i; int m1 = i==0? Integer.MIN_VALUE : nums1[i-1]; int m2 = i&gt;=m? Integer.MAX_VALUE : nums1[i]; int n1 = j==0? Integer.MIN_VALUE : nums2[j-1]; int n2 = j&gt;=n? Integer.MAX_VALUE : nums2[j]; if (m1 &lt; n2) &#123; lmax = Math.max(m1, n1); rmin = Math.min(m2, n2); left = i+1; &#125; else &#123; right = i - 1; &#125; &#125; return (m+n)%2 == 0 ? (lmax+rmin)/2.0 : lmax;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第76题: 最小覆盖子串","slug":"LeetCode-第76题-最小覆盖子串","date":"2020-05-23T01:03:43.000Z","updated":"2021-02-18T14:13:09.246Z","comments":true,"path":"2020/05/23/LeetCode-第76题-最小覆盖子串/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/23/LeetCode-%E7%AC%AC76%E9%A2%98-%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2/","excerpt":"给你一个字符串 S、一个字符串 T，请在字符串 S 里面找出：包含 T 所有字符的最小子串。","text":"76. 最小覆盖子串给你一个字符串 S、一个字符串 T，请在字符串 S 里面找出：包含 T 所有字符的最小子串。 示例：输入: S = “ADOBECODEBANC”, T = “ABC”输出: “BANC” 说明： 如果 S 中不存这样的子串，则返回空字符串 “”。 如果 S 中存在这样的子串，我们保证它是唯一的答案。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/minimum-window-substring著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析滑动窗口、哈希表： 滑动窗口右边界往右边移动，知道找一个包含t字符串的子串（通过哈希表的方式进行判断是否含有最小字串） 当找到一个最小字串后，将滑动窗口的左边界向右移动，找到包含t的最小字串 然后将左边界向外排除一个t字符串的字符，右边界找到下一个符合条件的字串 作者：LeetCode-Solution链接：https://leetcode-cn.com/problems/minimum-window-substring/solution/zui-xiao-fu-gai-zi-chuan-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344public String minWindow(String s, String t) &#123; int slen = s.length(); int tlen = t.length(); char[] sChars = s.toCharArray(); char[] tChars = t.toCharArray(); int[] winCnt = new int[128]; int[] tCnt = new int[128]; for (char ch : tChars) &#123; tCnt[ch]++; &#125; int distance = 0; int minLen = slen + 1; int begin = 0; int L = 0; int R = 0; while (R &lt; slen) &#123; // 向右扩展，找到包含t的字串 if (winCnt[sChars[R]] &lt; tCnt[sChars[R]]) &#123; distance++; &#125; winCnt[sChars[R]]++; R++; while (distance == tlen) &#123; // 左边收缩，找到包含的最小字串 if (R-L&lt;minLen) &#123; //如果比最小字串长度小就更新 minLen = R-L; begin=L; &#125; // 往外排除一个字符 if (winCnt[sChars[L]] == tCnt[sChars[L]]) &#123; distance--; &#125; winCnt[sChars[L]]--; L++; &#125; &#125; return minLen==slen + 1? &quot;&quot;: s.substring(begin, begin+minLen);&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"synchronized详解","slug":"synchronized详解","date":"2020-05-21T09:05:37.000Z","updated":"2021-02-18T14:12:10.574Z","comments":true,"path":"2020/05/21/synchronized详解/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/21/synchronized%E8%AF%A6%E8%A7%A3/","excerpt":"对synchronized关键字底层做一个详细介绍，后续还会补充","text":"synchronized详解开篇 了解synchronized需要对Java对象内存布局有一定了解 指路 synchronized 是 Java 中的关键字，是利用锁的机制来实现同步的。锁机制有如下两种特性： 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程中的协调机制，这样在同一时间只有一个线程对需同步的代码块(复合操作)进行访问。互斥性我们也往往称为操作的原子性。 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作从而引起不一致。 对象锁和类锁 对象锁：在 Java 中，每个对象都会有一个 monitor 对象，这个对象其实就是 Java 对象的锁，通常会被称为“内置锁”或“对象锁”。类的对象可以有多个，所以每个对象有其独立的对象锁，互不干扰。 类锁: 在 Java 中，针对每个类也有一个锁，可以称为“类锁”，类锁实际上是通过对象锁实现的，即类的 Class 对象锁。每个类只有一个 Class 对象，所以每个类只有一个类锁。 synchronized的使用 直接使用synchronized关键字修饰方法 synchronized(this|object) {// 修饰非静态方法} synchronized(类.class) {// 修饰静态方法} synchronized的实现在早期synchronized是一把重量级锁，申请锁资源需要操作系统内核的实现，在jdk1.5之后对锁进行了升级，产生了一系列锁升级，在竞争不激烈的情况下，就是对对象中markword的修改来实现，竞争情况十分激烈的情况下会由内核操作，详情见下方synchronized锁升级 字节码层面通过两个字节码指令实现: monitorenter、moniterexit JVM层面在JVM层面对两个字节码指令进行了实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344// hotspot\\src\\share\\vm\\interpreter\\interpreterRuntime.cpp 606行IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) &#123; Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); &#125; Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), &quot;must be NULL or an object&quot;); if (UseBiasedLocking) &#123; // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); &#125; else &#123; ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); &#125; assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), &quot;must be NULL or an object&quot;);#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END//%note monitor_1IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), &quot;must be NULL or an object&quot;); if (elem == NULL || h_obj()-&gt;is_unlocked()) &#123; THROW(vmSymbols::java_lang_IllegalMonitorStateException()); &#125; ObjectSynchronizer::slow_exit(h_obj(), elem-&gt;lock(), thread); // Free entry. This must be done here, since a pending exception might be installed on // exit. If it is not cleared, the exception handling code will try to unlock the monitor again. elem-&gt;set_obj(NULL);#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END 在第12行代码中判断是否为偏向锁，如果是偏向锁就进入 ObjectSynchronizer::fast_enter 否则就进入 ObjectSynchronizer::slow_enter 123456789101112131415161718// hotspot\\src\\share\\vm\\runtime\\synchronizer.cpp 168行void ObjectSynchronizer::fast_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) &#123; if (UseBiasedLocking) &#123; if (!SafepointSynchronize::is_at_safepoint()) &#123; BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) &#123; return; &#125; &#125; else &#123; assert(!attempt_rebias, &quot;can not rebias toward VM thread&quot;); BiasedLocking::revoke_at_safepoint(obj); &#125; assert(!obj-&gt;mark()-&gt;has_bias_pattern(), &quot;biases should be revoked by now&quot;); &#125; slow_enter (obj, lock, THREAD) ;&#125; 可以看到4行再次判断了是否为偏向锁， 第五行如果是判断了是否在安全点 如果不在安全点就执行了偏向锁的撤销重偏向 如果在安全点，就在安全点上撤销偏向锁 再去执行了slow_enter 123456789101112131415161718192021222324252627282930313233343536373839404142// hotspot\\src\\share\\vm\\runtime\\synchronizer.cpp 212行// -----------------------------------------------------------------------------// Interpreter/Compiler Slow Case// This routine is used to handle interpreter/compiler slow case// We don&#x27;t need to use fast path here, because it must have been// failed in the interpreter/compiler code.void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123; markOop mark = obj-&gt;mark(); assert(!mark-&gt;has_bias_pattern(), &quot;should not see bias pattern here&quot;); if (mark-&gt;is_neutral()) &#123; // Anticipate successful CAS -- the ST of the displaced mark must // be visible &lt;= the ST performed by the CAS. lock-&gt;set_displaced_header(mark); if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123; TEVENT (slow_enter: release stacklock) ; return ; &#125; // Fall through to inflate() ... &#125; else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; assert(lock != mark-&gt;locker(), &quot;must not re-lock the same lock&quot;); assert(lock != (BasicLock*)obj-&gt;mark(), &quot;don&#x27;t relock with same BasicLock&quot;); lock-&gt;set_displaced_header(NULL); return; &#125;#if 0 // The following optimization isn&#x27;t particularly useful. if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123; lock-&gt;set_displaced_header (NULL) ; return ; &#125;#endif // The object header will never be displaced to this lock, // so it does not matter what the value is, except that it // must be non-zero to avoid looking like a re-entrant lock, // and must not look locked either. lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125; 第15行执行了 cmpxchg_ptr 方法，这是由于锁升级进入了轻量级锁的状态 下面这段代码可以看到inflate方法：膨胀为重量级锁，再下面一段代码可以看到 1234567891011121314151617// hotspot\\src\\os_cpu\\linux_x86\\vm\\atomic_linux_x86.inline.hpp 144行inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) &#123; bool mp = os::is_MP(); __asm__ __volatile__ (LOCK_IF_MP(%4) &quot;cmpxchgq %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value;&#125;inline intptr_t Atomic::cmpxchg_ptr(intptr_t exchange_value, volatile intptr_t* dest, intptr_t compare_value) &#123; return (intptr_t)cmpxchg((jlong)exchange_value, (volatile jlong*)dest, (jlong)compare_value);&#125;inline void* Atomic::cmpxchg_ptr(void* exchange_value, volatile void* dest, void* compare_value) &#123; return (void*)cmpxchg((jlong)exchange_value, (volatile jlong*)dest, (jlong)compare_value);&#125; 可以看到轻量级锁调用的 Atomic::cmpxchg_ptr 实际上就是调用了CAS的那个汇编指令 Atomic::cmpxchg ，关于汇编指令参见这–&gt; 指路 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195// hotspot\\src\\share\\vm\\runtime\\synchronizer.cpp 1193行// Note that we could encounter some performance loss through false-sharing as// multiple locks occupy the same $ line. Padding might be appropriate.ObjectMonitor * ATTR ObjectSynchronizer::inflate (Thread * Self, oop object) &#123; // Inflate mutates the heap ... // Relaxing assertion for bug 6320749. assert (Universe::verify_in_progress() || !SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;) ; for (;;) &#123; const markOop mark = object-&gt;mark() ; assert (!mark-&gt;has_bias_pattern(), &quot;invariant&quot;) ; // The mark can be in one of the following states: // * Inflated - just return // * Stack-locked - coerce it to inflated // * INFLATING - busy wait for conversion to complete // * Neutral - aggressively inflate the object. // * BIASED - Illegal. We should never see this // CASE: inflated if (mark-&gt;has_monitor()) &#123; ObjectMonitor * inf = mark-&gt;monitor() ; assert (inf-&gt;header()-&gt;is_neutral(), &quot;invariant&quot;); assert (inf-&gt;object() == object, &quot;invariant&quot;) ; assert (ObjectSynchronizer::verify_objmon_isinpool(inf), &quot;monitor is invalid&quot;); return inf ; &#125; // CASE: inflation in progress - inflating over a stack-lock. // Some other thread is converting from stack-locked to inflated. // Only that thread can complete inflation -- other threads must wait. // The INFLATING value is transient. // Currently, we spin/yield/park and poll the markword, waiting for inflation to finish. // We could always eliminate polling by parking the thread on some auxiliary list. if (mark == markOopDesc::INFLATING()) &#123; TEVENT (Inflate: spin while INFLATING) ; ReadStableMark(object) ; continue ; &#125; // CASE: stack-locked // Could be stack-locked either by this thread or by some other thread. // // Note that we allocate the objectmonitor speculatively, _before_ attempting // to install INFLATING into the mark word. We originally installed INFLATING, // allocated the objectmonitor, and then finally STed the address of the // objectmonitor into the mark. This was correct, but artificially lengthened // the interval in which INFLATED appeared in the mark, thus increasing // the odds of inflation contention. // // We now use per-thread private objectmonitor free lists. // These list are reprovisioned from the global free list outside the // critical INFLATING...ST interval. A thread can transfer // multiple objectmonitors en-mass from the global free list to its local free list. // This reduces coherency traffic and lock contention on the global free list. // Using such local free lists, it doesn&#x27;t matter if the omAlloc() call appears // before or after the CAS(INFLATING) operation. // See the comments in omAlloc(). if (mark-&gt;has_locker()) &#123; ObjectMonitor * m = omAlloc (Self) ; // Optimistically prepare the objectmonitor - anticipate successful CAS // We do this before the CAS in order to minimize the length of time // in which INFLATING appears in the mark. m-&gt;Recycle(); m-&gt;_Responsible = NULL ; m-&gt;OwnerIsThread = 0 ; m-&gt;_recursions = 0 ; m-&gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit ; // Consider: maintain by type/class markOop cmp = (markOop) Atomic::cmpxchg_ptr (markOopDesc::INFLATING(), object-&gt;mark_addr(), mark) ; if (cmp != mark) &#123; omRelease (Self, m, true) ; continue ; // Interference -- just retry &#125; // We&#x27;ve successfully installed INFLATING (0) into the mark-word. // This is the only case where 0 will appear in a mark-work. // Only the singular thread that successfully swings the mark-word // to 0 can perform (or more precisely, complete) inflation. // // Why do we CAS a 0 into the mark-word instead of just CASing the // mark-word from the stack-locked value directly to the new inflated state? // Consider what happens when a thread unlocks a stack-locked object. // It attempts to use CAS to swing the displaced header value from the // on-stack basiclock back into the object header. Recall also that the // header value (hashcode, etc) can reside in (a) the object header, or // (b) a displaced header associated with the stack-lock, or (c) a displaced // header in an objectMonitor. The inflate() routine must copy the header // value from the basiclock on the owner&#x27;s stack to the objectMonitor, all // the while preserving the hashCode stability invariants. If the owner // decides to release the lock while the value is 0, the unlock will fail // and control will eventually pass from slow_exit() to inflate. The owner // will then spin, waiting for the 0 value to disappear. Put another way, // the 0 causes the owner to stall if the owner happens to try to // drop the lock (restoring the header from the basiclock to the object) // while inflation is in-progress. This protocol avoids races that might // would otherwise permit hashCode values to change or &quot;flicker&quot; for an object. // Critically, while object-&gt;mark is 0 mark-&gt;displaced_mark_helper() is stable. // 0 serves as a &quot;BUSY&quot; inflate-in-progress indicator. // fetch the displaced mark from the owner&#x27;s stack. // The owner can&#x27;t die or unwind past the lock while our INFLATING // object is in the mark. Furthermore the owner can&#x27;t complete // an unlock on the object, either. markOop dmw = mark-&gt;displaced_mark_helper() ; assert (dmw-&gt;is_neutral(), &quot;invariant&quot;) ; // Setup monitor fields to proper values -- prepare the monitor m-&gt;set_header(dmw) ; // Optimization: if the mark-&gt;locker stack address is associated // with this thread we could simply set m-&gt;_owner = Self and // m-&gt;OwnerIsThread = 1. Note that a thread can inflate an object // that it has stack-locked -- as might happen in wait() -- directly // with CAS. That is, we can avoid the xchg-NULL .... ST idiom. m-&gt;set_owner(mark-&gt;locker()); m-&gt;set_object(object); // TODO-FIXME: assert BasicLock-&gt;dhw != 0. // Must preserve store ordering. The monitor state must // be stable at the time of publishing the monitor address. guarantee (object-&gt;mark() == markOopDesc::INFLATING(), &quot;invariant&quot;) ; object-&gt;release_set_mark(markOopDesc::encode(m)); // Hopefully the performance counters are allocated on distinct cache lines // to avoid false sharing on MP systems ... if (ObjectMonitor::_sync_Inflations != NULL) ObjectMonitor::_sync_Inflations-&gt;inc() ; TEVENT(Inflate: overwrite stacklock) ; if (TraceMonitorInflation) &#123; if (object-&gt;is_instance()) &#123; ResourceMark rm; tty-&gt;print_cr(&quot;Inflating object &quot; INTPTR_FORMAT &quot; , mark &quot; INTPTR_FORMAT &quot; , type %s&quot;, (void *) object, (intptr_t) object-&gt;mark(), object-&gt;klass()-&gt;external_name()); &#125; &#125; return m ; &#125; // CASE: neutral // TODO-FIXME: for entry we currently inflate and then try to CAS _owner. // If we know we&#x27;re inflating for entry it&#x27;s better to inflate by swinging a // pre-locked objectMonitor pointer into the object header. A successful // CAS inflates the object *and* confers ownership to the inflating thread. // In the current implementation we use a 2-step mechanism where we CAS() // to inflate and then CAS() again to try to swing _owner from NULL to Self. // An inflateTry() method that we could call from fast_enter() and slow_enter() // would be useful. assert (mark-&gt;is_neutral(), &quot;invariant&quot;); ObjectMonitor * m = omAlloc (Self) ; // prepare m for installation - set monitor to initial state m-&gt;Recycle(); m-&gt;set_header(mark); m-&gt;set_owner(NULL); m-&gt;set_object(object); m-&gt;OwnerIsThread = 1 ; m-&gt;_recursions = 0 ; m-&gt;_Responsible = NULL ; m-&gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit ; // consider: keep metastats by type/class if (Atomic::cmpxchg_ptr (markOopDesc::encode(m), object-&gt;mark_addr(), mark) != mark) &#123; m-&gt;set_object (NULL) ; m-&gt;set_owner (NULL) ; m-&gt;OwnerIsThread = 0 ; m-&gt;Recycle() ; omRelease (Self, m, true) ; m = NULL ; continue ; // interference - the markword changed - just retry. // The state-transitions are one-way, so there&#x27;s no chance of // live-lock -- &quot;Inflated&quot; is an absorbing state. &#125; // Hopefully the performance counters are allocated on distinct // cache lines to avoid false sharing on MP systems ... if (ObjectMonitor::_sync_Inflations != NULL) ObjectMonitor::_sync_Inflations-&gt;inc() ; TEVENT(Inflate: overwrite neutral) ; if (TraceMonitorInflation) &#123; if (object-&gt;is_instance()) &#123; ResourceMark rm; tty-&gt;print_cr(&quot;Inflating object &quot; INTPTR_FORMAT &quot; , mark &quot; INTPTR_FORMAT &quot; , type %s&quot;, (void *) object, (intptr_t) object-&gt;mark(), object-&gt;klass()-&gt;external_name()); &#125; &#125; return m ; &#125;&#125; 这二百行代码就是锁膨胀的过程 hotspot中对markword的实现下面这张图是作者画的，参照理解 synchronized锁升级JDK较早的版本 OS的资源 互斥量（mutex） 用户态 -&gt; 内核态的转换 重量级 效率比较低 锁升级后: 无锁 - 偏向锁 -轻量级锁（自旋锁）-重量级锁 偏向锁 - markword 上记录当前线程指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否同一个，所以，偏向锁，偏向加锁的第一个线程 。hashCode备份在线程栈上 线程销毁，锁降级为无锁 有争用 - 锁升级为轻量级锁 - 每个线程有自己的LockRecord在自己的线程栈上，用CAS去争用markword的LR的指针，指针指向哪个线程的LR，哪个线程就拥有锁 自旋超过10次，升级为重量级锁 - 如果太多线程自旋 CPU消耗过大，不如升级为重量级锁，进入等待队列（不消耗CPU）-XX:PreBlockSpin 自旋锁在 JDK1.4.2 中引入，使用 -XX:+UseSpinning 来开启。JDK 6 中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应自旋锁意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 偏向锁由于有锁撤销的过程revoke，会消耗系统资源，所以，在锁争用特别激烈的时候，用偏向锁未必效率高。还不如直接使用轻量级锁。 jdk1.8环境下新new出来的对象默认是001，正常状态。jdk11环境下new出来的对象调用hashcode后无法进入偏向锁状态，就会变成001正常状态 jdk11默认new出来的对象就是匿名偏向对象 jdk11加锁后并且未调用hashcode方法，会由匿名偏向升级到偏向锁 jdk11调用hashcode并且加锁就是变成轻量级锁 自旋的线程多了就会变为重量级锁 jdk1.8调用hashcode并且加锁就会变成轻量级锁 多个线程抢占锁或者等待时间长直接变为重量级锁 部分总结 只要上锁就上偏向锁 外面线程少就自旋等待 自旋多了就直接重量级锁 偏向锁不可重偏向 批量偏向 批量撤销 轻量级锁: 线程在自己的线程栈生成LockRecord ，用CAS操作将markword设置为指向自己这个线程的LR的指针，设置成功者得到锁 竞争加剧：有线程超过10次自旋， -XX:PreBlockSpin， 或者自旋线程数超过CPU核数的一半， 1.6之后，加入自适应自旋 Adapative Self Spinning ， JVM自己控制 升级重量级锁：-&gt; 向操作系统申请资源，linux mutex , CPU从3级-0级系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间 synchronized vs Lock (CAS) 在高争用 高耗时的环境下synchronized效率更高 在低争用 低耗时的环境下CAS效率更高 synchronized到重量级之后是等待队列（不消耗CPU） CAS（等待期间消耗CPU） 一切以实测为准 锁消除 lock eliminate123StringBuffer sb = new StringBuffer();sb.append(1).append(2).append(3); System.out.println(ClassLayout.parseInstance(sb).toPrintable()); StringBuffer 是线程安全的，因为它的关键方法都是被 synchronized 修饰过的，但我们看上面这段代码，我们会发现，sb 这个引用只会在 add 方法中使用，不可能被其它线程引用（因为是局部变量，栈私有），因此 sb 是不可能共享的资源，JVM 会自动消除 StringBuffer 对象内部的锁。 锁粗化 lock coarsening123456StringBuffer sb = new StringBuffer();int count = 100;while (count-- &gt; 0) &#123; sb.append(1);&#125; System.out.println(ClassLayout.parseInstance(sb).toPrintable()); JVM 会检测到这样一连串的操作都对同一个对象加锁（while 循环内 100 次执行 append，没有锁粗化的就要进行 100 次加锁/解锁），此时 JVM 就会将加锁的范围粗化到这一连串的操作的外部（比如 while 虚幻体外），使得这一连串操作只需要加一次锁即可。 锁重入sychronized是可重入锁重入次数必须记录，因为要解锁几次必须得对应偏向锁 自旋锁 -&gt; 线程栈 -&gt; LR + 1重量级锁 -&gt; ObjectMonitor字段上 123456789101112public class T &#123; static volatile int i = 0; public static void n() &#123; i++; &#125; public static synchronized void m() &#123;&#125; publics static void main(String[] args) &#123; for(int j=0; j&lt;1000_000; j++) &#123; m(); n(); &#125; &#125;&#125; openjdk中引入hsdis插件，打印出JIT中的所有汇编指令，执行java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly T C1 Compile Level 1 (一级优化)C2 Compile Level 2 (二级优化) 找到m() n()方法的汇编码，会看到 lock comxchg …..指令 Q&amp;AQ: 轻量级锁重量级锁的hashCode存在与什么地方？A: 线程栈中，轻量级锁的LR中，或是代表重量级锁的ObjectMonitor的成员中 Q: 自旋锁什么时候升级为重量级锁？为什么有自旋锁还需要重量级锁A: 自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗,重量级锁（非公平锁、metux）有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源 Q: 偏向锁是否一定比自旋锁效率高？A: 不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁, JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开 参考 开篇参考作者：zly394链接：https://juejin.im/post/594a24defe88c2006aa01f1c来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://rabbit-mar.github.io/tags/JVM/"}]},{"title":"LeetCode 第29题:两数相除","slug":"LeetCode-第29题-两数相除","date":"2020-05-21T01:42:57.000Z","updated":"2021-02-18T14:12:10.518Z","comments":true,"path":"2020/05/21/LeetCode-第29题-两数相除/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/21/LeetCode-%E7%AC%AC29%E9%A2%98-%E4%B8%A4%E6%95%B0%E7%9B%B8%E9%99%A4/","excerpt":"给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。 返回被除数 dividend 除以除数 divisor 得到的商。","text":"29. 两数相除给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。 返回被除数 dividend 除以除数 divisor 得到的商。 整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2 示例 1:输入: dividend = 10, divisor = 3输出: 3解释: 10/3 = truncate(3.33333..) = truncate(3) = 3 示例 2:输入: dividend = 7, divisor = -3输出: -2解释: 7/-3 = truncate(-2.33333..) = -2 提示： 被除数和除数均为 32 位有符号整数。 除数不为 0。 假设我们的环境只能存储 32 位有符号整数，其数值范围是 [−231, 231 − 1]。本题中，如果除法结果溢出，则返回 231 − 1。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/divide-two-integers著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析1. 位操作商，公式是：(被除数-余数)÷除数=商，记作：被除数÷除数=商…余数，是一种数学术语。在一个除法算式里，被除数、余数、除数和商的关系为：(被除数-余数)÷除数=商，记作：被除数÷除数=商…余数，进而推导得出：商×除数+余数=被除数。 要求商，我们首先想到的是减法，能被减多少次，那么商就为多少，但是明显减法的效率太低 那么我们可以用位移法，因为计算机在做位移时效率特别高，向左移1相当于乘以2，向右位移1相当于除以2 我们可以把一个dividend（被除数）先除以2^n，n最初为31，不断减小n去试探,当某个n满足dividend/2^n&gt;=divisor时， 表示我们找到了一个足够大的数，这个数*divisor是不大于dividend的，所以我们就可以减去2^n个divisor，以此类推 我们可以以100/3为例 2^n是1，2，4，8…2^31这种数，当n为31时，这个数特别大，100/2^n是一个很小的数，肯定是小于3的，所以循环下来， 当n=5时，100/32=3, 刚好是大于等于3的，这时我们将100-32*3=4，也就是减去了32个3，接下来我们再处理4，同样手法可以再减去一个3 所以一共是减去了33个3，所以商就是33 这其中得处理一些特殊的数，比如divisor是不能为0的，Integer.MIN_VALUE和Integer.MAX_VALUE 2. 间接除法使用对数减法相当于两个对数相除 logA - logB = log(A/B) 代码实现1.位操作参考leetcode上评论区的代码实现 贡献代码主 12345678910111213141516171819202122public int divide(int dividend, int divisor) &#123; if (dividend == 0) return 0; if (dividend == Integer.MIN_VALUE &amp;&amp; divisor == -1) return Integer.MAX_VALUE; boolean flag = (dividend ^ divisor) &lt; 0; if (divisor == 1) return dividend; int ans = 0; long dd = Math.abs((long) dividend); long dr = Math.abs((long) divisor); for (int i = 31; i &gt;= 0; i--) &#123; if ((dd &gt;&gt; i) &gt;= dr) &#123; ans += 1&lt;&lt;i; dd -= dr &lt;&lt; i; &#125; &#125; return flag ? -ans : ans;&#125; 2. 间接除法参考leetcode上评论区的代码实现 贡献代码主 123456789101112public int divide(int dividend, int divisor) &#123; if (divisor == 1) return dividend; boolean flag = (dividend ^ divisor) &lt; 0; long dd = Math.abs((long) dividend); long dr = Math.abs((long) divisor); double logAns = Math.log(dd) - Math.log(dr); int ans = (int) Math.exp(logAns); return flag?-ans:ans;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第5题:最长回文子串","slug":"LeetCode-第5题-最长回文子串","date":"2020-05-20T23:06:59.000Z","updated":"2021-02-18T14:10:01.130Z","comments":true,"path":"2020/05/21/LeetCode-第5题-最长回文子串/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/21/LeetCode-%E7%AC%AC5%E9%A2%98-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","excerpt":"给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。","text":"5. 最长回文子串给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 示例 1： 输入: “babad”输出: “bab”注意: “aba” 也是一个有效答案。示例 2： 输入: “cbbd”输出: “bb” 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-palindromic-substring著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析一、动态分析对于一个子串而言，如果它是回文串，并且长度大于 22，那么将它首尾的两个字母去除之后，它仍然是个回文串。例如对于字符串“ababa”，如果我们已经知道“bab” 是回文串，那么“ababa” 一定是回文串，这是因为它的首尾两个字母都是“a”。 时间复杂度：O(n^2)，其中n是字符串的长度。动态规划的状态总数为 O(n^2)对于每个状态，我们需要转移的时间为O(1)。 空间复杂度：O(n^2)，即存储动态规划状态需要的空间。 二、中点扩散边界情况即为子串长度为1或2的情况。我们枚举每一种边界情况，并从对应的子串开始不断地向两边扩展。如果两边的字母相同，我们就可以继续扩展，例如从P(i+1,j−1) 扩展到P(i,j)；如果两边的字母不同，我们就可以停止扩展，因为在这之后的子串都不能是回文串了。 时间复杂度：O(n^2)，其中n是字符串的长度。长度为1和2的回文中心分别有n和n−1个，每个回文中心最多会向外扩展O(n)次。 空间复杂度：O(1)。 三、manacher算法我们可以通过一个特别的操作将奇偶数的情况统一起来：我们向字符串的头尾以及每两个字符中间添加一个特殊字符 #，比如字符串 aaba 处理后会变成 #a#a#b#a#。那么原先长度为偶数的回文字符串 aa 会变成长度为奇数的回文字符串 #a#a#，而长度为奇数的回文字符串 aba 会变成长度仍然为奇数的回文字符串 #a#b#a#，我们就不需要再考虑长度为偶数的回文字符串了。 时间复杂度：O(n)，其中n是字符串的长度。由于对于每个位置，扩展要么从当前的最右侧臂长 right 开始，要么只会进行一步，而 right 最多向前走O(n) 步，因此算法的复杂度为O(n)。 空间复杂度：O(n)，我们需要O(n)的空间记录每个位置的臂长。 具体了解参照leetcode的视频 leetcode第5题:最长回文子串第一次看不懂没关系，一定要多看几遍！！！ 代码实现中心扩散 这个是博主很早以前写的代码，很烂，但是思路清晰 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123; public String longestPalindrome(String s) &#123; String result = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) &#123; String tmp1 = getPalindromeOfSingleCenter(s,i); String tmp2 = getPalindromeOfDoubleCenter(s,i); if (result.length()&lt;tmp1.length()) &#123; result = tmp1; &#125; if (result.length()&lt;tmp2.length()) &#123; result = tmp2; &#125; &#125; return result; &#125; public String getPalindromeOfSingleCenter(String source, int index)&#123; String palindromeStr = source.substring(index,index+1); for (int i = index+1; i &lt; source.length(); i++) &#123; if (2*index-i&lt;0 || i&gt;source.length()-1) &#123; return palindromeStr; &#125; else &#123; if (source.charAt(i) == source.charAt(2*index-i)) &#123; palindromeStr = source.substring(2*index-i,i+1); &#125; else &#123; return palindromeStr; &#125; &#125; &#125; return palindromeStr; &#125; public String getPalindromeOfDoubleCenter(String source, int index)&#123; String palindromeStr = source.substring(index,index+1); if (index+1 &lt; source.length() &amp;&amp; source.charAt(index) == source.charAt(index+1)) &#123; palindromeStr = source.substring(index,index+2); for (int i = index+2; i &lt; source.length(); i++) &#123; if (2*index-i+1&lt;0 || i&gt;source.length()-1) &#123; return palindromeStr; &#125; else &#123; if (source.charAt(2*index-i+1) == source.charAt(i)) &#123; palindromeStr = source.substring(2*index-i+1,i+1); &#125; else &#123; return palindromeStr; &#125; &#125; &#125; &#125; else &#123; return palindromeStr; &#125; return palindromeStr; &#125;&#125; manacher算法 这个是作者理解了leetcode的算法自己敲得一遍 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public String longestPalindrome(String s) &#123; if (s.length() &lt; 2) return s; String str = expand(s); int slen = str.length(); int[] p = new int[slen]; int center = 0; int maxRight = 0; int L = 0; int maxLen = 1; for (int i = 0; i &lt; slen; i++) &#123; // 这一步是为了利用之前的p[i]，优化代码，很重要！！！ if (i &lt; maxRight) &#123; int mirror = 2 * center - i; p[i] = Math.min(p[mirror], maxRight - i); &#125; // 开始中心扩散 int left = i - p[i] - 1; int right = i + p[i] + 1; while (left&gt;=0 &amp;&amp; right &lt; slen &amp;&amp; str.charAt(left) == str.charAt(right)) &#123; p[i]++; left--; right++; &#125; // 刷新maxRight 和center if (i+p[i] &gt; maxRight) &#123; maxRight = i + p[i]; center = i; &#125; // 刷新maxlen和L 最终输出答案用到 if (p[i] &gt; maxLen) &#123; maxLen = p[i]; L = (i-maxLen)/2; &#125; &#125; return s.substring(L, L + maxLen);&#125;// 拓展字符串public String expand(String s) &#123; StringBuilder sb = new StringBuilder(2 * s.length() + 1); sb.append(&#x27;#&#x27;); for (int i = 0; i &lt; s.length(); i++) &#123; sb.append(s.charAt(i)).append(&#x27;#&#x27;); &#125; return sb.toString();&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"深入剖析CAS","slug":"深入剖析CAS","date":"2020-05-20T00:20:58.000Z","updated":"2021-02-18T14:09:03.166Z","comments":true,"path":"2020/05/20/深入剖析CAS/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/20/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90CAS/","excerpt":"将CAS深入到hotspot源码分析，对CAS内容做一个总结","text":"深入剖析CAS开篇当我们一次i++操作时，是不具备原子性的，我们可以通过jclasslib查看到i++的jvm指令: 12345678910111213public class Main &#123; public static void main(String[] args) &#123; int i = 0; i++; &#125;&#125;/**--&gt; main.Code0 iconst_01 istore_12 iinc 1 by 15 return*/ 可以看到主要的实现方式就是iinc这个指令，在openjdk源码中 openjdk8u\\hotspot\\src\\share\\vm\\ci\\ciTypeFlow.cpp 文件中对iinc指令进行了实现 12345678&#x2F;&#x2F; 1295行 case Bytecodes::_iinc:&#123; int lnum &#x3D; str-&gt;get_index(); check_int(local(lnum)); store_to_local(lnum); break;&#125; 引入CAS可以发现这个指令在底层无法保证原子性，所以引入AtomicInteger这个类，然而这个的自增通过CAS实现 123456789101112131415161718public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(1); atomicInteger.incrementAndGet();&#125;/**跟踪一下字节码 0 new #2 &lt;java/util/concurrent/atomic/AtomicInteger&gt; 3 dup 4 iconst_1 5 invokespecial #3 &lt;java/util/concurrent/atomic/AtomicInteger.&lt;init&gt;&gt; 8 astore_1 9 aload_110 invokevirtual #4 &lt;java/util/concurrent/atomic/AtomicInteger.incrementAndGet&gt;13 pop14 return*/ 主要操作在第十行执行了AtomicInteger.类中incrementAndGet方法再跟踪一下 1234567891011121314public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125;/**这里时incrementAndGet方法中的字节码 0 getstatic #3 &lt;java/util/concurrent/atomic/AtomicInteger.U&gt; 3 aload_0 4 getstatic #4 &lt;java/util/concurrent/atomic/AtomicInteger.VALUE&gt; 7 iconst_1 8 invokevirtual #9 &lt;jdk/internal/misc/Unsafe.getAndAddInt&gt;11 iconst_112 iadd13 ireturn*/ 这里又调用了一个Unsafe类的getAndAddInt方法，再跟踪 12345678910public final int getAndAddInt(Object var1, long var2, int var4) &#123;int var5;do &#123; var5 = this.getIntVolatile(var1, var2);&#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));return var5;/**字节码已经无法跟踪*/&#125; 主要调用两个方法: getIntVolatile 和 compareAndSwapInt 这里逻辑是只要下面一直不成功执行就一直获取内存中的最新值，然后就调用了native本地方法 hotspot源码分析去 openjdk8u\\hotspot\\src\\share\\vm\\prims\\unsafe.cpp 中找到 compareAndSwapInt 方法的实现 1234567891011121314151617181920// 1614行&#123;CC&quot;getObjectVolatile&quot;,CC&quot;(&quot;OBJ&quot;J)&quot;OBJ&quot;&quot;, FN_PTR(Unsafe_GetObjectVolatile)&#125;,&#123;CC&quot;putObjectVolatile&quot;,CC&quot;(&quot;OBJ&quot;J&quot;OBJ&quot;)V&quot;, FN_PTR(Unsafe_SetObjectVolatile)&#125;,// getObjectVolatile方法....................// 1657行&#123;CC&quot;compareAndSwapObject&quot;, CC&quot;(&quot;OBJ&quot;J&quot;OBJ&quot;&quot;OBJ&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSwapObject)&#125;,&#123;CC&quot;compareAndSwapInt&quot;, CC&quot;(&quot;OBJ&quot;J&quot;&quot;I&quot;&quot;I&quot;&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSwapInt)&#125;,&#123;CC&quot;compareAndSwapLong&quot;, CC&quot;(&quot;OBJ&quot;J&quot;&quot;J&quot;&quot;J&quot;&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSwapLong)&#125;,...................// 1229行UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END Unsafe_CompareAndSwapInt 这个方法主要调用了 Atomic::cmpxchg 这个方法，可以看到这个方法在不同操作系统中有不同的实现，这里列举Windows和linux下的，继续跟踪 1234567891011121314151617181920212223242526272829303132333435363738// openjdk8u\\hotspot\\src\\os_cpu\\windows_x86\\vm\\atomic_windows_x86.inline.hpp// 66行#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0:.....................//216行inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125;// openjdk8u\\hotspot\\src\\os_cpu\\linux_x86\\vm\\atomic_linux_x86.inline.hpp // 47行// Adding a lock prefix to an instruction on MP machine#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot;..............................// 144行inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) &#123; bool mp = os::is_MP(); __asm__ __volatile__ (LOCK_IF_MP(%4) &quot;cmpxchgq %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value;&#125; 实现了asm汇编语言和__volatile__禁止编译器优化，逐条分析 首先判断了当前用户处理器的个数，如果是多核(multi processor)的就返回true 1234567891011// openjdk8u\\hotspot\\src\\share\\vm\\runtime\\os.hpp 217行static inline bool is_MP() &#123; // During bootstrap if _processor_count is not yet initialized // we claim to be MP as that is safest. If any platform has a // stub generator that might be triggered in this phase and for // which being declared MP when in fact not, is a problem - then // the bootstrap routine for the stub generator needs to check // the processor count directly and leave the bootstrap routine // in place until called after initialization has ocurred. return (_processor_count != 1) || AssumeMP;&#125; 然后执行 LOCK_IF_MP 方法,针对linux版的分析，有四条指令 123#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot;// 首先cmp指令比较 然后je执行(Jump if Equal)如果前面的相等就跳到后面标记1的位置(1:)，否则就执行lock。 详细说明一下lock指令，如何保证了操作的原子性，在 inter开发手册 中有详细介绍 所以在以前的LOCK前缀指令中，会进行锁总线处理，禁止其他处理器对内存操作。后面升级后，进行锁缓存的方式 然后再介绍一下 linux下的汇编格式 此处借鉴掘金上的一位博文的内容https://juejin.im/post/5a73cbbff265da4e807783f5 12345asm ( assembler template : output operands &#x2F;* optional *&#x2F; : input operands &#x2F;* optional *&#x2F; : list of clobbered registers &#x2F;* optional *&#x2F; ); template就是cmpxchgl %1,(%3)表示汇编模板 output operands表示输出操作数,=a对应eax寄存器 input operand 表示输入参数，%1 就是exchange_value, %3是dest, %4就是mp， r表示任意寄存器，a还是eax寄存器 list of clobbered registers就是些额外参数，cc表示编译器cmpxchgl的执行将影响到标志寄存器, memory告诉编译器要重新从内存中读取变量的最新值，这点实现了volatile的感觉。 那么表达式其实就是cmpxchgl exchange_value ,dest，我们会发现%2也就是compare_value没有用上，这里就要分析cmpxchgl的语义了。cmpxchgl末尾l表示操作数长度为4，上面已经知道了。cmpxchgl会默认比较eax寄存器的值即compare_value和exchange_value的值，如果相等，就把dest的值赋值给exchange_value,否则，将exchange_value赋值给eax。最终，JDK通过CPU的cmpxchgl指令的支持，实现AtomicInteger的CAS操作的原子性。 总结为何称CAS为自旋锁1234567891011121314151617181920// openjdk8u\\hotspot\\src\\share\\vm\\runtime\\atomic.cpp 45行jbyte Atomic::cmpxchg(jbyte exchange_value, volatile jbyte* dest, jbyte compare_value) &#123; assert(sizeof(jbyte) == 1, &quot;assumption.&quot;); uintptr_t dest_addr = (uintptr_t)dest; uintptr_t offset = dest_addr % sizeof(jint); volatile jint* dest_int = (volatile jint*)(dest_addr - offset); jint cur = *dest_int; jbyte* cur_as_bytes = (jbyte*)(&amp;cur); jint new_val = cur; jbyte* new_val_as_bytes = (jbyte*)(&amp;new_val); new_val_as_bytes[offset] = exchange_value; while (cur_as_bytes[offset] == compare_value) &#123; jint res = cmpxchg(new_val, dest_int, cur); if (res == cur) break; cur = res; new_val = cur; new_val_as_bytes[offset] = exchange_value; &#125; return cur_as_bytes[offset];&#125; 可以看到在执行 cmpxchg 方法外面一直持续着一个死循环，只要不交换成功就不退出，称为自旋 为何称无锁没有涉及到锁的获取和消除 产生的问题ABA问题: 当1号线程拿到值A更改为新值的过程中，有一个2号线程将值改为B，然后又改回A，对于1号线程来说是不可见了，由于最开始拿的值和最开始保存的值相同，可以交换成功。但实际中间的值经过了一次转换。 资源耗费大: 在自旋的过程中CPU资源消耗大","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://rabbit-mar.github.io/tags/JVM/"}]},{"title":"Java对象内存布局","slug":"Java对象内存布局","date":"2020-05-19T21:25:05.000Z","updated":"2021-02-18T14:08:18.480Z","comments":true,"path":"2020/05/20/Java对象内存布局/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/20/Java%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","excerpt":"该博文受到很多网上公开资源的整合，结合自己的理解，造就这篇博文，所以将其定位为装载","text":"java对象内存模型准备工作这边博文借助openjdk的开源工具JOL进行分析，在pom.xml中导入对应的包 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 开篇首先确认一个对象的内存布局，分为对象和数值对象两类: 普通对象(Object为例)有16个字节 markword class pointer instance date padding 8字节 4字节 0字节 4字节 这里解释一下:markword: 固定为8字节 class Pointer: 默认使用了压缩指针。64位的操作系统，本来情况下压缩指针也为64位(8字节)，由于jvm使用了压缩指针，将8字节类指针压缩为4字节 instance data: 一个空对象[new Object()]由于没有进行赋值，所以为0字节 padding: 将整个对象进行对齐，能够被8字节整除。例如前面一共为12字节，加上4字节，正好对齐为16字节，能够被8整除 ※ 见代码 123456789101112131415public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable());&#125;/**java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 50 1f 89 51 (01010000 00011111 10001001 01010001) (1367940944) 12 4 (object header) 1a 02 00 00 (00011010 00000010 00000000 00000000) (538)Instance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total*/ o：markword(8字节)+class ponter(4字节)+instance data(0字节)+padding(4字节) = 16字节 如果是数组对象，比普通对象多两个: 数组长度，对象头对齐 markword class pointer length padding instance date padding 8字节 默认4字节 4字节 4字节/0字节 N字节 0字节-7字节 实例数据区大小视情况而定 基本数据类型: int long float double byte short char boolean 4字节 8字节 4字节 8字节 1字节 2字节 2字节 1字节 引用类型数组: 开启指针压缩，默认为4字节；关闭指针压缩，为8字节(64位操作系统) ※ 见代码 开启指针压缩（开启指针压缩以及关闭指针压缩的方式见文末） 123456789101112131415161718192021222324252627282930313233343536static Test[] arr = &#123;new Test(1,2),new Test(2,3)&#125;;static int[] arr1 = &#123;1,2,3&#125;;System.out.println(ClassLayout.parseInstance(arr).toPrintable());System.out.println(ClassLayout.parseInstance(arr1).toPrintable());class Test &#123; int a; float b; public Test(int a, float b) &#123; this.a = a; this.b = b; &#125;&#125;/**[Lcom.marveal.Demo.Test; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 8a ce 00 20 (10001010 11001110 00000000 00100000) (536923786) 12 4 (object header) 02 00 00 00 (00000010 00000000 00000000 00000000) (2) 16 8 com.marveal.Demo.Test Test;.&lt;elements&gt; N/AInstance size: 24 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total--------------------------------------------------------------[I object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 82 01 00 20 (10000010 00000001 00000000 00100000) (536871298) 12 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 16 12 int [I.&lt;elements&gt; N/A 28 4 (loss due to the next object alignment)Instance size: 32 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total*/ arr数组: markword(8字节)+class pointer(4字节)+ length(4字节)+padding(0字节)+instance data(4字节*2)+padding(0字节)=24字节 arr1数组: markword(8字节)+class pointer(4字节)+ length(4字节)+padding(0字节)+instance data(4字节*3)+padding(4字节)=32字节 关闭指针压缩:（关闭压缩oop，并非类指针） 123456789101112131415161718192021222324252627282930313233static Test[] arr = &#123;new Test(1,2),new Test(2,3)&#125;;static int[] arr1 = &#123;1,2,3&#125;;System.out.println(ClassLayout.parseInstance(arr).toPrintable()); System.out.println(ClassLayout.parseInstance(arr1).toPrintable());/**[Lcom.marveal.Demo.Test; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) c8 5c 69 23 (11001000 01011100 01101001 00100011) (594107592) 12 4 (object header) df 01 00 00 (11011111 00000001 00000000 00000000) (479) 16 4 (object header) 02 00 00 00 (00000010 00000000 00000000 00000000) (2) 20 4 (alignment/padding gap) 24 16 com.marveal.Demo.Test Test;.&lt;elements&gt; N/AInstance size: 40 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total----------------------------------------------------------------------[I object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 10 0c 29 23 (00010000 00001100 00101001 00100011) (589892624) 12 4 (object header) df 01 00 00 (11011111 00000001 00000000 00000000) (479) 16 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 20 4 (alignment/padding gap) 24 12 int [I.&lt;elements&gt; N/A 36 4 (loss due to the next object alignment)Instance size: 40 bytesSpace losses: 4 bytes internal + 4 bytes external = 8 bytes total*/ arr数组: markword(8字节)+class pointer(8字节)+ length(4字节)+padding(4字节)+instance data(8字节*2)+padding(0字节)=40字节 arr1数组: markword(8字节)+class pointer(8字节)+ length(4字节)+padding(4字节)+instance data(4字节*3)+padding(4字节)=40字节 关于开启/关闭指针压缩在执行java程序时使用 -XX:+PrintCommandLineFlags 打印默认执行参数 1234567891011C:\\&gt;java -XX:+PrintCommandLineFlags -version-XX:InitialHeapSize&#x3D;129411456-XX:MaxHeapSize&#x3D;2070583296-XX:+PrintCommandLineFlags-XX:+UseCompressedClassPointers-XX:+UseCompressedOops-XX:-UseLargePagesIndividualAllocation-XX:+UseParallelGCjava version &quot;1.8.0_212&quot;Java(TM) SE Runtime Environment (build 1.8.0_212-b10)Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode) -XX:+UseCompressedClassPointers : 使用压缩指针，64位的操作系统中指针大小也为64(8字节)，使用压缩指针将其变成4字节大小指针 -XX:+UseCompressedOops：ordinary object pointer 普通对象指针，默认压缩，也变成四字节 可以看到jdk1.8中64位操作系统默认开启了指针压缩， 使用 -XX:-UseCompressedOops 关闭指针压缩(注意！前面是减号) 其他 如果数组大小超过了堆大小，会触发OOM 1234567static Test[] arr = new Test[Integer.MAX_VALUE&gt;&gt;1];System.out.println(ClassLayout.parseInstance(arr).toPrintable());/**Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.marveal.Demo.Main.&lt;clinit&gt;(Main.java:7)*/ 一个数组长度过大会超过VM极限（大于Integer.MAX_VALUE-3） 1234567static Test[] arr = new Test[Integer.MAX_VALUE];System.out.println(ClassLayout.parseInstance(arr).toPrintable());/**Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit at com.marveal.Demo.Main.&lt;clinit&gt;(Main.java:7)*/ 对象内存布局hotspot中的定义 12345678910111213141516171819// openjdk8u\\hotspot\\src\\share\\vm\\oops\\markOop.hpp// 32 bits:// --------// hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object)// size:32 ------------------------------------------&gt;| (CMS free block)// PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)//// 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://rabbit-mar.github.io/tags/JVM/"}]},{"title":"LeetCode 第567题: 字符串的排列","slug":"LeetCode-第567题-字符串的排列","date":"2020-05-19T05:28:58.000Z","updated":"2021-02-18T14:05:55.322Z","comments":true,"path":"2020/05/19/LeetCode-第567题-字符串的排列/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/19/LeetCode-%E7%AC%AC567%E9%A2%98-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/","excerpt":"给定两个字符串 s1 和 s2，写一个函数来判断 s2 是否包含 s1 的排列。 换句话说，第一个字符串的排列之一是第二个字符串的子串。","text":"567. 字符串的排列给定两个字符串 s1 和 s2，写一个函数来判断 s2 是否包含 s1 的排列。 换句话说，第一个字符串的排列之一是第二个字符串的子串。 示例1:输入: s1 = “ab” s2 = “eidbaooo”输出: True解释: s2 包含 s1 的排列之一 (“ba”). 示例2:输入: s1= “ab” s2 = “eidboaoo”输出: False 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/permutation-in-string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析采用滑动窗口加哈希表的方式 哈希表里面存放着26个字母，值为s1中字母出现的次数 那么当我在遍历s2字符串时，只要滑动窗口的内各个字符的个数和哈希表中字符个数相同即可 但是为了不用每次都去对比是否相同，只需要将滑动窗口的大小等于s1字符串的长度即可 所以最开始滑动窗口的大小为0，当遇到s2中的字母在哈希表中值大于0，就让滑动窗口扩一个，如果遇到s2中的字母在哈希表中值小于0，说明s1中不存在该字母，就让滑动窗口收缩为0，并让哈希表中的值还原 代码实现123456789101112131415161718192021222324252627public boolean checkInclusion(String s1, String s2) &#123; // 初始化哈希表 HashMap&lt;Character, Integer&gt; mp = new HashMap&lt;&gt;(26); for (int i = 0; i &lt; 26; i++) &#123; mp.put((char) (i+&#x27;a&#x27;), 0); &#125; for (int i = 0; i &lt; s1.length(); i++) &#123; mp.put(s1.charAt(i), mp.get(s1.charAt(i))+1); &#125; int L = 0, R = 0; while (R &lt; s2.length()) &#123; char ch = s2.charAt(R++); mp.put(ch, mp.get(ch) - 1); // 将哈希表中的值-1 // 如果减了之后小于0， 就说明哈希表中这个字母不够了 // 开始还原哈希表中的数据，滑动窗口收缩为0 while (L &lt; R &amp;&amp; mp.get(ch) &lt; 0) &#123; mp.put(s2.charAt(L), mp.get(s2.charAt(L)) + 1); L++; &#125; // 如果减了之后不小于0，就说明哈希表中有值 // 一直减到滑动窗口大小和s1相等时，说明这个就是答案 if ( (R-L) == s1.length() ) return true; &#125; return false;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第125题: 验证回文串","slug":"LeetCode-第125题-验证回文串","date":"2020-05-19T03:03:45.000Z","updated":"2021-02-18T14:05:55.271Z","comments":true,"path":"2020/05/19/LeetCode-第125题-验证回文串/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/19/LeetCode-%E7%AC%AC125%E9%A2%98-%E9%AA%8C%E8%AF%81%E5%9B%9E%E6%96%87%E4%B8%B2/","excerpt":"给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。 说明：本题中，我们将空字符串定义为有效的回文串。","text":"125. 验证回文串给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。说明：本题中，我们将空字符串定义为有效的回文串。 示例 1:输入: “A man, a plan, a canal: Panama”输出: true 示例 2:输入: “race a car”输出: false 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/valid-palindrome著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析题目无难度，关键在于排除无关字符 代码实现123456789101112131415161718public boolean isPalindrome(String s) &#123; if (s.length() &lt;= 1) return true; int L = 0, R = s.length() - 1; while (L &lt; R) &#123; if (!Character.isLetterOrDigit(s.charAt(L))) &#123; L++; continue; &#125; if (!Character.isLetterOrDigit(s.charAt(R))) &#123; R--; continue; &#125; if (Character.toLowerCase(s.charAt(L)) == Character.toLowerCase(s.charAt(R))) &#123; L++; R--; &#125; else &#123; return false; &#125; &#125; return true;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第680题:验证回文字符串 Ⅱ","slug":"LeetCode-第680题-验证回文字符串-Ⅱ","date":"2020-05-19T02:36:54.000Z","updated":"2021-02-18T14:04:11.145Z","comments":true,"path":"2020/05/19/LeetCode-第680题-验证回文字符串-Ⅱ/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/19/LeetCode-%E7%AC%AC680%E9%A2%98-%E9%AA%8C%E8%AF%81%E5%9B%9E%E6%96%87%E5%AD%97%E7%AC%A6%E4%B8%B2-%E2%85%A1/","excerpt":"给定一个非空字符串 s，最多删除一个字符。判断是否能成为回文字符串。","text":"680. 验证回文字符串 Ⅱ给定一个非空字符串 s，最多删除一个字符。判断是否能成为回文字符串。 示例 1:输入: “aba”输出: True 示例 2:输入: “abca”输出: True解释: 你可以删除c字符。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/valid-palindrome-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析简单的回文串判断，双指针+递归处理 既然这么简单我为什么要记录！！！ 原因是我超时了，需要一点小优化，代码实现见 代码实现下面这段是超时代码 1234567891011121314151617// 用来判断是否需要到了删除字符// 只有一次删除机会，如果为true并且还不相等，那就返回falsepublic boolean flag = false;public boolean validPalindrome(String s) &#123; if (s.length() &lt;= 1) return true; if (s.charAt(0) == s.charAt(s.length() - 1)) &#123; return validPalindrome(s.substring(1, s.length()-1)); &#125; else &#123; if (!flag) &#123; flag = true; return validPalindrome(s.substring(0, s.length()-1)) || validPalindrome(s.substring(1, s.length())); &#125; else return false; &#125;&#125; 下面这段是不超时代码 1234567891011121314151617181920public boolean flag = false;public boolean validPalindrome(String s) &#123; if (s.length() &lt;= 1) return true; int L = 0, R = s.length() - 1; while (L &lt; R) &#123; if (s.charAt(L) == s.charAt(R)) &#123; L++; R--; &#125; else &#123; if (!flag) &#123; flag = true; return validPalindrome(s.substring(L+1, R+1)) || validPalindrome(s.substring(L, R)); &#125; else return false; &#125; &#125; return true;&#125; 两个代码差距只有一点点但是可以测试以下结果测试字符串的长度为 49801方式一执行: Exception in thread “main” java.lang.StackOverflowError 方式二执行: 消耗时长: 1ms 差值毫厘，失之千里","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"项目整合Redis对用户访问和点赞功能优化","slug":"项目整合Redis对用户访问和点赞功能优化","date":"2020-05-19T01:15:13.000Z","updated":"2021-02-18T14:03:00.181Z","comments":true,"path":"2020/05/19/项目整合Redis对用户访问和点赞功能优化/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/19/%E9%A1%B9%E7%9B%AE%E6%95%B4%E5%90%88Redis%E5%AF%B9%E7%94%A8%E6%88%B7%E8%AE%BF%E9%97%AE%E5%92%8C%E7%82%B9%E8%B5%9E%E5%8A%9F%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"优化用户访问博客详情页的对博文点赞后端处理的功能优化","text":"优化前功能实现流程图 优化后功能实现流程图 后记如果有更好的建议，希望过客可以留下你的建议，感谢万分","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"}]},{"title":"Springboot集成Redis实现定时任务Key消失问题","slug":"Springboot集成Redis实现定时任务Key消失问题","date":"2020-05-18T23:49:04.000Z","updated":"2021-02-18T14:01:52.164Z","comments":true,"path":"2020/05/19/Springboot集成Redis实现定时任务Key消失问题/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/19/Springboot%E9%9B%86%E6%88%90Redis%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1Key%E6%B6%88%E5%A4%B1%E9%97%AE%E9%A2%98/","excerpt":"记录一次本博客网站Redis问题: 使用Redis键空间事件做定时任务，运行过程中key消失问题","text":"SpringBoot集成Redis Key消失问题Springboot集成Redis步骤准备工作参考网站Redis官网键空间通知官网中介绍了其准备工作 先将redis.conf文件中的notify-keyspace-events改为KEA notify-keyspace-events KEA 官网中有对KEA三个参数进行了解释，redis.conf文件中也有介绍 123456789101112K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...$ String commandsl List commandss Set commandsh Hash commandsz Sorted set commandst Stream commandsx Expired events (events generated every time a key expires)e Evicted events (events generated when a key is evicted for maxmemory)A Alias for g$lshztxe, so that the &quot;AKE&quot; string means all the events. 字符串中至少应存在K或E，否则字符串将不传递任何事件。 例如，仅启用列表的键空间事件，必须将配置参数设置为Kl，依此类推。 该字符串KEA可用于启用每个可能的事件。 在redis-cli中查看是否生效 $ redis-cli config get notify-keyspace-events 在终端输入psubscribe __keyevent@0__:expired 订阅一个键失效事件 psubscribe __keyevent@0__:expired 在另一个终端中设置一个key过期时间为10s可以看到第一个终端产生反应 第二个终端 set test t1 ex 10 第一个终端 1)”pmessage”2)”__keyevent@0__:expired”3)”__keyevent@0__:expired”4)”test” 在SpringBoot中导入Redis配置在pom.xml中引入Redis1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 编写订阅事件12345678910111213141516171819202122232425262728// RedisConfig.java@Configurationpublic class RedisConfig &#123; /** * key失效通知事件 * @param connectionFactory * @param listenerAdapter * @return */ @Bean RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory, MessageListenerAdapter listenerAdapter) &#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(connectionFactory); container.addMessageListener(listenerAdapter, new PatternTopic(&quot;__keyevent@0__:expired&quot;)); return container; &#125; /** * 失效监听方法 * @param receiver * @return */ @Bean MessageListenerAdapter listenerAdapter(RedisMessageReceiver receiver) &#123; return new MessageListenerAdapter(receiver, &quot;receiveMessage&quot;); &#125;&#125; 再写一个处理监听的方法 123456789101112// RedisMessageReceiver.java@Componentpublic class RedisMessageReceiver &#123; /** * 键失效监听方法 * @param message key */ public void receiveMessage(String message) &#123; // 这个message就是key System.out.println(message); &#125;&#125; 然后在项目启动时给Redis中进行设值 1234567891011@Componentpublic class InitCache implements ApplicationRunner &#123; @Resource private RedisUtil redisUtil; @Override public void run(ApplicationArguments args) throws Exception &#123; // 使用RedisUtil设置值 &#125;&#125; 问题产生当我在RedisMessageReceiver这个类中调用receiveMessage方法时，会处理我的业务逻辑。 如下面这个业务员逻辑，当我的观看量和点赞量写入数据库中 123456789101112131415161718192021222324252627282930private void dealBlogLookLike() &#123; // 获取匹配的key Set&lt;String&gt; keys = redisUtil.scan(&quot;blog::*&quot;); // 如果不为null并且size大于0 就执行下面的逻辑 if (keys != null &amp;&amp; keys.size() &gt; 0) &#123; // 创建一个list,将要更新的数据放在里面，然后数据库批量更新 List&lt;BlogLookLikeDto&gt; list = new ArrayList&lt;&gt;(); // 循环遍历key for (String key : keys) &#123; // 拿到需要的数据 Integer look = (Integer) redisUtil.hget(key, &quot;look&quot;); Integer like = (Integer) redisUtil.hget(key, &quot;like&quot;); // 存入到对象里面 BlogLookLikeDto blog = new BlogLookLikeDto(); blog.setId(Integer.valueOf(key.substring(6))); blog.setLook(look); blog.setLike(like); list.add(blog); &#125; // 批量刷入到数据库 int res = blogDao.updateBlogLookLike(list); // 如果更新没失败就删除值 if (res == keys.size()) &#123; redisUtil.del(keys); &#125; &#125; // 最后重新定时 redisUtil.set(&quot;blog:looklike:timmer&quot;, &quot;博文刷新观看数点赞数定时器&quot;, Constants.BLOG_LOOK_LIKE_TIME_INTERVAL);&#125; 自我认为代码逻辑没有问题，但是在执行这个键空间事件通知的时候，会执行以下的代码，但是某一天发现我的访问没有刷入到数据库然后打开本地的数据进行复现，将Constants.BLOG_LOOK_LIKE_TIME_INTERVAL更改为10S刷一次,发现问题所在 以下是复现 打开一个键失效监听，可以发现在第三次之后应该为&quot;blog:looklike:timmer&quot;键失效 12345678910111213141516171819202122232425262728293031323334353637127.0.0.1:6379&gt; PSUBSCRIBE __keyevent@0__:expiredReading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;__keyevent@0__:expired&quot;3) (integer) 11) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;blog:looklike:timmer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot;1) &quot;pmessage&quot;2) &quot;__keyevent@0__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;web::viewer&quot; 在另一个redis-cli中查看keys的数据 发现&quot;blog:looklike:timmer&quot;和&quot;web::viewer&quot;的消失 123456789101112127.0.0.1:6379&gt; keys *1) &quot;web::viewer&quot;2) &quot;blog:looklike:timmer&quot;3) &quot;web::views&quot;127.0.0.1:6379&gt; keys *1) &quot;web::viewer&quot;2) &quot;web::views&quot;127.0.0.1:6379&gt; keys *1) &quot;web::views&quot;127.0.0.1:6379&gt; keys *1) &quot;web::views&quot;127.0.0.1:6379&gt; 回到Redis终端发现为redis命令超时错误 Caused by: io.lettuce.core.RedisCommandTimeoutException: Command timed out 这个问题很好解决，只需要调大配置文件中redis超时时间就可以了 spring.redis.timeout: 1000 但是追踪溯源为何导致了key的消失原来的键空间处理事件中执行dealBlogLookLike()方法时，这其中内部的命令如果超时的话会直接抛出异常，将方法弹出栈 其实解决办法还可以通过catch下来，自定义一个异常处理，但是我没选择这个方法的原因有两点: 如何保证catch下来的，自定义异常处理中关于Redis的操作一定超时呢，这是没办法保证的。 自定义异常处理会带来一些其他的问题，例如针对单个key如何进行个性化处理。随着后面业务的拓展，个性化代码变得冗余，更加不好维护。 后记这次线上问题主要是分享SpringBoot整合Redis实现定时任务，正好趁这次事件编辑这篇博文。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"}]},{"title":"Redis学习之路(四)——Redis持久化理念","slug":"Redis学习之路(四)——Redis持久化理念","date":"2020-05-18T06:22:27.000Z","updated":"2021-02-18T14:00:23.793Z","comments":true,"path":"2020/05/18/Redis学习之路(四)——Redis持久化理念/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/18/Redis%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E5%9B%9B)%E2%80%94%E2%80%94Redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%90%86%E5%BF%B5/","excerpt":"Redis的持久化方式以及redis应用场景辩证","text":"Redis持久化理论两类持久化一类是RDB、image、bak，统称为派快照，通常和时间点挂钩，在某个时间，进行一次持久化备份(全量备份)。但是如果说下一次时间点备份的时候，发现已经宕机了，那么数据量丢失就会比较大；再一个就是这种备份恢复很快，相对于I/O读取速度，就是把内存中什么样子直接弄到一个文件里面，所以大小也和内存大小差不多。 还有一类就是日志、AOF(append only file)。倾向于行为的记录，趋近于实时；再某个时间点突然宕机，同样会丢数据，但是这个丢数据取决系统的配置，如果是用redis操作写，每操作一个sync（磁盘写），redis性能就被压得很低(读客户端io，写到内存，再掉磁盘io写到文件，然后才能调第二个客户端的操作)；如果说是交给os（操作系统）去做，就涉及到一个pagecache（页缓冲）的概念，不断得往里面写。但是同样有丢失，两个维度，一个是5秒，一个是内存的10%。相当于就是达到5s或者内存10%得时候就往文件里面写，看自己得配置用的哪种方式，此时突然宕机就是把内存中积压的数据丢了，而且pagecahce还有一个参数，如果说内存挤压到30%，就会直接阻塞io，不能再往pagecache里面写，pagecache就往磁盘写(类似于stop the world)；也可以采用其他的技术1秒写一次，这样数据丢失量小。 DB一般都会使用的DIO（direct io），将pagecache移到进程中去，由自己去维护。 DMA 直接内存访问（Direct Memory Access，DMA）是计算机科学计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统（电脑外设），可以独立地直接读写系统内存，而不需中央处理器（CPU）介入处理 。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。 redis默认开启RDB关闭AOF方式，如果在4.x之前手工开启AOF，重启之后只会读取AOF的内容，放弃RDB内容。如果AOF运行时间超长，AOF文件很大，里面含有大量的无效内容，回滚的时候能够拿到的资源很少。 如何解决AOF这个问题 （namenode）采用AOF进行一次全量备份，然后到时间点之后对RDB进行一次写入，然后AOF进行增量备份。 （redis）追求全量，为了恢复的快，将无效的数据抵消掉，采用了重写的操作，保证AOF文件小(在到达某个点的时候进行重写，例如文件过大)。4.x之后提出一个概念，依旧是开始AOF，当触发重写的时候，不去做去重操作，去进行了一次RDB，将这个RDB文件其放到AOF日志文件头，然后再去做AOF的追加操作 redis应用场景辩证使用redis是由于其内存级的操作，然而采用AOF的话就会降低其效率。 如果做缓存就不建议开启AOF，采用最快的缓存方案例如主从复制，但是主从复制是弱一致性，由于是缓冲没有影响。 如果做数据库，就必然要开启持久化。那肯定要开redis的sync写，主从复制等，效率和MySQL就差距不大。 redis需要解决的问题redis定位为单机程序，必然有两类问题：1、单点故障；2、压力过大 如果说单点故障后就不可用，就得做主从（主备）复制或者全量集群。但是这样就多台机器存放着相同的数据。 如果说压力过大/性能满，那就只有分而治之，将数据进行分片。每台机器存放部分数据，但是同样存在着单机故障，就要对分片机器就行全量集群。 所以两种方案同时使用。 如果redis需要HA(高可用)就要主从复制 CAP(C是一致性，A是可用性，P是分区容错性) 强一致性，客户端向redis写数据，redis主机向redis备机写数据，如果redis备机写成功了，就向redis主机发送ok，redis主机收到ok后，再向客户端返回ok。但是备机如果突然挂掉了，则redis主机就等待着备机响应，redis集群对外就表现为不可用。 弱一致性，客户端向redis主机写数据，redis主机处理成功后直接向客户端写数据，然后再向redis备机写数据。但是无法保证redis备机的数据是否一致 所以这里抛出一个问题:用redis做分布式锁可行吗 可以做分布式锁方式有很多例如，redis、zookeeper&lt;大数据&gt;、etcd 涉及行业，如果说金融行业使用redis做分布式锁，就不行，对强一致性要求极高，会导致redis效率过低。如果说互联网行业，对强一致性要求不高的业务来说是没有问题的。 最终一致性: 如果说在redis直接有一个黑盒的技术，redis主机将数据写向黑盒，写完就成功返回ok，强一致性，并且不宕机，redis去黑盒拿数据，最终数据是一致的。但是这个技术redis暂时没有。但是在大数据的namenode中实现了。如图所示 分片集群： 将数据分到多个redis机器上 实现方式有多种 对客户端的键值进行hash，然后取模2，分到两个redis机器上，但是需要客户端引入其他jar包，浪费一部分性能，并且扩展性不强 将hash之类的算法让在一个代理服务器上，由这个服务器进行计算然后发到哪个redis机器上，但是多一台机器，多一份风险，也可以做一个负载均衡，相对于第一种情况好一些 将算法挪到redis内部，redis可以评估这个key该到哪个redis服务器上去取值。所以在redis中有一个slot槽（16384），当需要扩展时，只需要牵出部分数据到新的redis服务器上即可 redis-cli.c:#define CLUSTER_MANAGER_SLOTS 16384/* We have 16384 hash slots. The hash slot of a given key is obtained as the least significant 14 bits of the crc16 of the key. However if the key contains the {…} pattern, only the part between { and } is hashed. This may be useful in the future to force certain keys to be in the same node (assuming no resharding is in progress). */static unsigned int clusterManagerKeyHashSlot(char *key, int keylen) {}","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]},{"title":"Redis学习之路(三)——Redis基础资料","slug":"Redis学习之路(三)——Redis基础资料","date":"2020-05-18T02:27:48.000Z","updated":"2021-02-18T13:59:11.788Z","comments":true,"path":"2020/05/18/Redis学习之路(三)——Redis基础资料/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/18/Redis%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%B8%89)%E2%80%94%E2%80%94Redis%E5%9F%BA%E7%A1%80%E8%B5%84%E6%96%99/","excerpt":"Redis计算向数据移动、Redis实现步骤、Redis单线程、Redis连接池","text":"Redis 基础资料1. 数据向计算移动 or 计算向数据移动1.1 数据向计算移动memcached只能存储字符串类型，当客户端发送一个”set a {a,b,c,d}”的命令时，memcached会记录字符串类型的{a,b,c,d}，但是当客户端想要获取a数据中下标为2的数据时，客户端发送指令“get a”，memcached会将整个字符串返回，客户端会拿到{a,b,c,d}，然后通过json反序列化的方式，将字符串类型的数据类型转换为数组类型，然后通过下标方式获取到c字符。 1.2 计算向数据移动redis可以存储五大数据类型，当客户端发送一个”lpush a {a,b,c,d}”时，redis会将其识别为数组类型。当客户端想要获取a数据下标为2的数据时，发送指令“lindex a 2”，redis会调用本地方法index(2)直接获取到a数组中下标为2的数据c。客户端拿到的数据就是已经通过计算的数据 2. Redis 实现步骤多个客户端发送消息到操作系统内核kernel，redis去问多路复用器epoll有几个客户端发送了消息，然后redis worker单线程到kernel取数据，然后再到redis本地方法进行计算。 3. Redis 单线程好还是多线程好多个客户端高并发访问service时，会先通过负载均衡器（例如nginx），由负载均衡器将请求发送到不同的service机器上，并行执行，如果说db层只有数据库，那么很容易就会造成脏读，为了保证数据一致性，就只有通过加锁的方式，让service进行一个排队处理，但是加锁的弊端就会暴露出来，涉及到性能的损耗（内核态和用户态的切换） 如果说把db换成redis，由于redis是单线程操作，所以就形成了串行化操作。 同样是多个客户端发送数据到操作系统kernel内核上，epoll感知到数据到了，redis worker线程取数据，但是cpu的利用率不高，单个线程对应cpu单核操作，为了提高cpu利用率redis在6.x之后进行了升级。 redis升级过后采用了io threads，但是不是默认的，需要开启，多线程进行读取操作，由worker单线程进行计算，计算后再由io thread写回。 4. 连接池和线程池连接池本质是一个list，里面存放着N多个socket，这一个list可以用线程池进行处理，线程池里面也可以只有一个线程，这就涉及到NIO，多路复用和epoll等知识","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]},{"title":"LeetCode 第53题: 最大子序和","slug":"LeetCode-第53题-最大子序和","date":"2020-05-17T23:05:45.000Z","updated":"2021-02-18T13:57:33.616Z","comments":true,"path":"2020/05/18/LeetCode-第53题-最大子序和/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/18/LeetCode-%E7%AC%AC53%E9%A2%98-%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/","excerpt":"给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。","text":"53. 最大子序和给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例: 输入: [-2,1,-3,4,-1,2,1,-5,4],输出: 6解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/maximum-subarray著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析思路1: 动态规划一个数组的最大和可由一个函数表示 F max = F(i-1) + ai 由于需要连续的子数组，那么当** F(i-1) + ai &lt; ai** 时，就需要将最大值记为ai，所以有 F max = Max( F(i-1) + ai , ai ) 思路2:线段树将一个数组拆分为最小单位，将其处理为一个Status{iSum,lSum,rSum,mSum}，其中:lSum 表示 [l, r]内以 l 为左端点的最大子段和rSum 表示 [l, r]内以 r 为右端点的最大子段和mSum 表示 [l, r]内的最大子段和iSum 表示 [l, r]的区间和 所以当输入lSub和rSub时，需要对两个Status进行处理iSum：就是左边的iSum加上右边的iSumlSum: 两个Status中lSum的最大值rSum：同理lSum，为两个Status中rSum的最大值mSum：就有三种情况: 左边的最大字段和(l.mSum)大 右边的最大字段和(r.mSum)大 左边的右部分加上右边的左部分之和大(l.rSum+r.lSum)，这里相当于拼接两个子数组 代码实现思路一代码实现： 123456789public int maxSubArray(int[] nums) &#123; int res = nums[0], max = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; max = Math.max(max + nums[i], nums[i]); res = Math.max(max, res); &#125; return res;&#125; 思路二代码实现: 12345678910111213141516171819202122232425262728293031323334class Status &#123; int iSum; int lSum; int rSum; int mSum; public Status(int iSum, int lSum, int rSum, int mSum) &#123; this.iSum = iSum; this.lSum = lSum; this.rSum = rSum; this.mSum = mSum; &#125;&#125;// 构造新的Statusprivate Status pushup(Status lsub, Status rsub)&#123; int isum = lsub.iSum + rsub.iSum; int lsum = Math.max(lsub.lSum, rsub.lSum); int rsum = Math.max(rsub.rSum, lsub.rSum); int msum = Math.max(Math.max(lsub.mSum, rsub.mSum), lsub.rSum+ rsub.lSum); return new Status(lsum, rsum, msum, isum);&#125;// 将数组的单位数据构造成Status对象private Status get(int[] nums, int L, int R) &#123; if (L == R) return new Status(nums[0],nums[0],nums[0],nums[0]); // 创建 int m = (L + R) &gt;&gt; 1; Status lSub = get(nums, L, m); Status rSub = get(nums, m+1, R); return pushup(lSub, rSub);&#125;private int maxSubArray(int[] nums) &#123; return get(nums, 0, nums.length-1).mSum;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第152题: 乘积最大子数组","slug":"LeetCode-第152题-乘积最大子数组","date":"2020-05-17T22:11:57.000Z","updated":"2021-02-18T13:56:18.431Z","comments":true,"path":"2020/05/18/LeetCode-第152题-乘积最大子数组/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/18/LeetCode-%E7%AC%AC152%E9%A2%98-%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84/","excerpt":"给你一个整数数组 nums ，请你找出数组中乘积最大的连续子数组（该子数组中至少包含一个数字），并返回该子数组所对应的乘积。","text":"152. 乘积最大子数组给你一个整数数组 nums ，请你找出数组中乘积最大的连续子数组（该子数组中至少包含一个数字），并返回该子数组所对应的乘积。 示例 1: 输入: [2,3,-2,4]输出: 6解释: 子数组 [2,3] 有最大乘积 6。示例 2: 输入: [-2,0,-1]输出: 0解释: 结果不能为 2, 因为 [-2,-1] 不是子数组。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/maximum-product-subarray著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析思路1: 如果说数组中有0 数组中负数的个数为奇数 数组中正数的个数为偶数 针对这种思路，遍历一遍整个数组，判断有几个奇数和是否含有0然后如果说含有0，那就最大子数组一定在0左边或右边如果说有奇数个负数，最大子数组一定在最后一个负数的左边或右边如果说有偶数个负数，最大子数组一定是整个字符串 分析: 需要遍历两边数组，时间复杂度为2n，空间复杂度为O(1) 思路2: 动态规划我们可以知道在一个数组中，最大值可以构造一个函数定义 *Fmax = F(i-1) * ai* 但由于数组中含有负数，所以当 F(i-1)的值为一个负数且ai也为负数时，产生一个整数的最大值。所以函数表达式产生了变形Fmax = Max( F(i-1)max * ai , F(i-1)min * ai) Fmin = Min( F(i-1)max * ai , F(i-1)min * ai) 由于题目中规定了连续的子数组，那么就需要一个状态转移，需要将ai也考虑进来，如果*F(i-1)max * ai &lt; ai*那么，ai就是最大值，只需要再状态转移方程中加上ai Fmax = Max( F(i-1)max * ai , F(i-1)min * ai , ai) Fmin = Min( F(i-1)max * ai , F(i-1)min * ai , ai) 分析: 只需要遍历一次数组，时间复杂度O(n),空间复杂度O(1) 代码实现这里选择思路2进行代码实现 123456789101112public int maxProduct(int[] nums) &#123; int res = nums[0], min = nums[0], max = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; int mx = max, mn = min; max = Math.max( mx * nums[i], Math.max( mn * nums[i], nums[i] )); min = Math.min( mx * nums[i], Math.min( mn * nums[i], nums[i] )); res = Math.max(max, res); &#125; return res;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"Redis学习之路(二)——Redis五大数据类型","slug":"Redis学习之路(二)——Redis五大数据类型","date":"2020-05-17T07:52:50.000Z","updated":"2021-02-18T13:52:07.978Z","comments":true,"path":"2020/05/17/Redis学习之路(二)——Redis五大数据类型/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/17/Redis%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%BA%8C)%E2%80%94%E2%80%94Redis%E4%BA%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"整理Redis五大数据类型以及使用部分场景","text":"五大基本数据类型及其使用场景string1. 字符串操作set key value 新增一个key append key value 在一个key后面追加一个value strlen key key所对的value的长处 中文字符在redis中根据编码来定例如一个‘中’字，在utf-8的编码情况下得到的长度为3例：127.0.0.1:6379&gt; set k1 中OK127.0.0.1:6379&gt; STRLEN k1(integer) 3 在gbk的编码集下，长度为2例：127.0.0.1:6379&gt; set k2 中OK127.0.0.1:6379&gt; strlen k2(integer) 2 2. 数值计算incr key 让一个数字性的value自增1 如果说value为一个数值类型，例如为9，则它的长度为1；为10，则他的长度为2；为100，则它的长度为3127.0.0.1:6379&gt; set k3 9OK127.0.0.1:6379&gt; strlen k3(integer) 1127.0.0.1:6379&gt; set k3 10OK127.0.0.1:6379&gt; STRlen k3(integer) 2127.0.0.1:6379&gt; set k3 100OK127.0.0.1:6379&gt; strlen k3(integer) 3 由此可知，数值类型的长度相当于数值转换为字符串的长度 原因是因为redis是一个二进制安全的，就是由数据发送方和数据接收方已经商量好数据编解码，而作为中间组件，把他们的数据序列化时都当作byte[]类型进行处理 3. 位操作 bitmap(位图) setbit key offset value 设置二进制位 例如 ： setbit k1 1 1在内存中就是开辟一个字节的空间空间 0 0 0 0 0 0 0 0offset 0 1 2 3 4 5 6 7这个命令就是将offset为1的位置设置为1结果 0 1 0 0 0 0 0 0这个结果在ascii码中对应的是十进制64号字符‘@’（在linux中执行man ascii可以看到ascii表对应的8进制、10进制、16进制）如果offset超过了7，则redis会再开辟空间，直到offset能够放下例如 offset k2 9999 1127.0.0.1:6379&gt; setbit k2 9999 1(integer) 0127.0.0.1:6379&gt; strlen k2(integer) 1250 *可以计算到一个字节八位 ，12508=10000 = 9999+1 ，凑成整数个字节**如果说设置一个字节的最高位为1，则有可能无法识别当被ascii字符集识别时，最高位无用，所以在setbit后无法识别例如 0100 0000 1000 0000127.0.0.1:6379&gt; setbit k3 1 1(integer) 0127.0.0.1:6379&gt; setbit k3 8 1(integer) 0127.0.0.1:6379&gt; get k3“@\\x80” 如果说key正好符合各种字符集，则会被设别为对应字符集的值可以用man utf-8命令查看utf-8的字符集规则 man ascii man utf-8 bitcount key start end 计算从开始字节到结束字节有多少个1，默认统计全部 例如： bitcount k3127.0.0.1:6379&gt; BITCOUNT k3(integer) 2这个双向的同样可以统计 0 -1 从0到最后一个字节1的个数例如：127.0.0.1:6379&gt; setbit k3 20 1(integer) 0127.0.0.1:6379&gt; BITCOUNT k3 0 -1(integer) 3 bitop operation destkey key.. 位操作，操作类型可以是and、or，结果key是destkey 例如127.0.0.1:6379&gt; setbit k1 7 1(integer) 0127.0.0.1:6379&gt; setbit k1 1 1(integer) 0127.0.0.1:6379&gt; setbit k2 1 1(integer) 0127.0.0.1:6379&gt; setbit k2 6 1(integer) 0127.0.0.1:6379&gt; get k1“A”127.0.0.1:6379&gt; get k2“B” k1: 0 1 0 0 0 0 0 1 k2: 0 1 0 0 0 0 1 0 127.0.0.1:6379&gt; bitop and andkey k1 k2(integer) 1127.0.0.1:6379&gt; get andkey“@” andkey: 0 1 0 0 0 0 0 0 127.0.0.1:6379&gt; bitop or orkey k1 k2(integer) 1127.0.0.1:6379&gt; get orkey“C” orkey: 0 1 0 0 0 0 1 1 4. 应用场景string: session 、 kv缓存、数值计算、fs文件系统（将一个小文件存放在内存里，key为文件名，value为文件内容）、内存 二进制： 统计任意时间窗口一个用户的登陆情况、在活动期间用户的注册数或者活跃用户数 1、设置key为用户名 每一个bit就代表一天，当天登陆就设置为1 例如 127.0.0.1:6379&gt; SETBIT zs 1 1(integer) 0127.0.0.1:6379&gt; SETBIT zs 2 1(integer) 0127.0.0.1:6379&gt; SETBIT zs 364 1(integer) 0127.0.0.1:6379&gt; BITCOUNT zs(integer) 3 2、设置日期为key，第几号用户登陆过就设置为1 例如 ： 127.0.0.1:6379&gt; setbit 20200101 3 1(integer) 0127.0.0.1:6379&gt; setbit 20200101 8 1(integer) 0 在2020年1月1号这天3号用户和8号用户登陆过 127.0.0.1:6379&gt; setbit 20200102 3 1(integer) 0127.0.0.1:6379&gt; setbit 20200102 10 1(integer) 0 在2020年1月2号这天3号用户和10号用户登陆过 127.0.0.1:6379&gt; bitop or res 20200101 20200102(integer) 2 127.0.0.1:6379&gt; BITCOUNT res(integer) 3 进行或运算就可以知道这两天有多少个活跃用户 list1. 本质是一个双向链表key指向链表的头部和尾部，所以redis的list类型可以双向操作，顺序为放入顺序 2. 操作lpush key a b c d e 从左边压入数据,实际内存中为edcbaLRANGE key start end 正序遍历list从start到end 127.0.0.1:6379&gt; lpush k1 a b c d e(integer) 5 127.0.0.1:6379&gt; LRANGE k1 0 -11)”e”2)”d”3)”c”4)”b”5)”a” rpush key x y z 从右边压入数据,在内存中为 xyz 127.0.0.1:6379&gt; RPUSH k1 x y z(integer) 8127.0.0.1:6379&gt; LRANGE k1 0 -11)”e”2)”d”3)”c”4)”b”5)”a”6)”x”7)”y”8)”z” lpop key 从左边弹出数据rpop key 从右边弹出数据 127.0.0.1:6379&gt; lpop k1“e”127.0.0.1:6379&gt; rpop k1“z” lindex key index 获取从左边数下标为index的值 127.0.0.1:6379&gt; lindex k1 1“c” ltrim key start end 删除start之前end之后的数据 127.0.0.1:6379&gt; LTRIM k1 0 -2OK 127.0.0.1:6379&gt; LRANGE k1 0 -11)”d”2)”c”3)”b”4)”a”5)”x” 3. 应用场景消息队列、评论、替代 替代Java的一些容器可以让jvm无状态,当jvm宕机的情况下，redis中可以拿到数据。高并发情况下访问同一个redis，让数据共享，服务无状态 hash1. hash本质是hashMapHashMap本质是HashTable，主要体现出分治思想 2. 操作hset key field name 设置一个名key的hash，键为field，值为value **hgetall key ** 获取key的键和值 127.0.0.1:6379&gt; HSet k1 name 123(integer) 1127.0.0.1:6379&gt; hset k1 age 17(integer) 1127.0.0.1:6379&gt; hgetall k11)”name”2)”123”3)”age”4)”17” hkeys key 获取key的键 127.0.0.1:6379&gt; hkeys k11)”name”2)”age” hvals key 获取key的值 127.0.0.1:6379&gt; hvals k11)”123”2)”17” hincrby key field value 让key的键为field的增加value，value可以为负数 127.0.0.1:6379&gt; HINCRBY k1 age 1(integer) 18127.0.0.1:6379&gt; HINCRBY k1 age -1(integer) 17 3. 使用场景聚集数据，详情页 set1. 集合，无序不重复，set底层是hashsethashset底层是hashmap，value为null，且去重。效率低，阻塞后边操作 2. 操作sadd key member…. 添加集合 smembers key 取出所有集合 127.0.0.1:6379&gt; clear127.0.0.1:6379&gt; Sadd k1 1122 2211 1212 2121 1221 2112 1122(integer) 6127.0.0.1:6379&gt; SMEMBERS k11)”1122”2)”1212”3)”1221”4)”2112”5)”2121”6)”2211” srandmember key count 返回多少个值，如果是正值且小于总数可以返回乱序且不重复的元素；如果是正值且大于总数，则返回总的元素；如果是负数，则返回count个可重复的元素。 127.0.0.1:6379&gt; SRANDMEMBER k1 31)”1122”2)”1221”3)”2121”127.0.0.1:6379&gt; SRANDMEMBER k1 101)”1122”2)”1212”3)”1221”4)”2112”5)”2121”6)”2211”127.0.0.1:6379&gt; SRANDMEMBER k1 -51)”1212”2)”2112”3)”2211”4)”2112”5)”1212”127.0.0.1:6379&gt; SRANDMEMBER k1 -101)”2211”2)”1221”3)”1212”4)”1221”5)”1212”6)”1221”7)”1221”8)”2211”9)”2112”10)”2211” spop key 随机弹出一个值 127.0.0.1:6379&gt; spop k1“1221”127.0.0.1:6379&gt; spop k1“1122”127.0.0.1:6379&gt; spop k1“2121”127.0.0.1:6379&gt; spop k1“2112”127.0.0.1:6379&gt; spop k1“2211”127.0.0.1:6379&gt; spop k1“1212”127.0.0.1:6379&gt; spop k1(nil) sunion key… 返回总的集合且去重 127.0.0.1:6379&gt; sadd k1 a b c d e(integer) 5127.0.0.1:6379&gt; sadd k2 d e f(integer) 3127.0.0.1:6379&gt; SUNION k1 k21)”d”2)”a”3)”c”4)”b”5)”e”6)”f” sinter key… 返回交集 127.0.0.1:6379&gt; SINTER k1 k21)”e”2)”d” sdiff key… 返回以第一个key为准的差集 127.0.0.1:6379&gt; SDIFF k1 k21)”a”2)”b”3)”c”127.0.0.1:6379&gt; SDIFF k2 k11)”f” 3. 使用场景集合交并差集、随机时间、抽奖、验证码、扑克牌游戏、好友推荐 sorted set (Zset)1. 有序集合、去重、排序通过score进行排序，如果score相同则进行ascii字典表进行排序。还有一个rank，是排序后的排名即rank。同样有正序倒序。 2. 操作zadd key score value 新建一个有序集合 zrange key start end withscores 从start到end取出有序集合（通过score排序） 127.0.0.1:6379&gt; ZADD k1 10 apple 20 pear 30 banana(integer) 3127.0.0.1:6379&gt; ZRANGE k1 0 -1 withscores1)”apple”2)”10”3)”pear”4)”20”5)”banana”6)”30” zrevrange key start end 倒序取出集合 127.0.0.1:6379&gt; ZREVRANGE k1 0 -11)”banana”2)”pear”3)”apple” zrangebyscore key min max 取出score在min到max之间的有序集合 127.0.0.1:6379&gt; ZRANGEBYSCORE k1 12 311)”pear”2)”banana” 3. 场景排行榜、评论 4. 动态排序正序倒序并没有进行重排序 排序方式数据结构：ziplist、skiplist（后边详细介绍ziplist和skiplist） 12345678&gt; **当单个值过大的时候就会进行结构的转换**&gt;&gt; 127.0.0.1:6379&gt; OBJECT encoding k1 &gt; &quot;ziplist&quot; &gt; 127.0.0.1:6379&gt; zadd k1 123 aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa &gt; (integer) 1 &gt; 127.0.0.1:6379&gt; OBJECT encoding k1 &gt; &quot;skiplist&quot;","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]},{"title":"LeetCode 第33题:搜索旋转排序数组","slug":"LeetCode-第33题-搜索旋转排序数组","date":"2020-05-16T06:51:14.000Z","updated":"2021-02-18T13:49:36.957Z","comments":true,"path":"2020/05/16/LeetCode-第33题-搜索旋转排序数组/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/16/LeetCode-%E7%AC%AC33%E9%A2%98-%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/","excerpt":"假设按照升序排序的数组在预先未知的某个点上进行了旋转。 ( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。 搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。","text":"33. 搜索旋转排序数组假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。你可以假设数组中不存在重复的元素。你的算法时间复杂度必须是 O(log n) 级别。示例 1:输入: nums = [4,5,6,7,0,1,2], target = 0输出: 4示例 2:输入: nums = [4,5,6,7,0,1,2], target = 3输出: -1 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/search-in-rotated-sorted-array著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 解题分析当看到有序数组查找值，并且时间要求为O(log n)，优先想到的就是二分查找法，先写个例子 1234567891011private int banarySearch(int[] nums, int target)&#123; int L = 0; int R = 0; while (L &lt;= R) &#123; int mid = (L+R)&gt;&gt;&gt;1; if (nums[mid] == target) return mid; if (nums[mid] &lt; target) L = mid + 1; else if (nums[mid] &gt; target) R = mid - 1; &#125; return -1;&#125; 但题目中的数组并不是一个纯排好序的数组，先举个例子 nums 4 5 6 7 8 1 2 3 index 0 1 2 3 4 5 6 7 按照传统的二分查找，第一次的mid=3（ (L+R)/2 ），那么原数组被分为两个数组数组1 nums 4 5 6 7 index 0 1 2 3 数组2： nums 8 1 2 3 index 4 5 6 7 可以看到，这个两个数组被拆分成了两种情况，有序数组1，无序数组2.接下来就可以安装传统二分法处理数组1，但是数组二还是无法处理但是，我们发现将数组2继续拆分还是会得到两个数组，有序和无序 nums 8 1 index 4 5 nums 2 3 index 6 7 那么思路就有了如果target在有序数组中就按照传统二分查找做如果target在无序数组中就继续拆分 代码实现1234567891011121314151617181920212223public int search(int[] nums, int target) &#123; int L = 0; int R = nums.length - 1; while(L &lt;= R) &#123; int mid = (L+R)&gt;&gt;&gt;1; if (nums[mid] == target) return mid; if (nums[0] &lt;= nums[mid]) &#123; // 左边有序 if (nums[0] &lt;= target &amp;&amp; target &lt; nums[mid]) &#123; // 最左边 &gt; target &gt; mid R = mid - 1; &#125; else &#123; L = mid + 1; &#125; &#125; else &#123; // 左边无序 右边有序 if (nums[mid] &lt; target &amp;&amp; target &lt;= nums[nums.length - 1]) &#123; // mid &lt; target &lt; 最右边 L = mid + 1; &#125; else &#123; R = mid - 1; &#125; &#125; &#125; return -1;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"LeetCode 第31题:下一个排列","slug":"LeetCode 第31题 下一个排列","date":"2020-05-16T01:08:35.000Z","updated":"2021-02-18T13:48:51.680Z","comments":true,"path":"2020/05/16/LeetCode 第31题 下一个排列/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/16/LeetCode%20%E7%AC%AC31%E9%A2%98%20%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%8E%92%E5%88%97/","excerpt":"实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。 如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。 必须原地修改，只允许使用额外常数空间。","text":"31. 下一个排列实现获取下一个排列的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。必须原地修改，只允许使用额外常数空间。以下是一些例子，输入位于左侧列，其相应输出位于右侧列。1,2,3 → 1,3,23,2,1 → 1,2,31,1,5 → 1,5,1 题目来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/next-permutation著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目分析输入一串数组例如 nums 1 2 4 3 2 index 0 1 2 3 4 找出下一个更大的排列，即 nums 1 3 2 2 4 index 0 1 2 3 4 可以找打规律从右向左遍历，找到一个拐点的时候，如上例所示，即 2、4、3、22在2、3、4这样的逆序排列中，突然递减，此时可以找到一个更大的排列 如图所示，只需要找到2之后的节点，并且离2最接近的节点进行交换 然后将3之后的节点进行排序，就拿到了1、3、2、2、4这个顺序 代码实现123456789101112131415161718192021222324252627282930313233343536373839public void nextPermutation(int[] nums) &#123; int len = nums.length; for (int i = len - 1; i &gt; 0; i--) &#123; if (nums[i-1] &lt; nums[i]) &#123; int aim = getClosestNum(nums, i-1); swap(nums, i-1, aim); Arrays.sort(nums, i, len); return; &#125; &#125; // 降序排列 Arrays.sort(nums);&#125;// 交换public void swap(int[] nums, int source, int target)&#123; int tmp = nums[source]; nums[source] = nums[target]; nums[target] = tmp;&#125;public int getClosestNum(int[] nums, int idx)&#123; int len = nums.length; int seek = idx + 2; // 游标i int aim = idx+1; // 初始化最接近的下标 int gap = nums[aim] - nums[idx];//差值 // 开始遍历后续节点，找到最接近拐点前的那个值 while (seek &lt;= len-1) &#123; if (nums[seek] &gt; nums[idx] &amp;&amp; (nums[seek] - nums[idx]) &lt; gap) &#123; aim = seek; gap = nums[seek] - nums[idx]; &#125; seek++; &#125; return aim;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"}]},{"title":"Redis学习之路(一)——Redis的安装","slug":"Redis学习之路(一)——Redis的安装","date":"2020-05-15T22:16:07.000Z","updated":"2021-02-18T13:48:15.586Z","comments":true,"path":"2020/05/16/Redis学习之路(一)——Redis的安装/","link":"","permalink":"https://rabbit-mar.github.io/2020/05/16/Redis%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF(%E4%B8%80)%E2%80%94%E2%80%94Redis%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"安装主机CentOS6，redis6.0 ，其中包含redis安装问题解决","text":"redis的安装及使用安装 打开redis官网 https://redis.io/ 找到download界面，复制下载链接 http://download.redis.io/releases/redis-6.0.1.tar.gz 然后在linux终端上用wget命令进行安装 wget http://download.redis.io/releases/redis-6.0.1.tar.gz 然后执行tar进行解压缩包 tar -zxvf redis-6.0.1.tar.gz 通过阅读redis-6.0.1下的README.MD可以自己进行安装，这里留下安装方式 3.1 输入make命令进行编译整个redis make 3.2 如果遇到cc命令没找到，就要先安装gcc，如果没有问题就跳转到3.5 3.3 执行yum安装gcc yum install gcc -y 3.4 安装完成后清除一下上一次make的缓存，然后再执行命令make，就行编译 make distclean &amp;&amp; make 3.5 如果还是报错server.c的问题，查看gcc的版本，然后升级gcc的版本,如果没有问题就跳转到3.7 12345678910111213# 查看gcc版本是否在5.3以上，centos7.6默认安装4.8.5gcc -v# 升级gcc到5.3及以上,如下：升级到gcc 9.3：yum -y install centos-release-sclyum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilsscl enable devtoolset-9 bash需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。如果要长期使用gcc 9.3的话：echo &quot;source &#x2F;opt&#x2F;rh&#x2F;devtoolset-9&#x2F;enable&quot; &gt;&gt;&#x2F;etc&#x2F;profile这样退出shell重新打开就是新版的gcc了以下其他版本同理，修改devtoolset版本号即可。 3.6 完成后再清理一次缓存，然后再make make distclean &amp;&amp; make 3.7 然后执行install命令进行安装，安装到/opt/redis/redis6目录下 mkdir /opt/redismkdir /opt/redis/redis6make PREFIX=/opt/redis/redis6 install 编辑/etc/profile文件，将redis命令安装到命令行快捷栏上 export REDIS_HOME=/opt/redis/redis6 export PATH=$PATH:$REDIS_HOME/bin 去设置redis为后台服务启动，进到redis安装目录下的utils,执行install_server.sh，进行安装 ./install_server.sh 如果出现问题，就去自己创建redis服务 6.1 拷贝一份conf文件到/etc/redis/下 cp /usr/lib/redis/redis-6.0.1/redis.conf /etc/redis/6380.conf 6.2 更改/etc/redis/下的配置文件 vim /etc/redis/6380.conf 1234567#下面要是改的参数 可以通过vim的&#x2F;查找port 6380daemonize yespidfile &#x2F;var&#x2F;run&#x2F;redis_6380.pidlogfile &quot;&#x2F;var&#x2F;log&#x2F;redis_6380.log&quot;#这个是redis数据持久化存放的地方dir &#x2F;var&#x2F;lib&#x2F;redis&#x2F;6380 6.3 创建数据存放目录 mkdir /var/lib/redis/6380 6.4 创建service文件 vim /usr/lib/systemd/system/redis_6380.service 1234567891011121314[Unit]Description&#x3D;redis_6380After&#x3D;network.target[Service]Type&#x3D;forking#pid文件路径PIDFile&#x3D;&#x2F;var&#x2F;run&#x2F;redis_6380.pid#这就是执行命令 前面为redis-server所在路径 后一个为刚配置的conf文件ExecStart&#x3D;&#x2F;opt&#x2F;redis&#x2F;redis6&#x2F;bin&#x2F;redis-server &#x2F;etc&#x2F;redis&#x2F;6380.confExecReload&#x3D;&#x2F;bin&#x2F;kill -s HUP $MAINPIDExecStop&#x3D;&#x2F;bin&#x2F;kill -s QUIT $MAINPIDPrivateTmp&#x3D;true[Install]WantedBy&#x3D;multi-user.target 6.5 启动service systemctl start redis_6380 6.6 根据需求可以再配一个本来端口6379的，会简单很多，两个可以一起启动 正式环境中有开机启动需求的话，就执行下方命令就行了 先创建一个符号链接 ln -s /usr/lib/systemd/system/redis_6379.service /etc/systemd/system/multi-user.target.wants/redis_6379.service systemctl list-unit-files | grep redis如果看到有这个出现就完成redis_6379.service enabled","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"}]}],"categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://rabbit-mar.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Kafka","slug":"Kafka","permalink":"https://rabbit-mar.github.io/tags/Kafka/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://rabbit-mar.github.io/tags/sharding-jdbc/"},{"name":"mycat","slug":"mycat","permalink":"https://rabbit-mar.github.io/tags/mycat/"},{"name":"Redis","slug":"Redis","permalink":"https://rabbit-mar.github.io/tags/Redis/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://rabbit-mar.github.io/tags/RabbitMQ/"},{"name":"文件系统","slug":"文件系统","permalink":"https://rabbit-mar.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"Java","slug":"Java","permalink":"https://rabbit-mar.github.io/tags/Java/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://rabbit-mar.github.io/tags/ElasticSearch/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://rabbit-mar.github.io/tags/SpringBoot/"},{"name":"Nginx","slug":"Nginx","permalink":"https://rabbit-mar.github.io/tags/Nginx/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://rabbit-mar.github.io/tags/LeetCode/"},{"name":"Gradle","slug":"Gradle","permalink":"https://rabbit-mar.github.io/tags/Gradle/"},{"name":"JVM","slug":"JVM","permalink":"https://rabbit-mar.github.io/tags/JVM/"}]}